{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
      "             ReLU-34           [-1, 48, 32, 32]               0\n",
      "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-36           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
      "             ReLU-38           [-1, 84, 32, 32]               0\n",
      "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "             ReLU-41           [-1, 48, 32, 32]               0\n",
      "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-43           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
      "             ReLU-45           [-1, 96, 32, 32]               0\n",
      "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
      "        AvgPool2d-47           [-1, 48, 16, 16]               0\n",
      "       Transition-48           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 48, 16, 16]              96\n",
      "             ReLU-50           [-1, 48, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 60, 16, 16]             120\n",
      "             ReLU-57           [-1, 60, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 72, 16, 16]             144\n",
      "             ReLU-64           [-1, 72, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 84, 16, 16]             168\n",
      "             ReLU-71           [-1, 84, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 96, 16, 16]             192\n",
      "             ReLU-78           [-1, 96, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 108, 16, 16]             216\n",
      "             ReLU-85          [-1, 108, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 120, 16, 16]             240\n",
      "             ReLU-92          [-1, 120, 16, 16]               0\n",
      "           Conv2d-93           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-94           [-1, 48, 16, 16]              96\n",
      "             ReLU-95           [-1, 48, 16, 16]               0\n",
      "           Conv2d-96           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-97          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-98          [-1, 132, 16, 16]             264\n",
      "             ReLU-99          [-1, 132, 16, 16]               0\n",
      "          Conv2d-100           [-1, 48, 16, 16]           6,336\n",
      "     BatchNorm2d-101           [-1, 48, 16, 16]              96\n",
      "            ReLU-102           [-1, 48, 16, 16]               0\n",
      "          Conv2d-103           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-104          [-1, 144, 16, 16]               0\n",
      "     BatchNorm2d-105          [-1, 144, 16, 16]             288\n",
      "            ReLU-106          [-1, 144, 16, 16]               0\n",
      "          Conv2d-107           [-1, 48, 16, 16]           6,912\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "            ReLU-109           [-1, 48, 16, 16]               0\n",
      "          Conv2d-110           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-111          [-1, 156, 16, 16]               0\n",
      "     BatchNorm2d-112          [-1, 156, 16, 16]             312\n",
      "            ReLU-113          [-1, 156, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           7,488\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-118          [-1, 168, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 168, 16, 16]             336\n",
      "            ReLU-120          [-1, 168, 16, 16]               0\n",
      "          Conv2d-121           [-1, 48, 16, 16]           8,064\n",
      "     BatchNorm2d-122           [-1, 48, 16, 16]              96\n",
      "            ReLU-123           [-1, 48, 16, 16]               0\n",
      "          Conv2d-124           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-125          [-1, 180, 16, 16]               0\n",
      "     BatchNorm2d-126          [-1, 180, 16, 16]             360\n",
      "            ReLU-127          [-1, 180, 16, 16]               0\n",
      "          Conv2d-128           [-1, 48, 16, 16]           8,640\n",
      "     BatchNorm2d-129           [-1, 48, 16, 16]              96\n",
      "            ReLU-130           [-1, 48, 16, 16]               0\n",
      "          Conv2d-131           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-132          [-1, 192, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 192, 16, 16]             384\n",
      "            ReLU-134          [-1, 192, 16, 16]               0\n",
      "          Conv2d-135           [-1, 96, 16, 16]          18,432\n",
      "       AvgPool2d-136             [-1, 96, 8, 8]               0\n",
      "      Transition-137             [-1, 96, 8, 8]               0\n",
      "     BatchNorm2d-138             [-1, 96, 8, 8]             192\n",
      "            ReLU-139             [-1, 96, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           4,608\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 108, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 108, 8, 8]             216\n",
      "            ReLU-146            [-1, 108, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           5,184\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 120, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 120, 8, 8]             240\n",
      "            ReLU-153            [-1, 120, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           5,760\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 132, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 132, 8, 8]             264\n",
      "            ReLU-160            [-1, 132, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           6,336\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 144, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 144, 8, 8]             288\n",
      "            ReLU-167            [-1, 144, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           6,912\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 156, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 156, 8, 8]             312\n",
      "            ReLU-174            [-1, 156, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           7,488\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 168, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 168, 8, 8]             336\n",
      "            ReLU-181            [-1, 168, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           8,064\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 180, 8, 8]             360\n",
      "            ReLU-188            [-1, 180, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           8,640\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 192, 8, 8]             384\n",
      "            ReLU-195            [-1, 192, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           9,216\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 204, 8, 8]             408\n",
      "            ReLU-202            [-1, 204, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           9,792\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 216, 8, 8]             432\n",
      "            ReLU-209            [-1, 216, 8, 8]               0\n",
      "          Conv2d-210             [-1, 48, 8, 8]          10,368\n",
      "     BatchNorm2d-211             [-1, 48, 8, 8]              96\n",
      "            ReLU-212             [-1, 48, 8, 8]               0\n",
      "          Conv2d-213             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-214            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-215            [-1, 228, 8, 8]             456\n",
      "            ReLU-216            [-1, 228, 8, 8]               0\n",
      "          Conv2d-217             [-1, 48, 8, 8]          10,944\n",
      "     BatchNorm2d-218             [-1, 48, 8, 8]              96\n",
      "            ReLU-219             [-1, 48, 8, 8]               0\n",
      "          Conv2d-220             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-221            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-222            [-1, 240, 8, 8]             480\n",
      "            ReLU-223            [-1, 240, 8, 8]               0\n",
      "          Conv2d-224             [-1, 48, 8, 8]          11,520\n",
      "     BatchNorm2d-225             [-1, 48, 8, 8]              96\n",
      "            ReLU-226             [-1, 48, 8, 8]               0\n",
      "          Conv2d-227             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-228            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-229            [-1, 252, 8, 8]             504\n",
      "            ReLU-230            [-1, 252, 8, 8]               0\n",
      "          Conv2d-231             [-1, 48, 8, 8]          12,096\n",
      "     BatchNorm2d-232             [-1, 48, 8, 8]              96\n",
      "            ReLU-233             [-1, 48, 8, 8]               0\n",
      "          Conv2d-234             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-235            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-236            [-1, 264, 8, 8]             528\n",
      "            ReLU-237            [-1, 264, 8, 8]               0\n",
      "          Conv2d-238             [-1, 48, 8, 8]          12,672\n",
      "     BatchNorm2d-239             [-1, 48, 8, 8]              96\n",
      "            ReLU-240             [-1, 48, 8, 8]               0\n",
      "          Conv2d-241             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-242            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-243            [-1, 276, 8, 8]             552\n",
      "            ReLU-244            [-1, 276, 8, 8]               0\n",
      "          Conv2d-245             [-1, 48, 8, 8]          13,248\n",
      "     BatchNorm2d-246             [-1, 48, 8, 8]              96\n",
      "            ReLU-247             [-1, 48, 8, 8]               0\n",
      "          Conv2d-248             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-249            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-250            [-1, 288, 8, 8]             576\n",
      "            ReLU-251            [-1, 288, 8, 8]               0\n",
      "          Conv2d-252             [-1, 48, 8, 8]          13,824\n",
      "     BatchNorm2d-253             [-1, 48, 8, 8]              96\n",
      "            ReLU-254             [-1, 48, 8, 8]               0\n",
      "          Conv2d-255             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-256            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-257            [-1, 300, 8, 8]             600\n",
      "            ReLU-258            [-1, 300, 8, 8]               0\n",
      "          Conv2d-259             [-1, 48, 8, 8]          14,400\n",
      "     BatchNorm2d-260             [-1, 48, 8, 8]              96\n",
      "            ReLU-261             [-1, 48, 8, 8]               0\n",
      "          Conv2d-262             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-263            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-264            [-1, 312, 8, 8]             624\n",
      "            ReLU-265            [-1, 312, 8, 8]               0\n",
      "          Conv2d-266             [-1, 48, 8, 8]          14,976\n",
      "     BatchNorm2d-267             [-1, 48, 8, 8]              96\n",
      "            ReLU-268             [-1, 48, 8, 8]               0\n",
      "          Conv2d-269             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-270            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-271            [-1, 324, 8, 8]             648\n",
      "            ReLU-272            [-1, 324, 8, 8]               0\n",
      "          Conv2d-273             [-1, 48, 8, 8]          15,552\n",
      "     BatchNorm2d-274             [-1, 48, 8, 8]              96\n",
      "            ReLU-275             [-1, 48, 8, 8]               0\n",
      "          Conv2d-276             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-277            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-278            [-1, 336, 8, 8]             672\n",
      "            ReLU-279            [-1, 336, 8, 8]               0\n",
      "          Conv2d-280             [-1, 48, 8, 8]          16,128\n",
      "     BatchNorm2d-281             [-1, 48, 8, 8]              96\n",
      "            ReLU-282             [-1, 48, 8, 8]               0\n",
      "          Conv2d-283             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-284            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-285            [-1, 348, 8, 8]             696\n",
      "            ReLU-286            [-1, 348, 8, 8]               0\n",
      "          Conv2d-287             [-1, 48, 8, 8]          16,704\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-291            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 360, 8, 8]             720\n",
      "            ReLU-293            [-1, 360, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]          17,280\n",
      "     BatchNorm2d-295             [-1, 48, 8, 8]              96\n",
      "            ReLU-296             [-1, 48, 8, 8]               0\n",
      "          Conv2d-297             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-298            [-1, 372, 8, 8]               0\n",
      "     BatchNorm2d-299            [-1, 372, 8, 8]             744\n",
      "            ReLU-300            [-1, 372, 8, 8]               0\n",
      "          Conv2d-301             [-1, 48, 8, 8]          17,856\n",
      "     BatchNorm2d-302             [-1, 48, 8, 8]              96\n",
      "            ReLU-303             [-1, 48, 8, 8]               0\n",
      "          Conv2d-304             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-305            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-306            [-1, 384, 8, 8]             768\n",
      "            ReLU-307            [-1, 384, 8, 8]               0\n",
      "          Conv2d-308            [-1, 192, 8, 8]          73,728\n",
      "       AvgPool2d-309            [-1, 192, 4, 4]               0\n",
      "      Transition-310            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-311            [-1, 192, 4, 4]             384\n",
      "            ReLU-312            [-1, 192, 4, 4]               0\n",
      "          Conv2d-313             [-1, 48, 4, 4]           9,216\n",
      "     BatchNorm2d-314             [-1, 48, 4, 4]              96\n",
      "            ReLU-315             [-1, 48, 4, 4]               0\n",
      "          Conv2d-316             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-317            [-1, 204, 4, 4]               0\n",
      "     BatchNorm2d-318            [-1, 204, 4, 4]             408\n",
      "            ReLU-319            [-1, 204, 4, 4]               0\n",
      "          Conv2d-320             [-1, 48, 4, 4]           9,792\n",
      "     BatchNorm2d-321             [-1, 48, 4, 4]              96\n",
      "            ReLU-322             [-1, 48, 4, 4]               0\n",
      "          Conv2d-323             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-324            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-325            [-1, 216, 4, 4]             432\n",
      "            ReLU-326            [-1, 216, 4, 4]               0\n",
      "          Conv2d-327             [-1, 48, 4, 4]          10,368\n",
      "     BatchNorm2d-328             [-1, 48, 4, 4]              96\n",
      "            ReLU-329             [-1, 48, 4, 4]               0\n",
      "          Conv2d-330             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-331            [-1, 228, 4, 4]               0\n",
      "     BatchNorm2d-332            [-1, 228, 4, 4]             456\n",
      "            ReLU-333            [-1, 228, 4, 4]               0\n",
      "          Conv2d-334             [-1, 48, 4, 4]          10,944\n",
      "     BatchNorm2d-335             [-1, 48, 4, 4]              96\n",
      "            ReLU-336             [-1, 48, 4, 4]               0\n",
      "          Conv2d-337             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-338            [-1, 240, 4, 4]               0\n",
      "     BatchNorm2d-339            [-1, 240, 4, 4]             480\n",
      "            ReLU-340            [-1, 240, 4, 4]               0\n",
      "          Conv2d-341             [-1, 48, 4, 4]          11,520\n",
      "     BatchNorm2d-342             [-1, 48, 4, 4]              96\n",
      "            ReLU-343             [-1, 48, 4, 4]               0\n",
      "          Conv2d-344             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-345            [-1, 252, 4, 4]               0\n",
      "     BatchNorm2d-346            [-1, 252, 4, 4]             504\n",
      "            ReLU-347            [-1, 252, 4, 4]               0\n",
      "          Conv2d-348             [-1, 48, 4, 4]          12,096\n",
      "     BatchNorm2d-349             [-1, 48, 4, 4]              96\n",
      "            ReLU-350             [-1, 48, 4, 4]               0\n",
      "          Conv2d-351             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-352            [-1, 264, 4, 4]               0\n",
      "     BatchNorm2d-353            [-1, 264, 4, 4]             528\n",
      "            ReLU-354            [-1, 264, 4, 4]               0\n",
      "          Conv2d-355             [-1, 48, 4, 4]          12,672\n",
      "     BatchNorm2d-356             [-1, 48, 4, 4]              96\n",
      "            ReLU-357             [-1, 48, 4, 4]               0\n",
      "          Conv2d-358             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-359            [-1, 276, 4, 4]               0\n",
      "     BatchNorm2d-360            [-1, 276, 4, 4]             552\n",
      "            ReLU-361            [-1, 276, 4, 4]               0\n",
      "          Conv2d-362             [-1, 48, 4, 4]          13,248\n",
      "     BatchNorm2d-363             [-1, 48, 4, 4]              96\n",
      "            ReLU-364             [-1, 48, 4, 4]               0\n",
      "          Conv2d-365             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-366            [-1, 288, 4, 4]               0\n",
      "     BatchNorm2d-367            [-1, 288, 4, 4]             576\n",
      "            ReLU-368            [-1, 288, 4, 4]               0\n",
      "          Conv2d-369             [-1, 48, 4, 4]          13,824\n",
      "     BatchNorm2d-370             [-1, 48, 4, 4]              96\n",
      "            ReLU-371             [-1, 48, 4, 4]               0\n",
      "          Conv2d-372             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-373            [-1, 300, 4, 4]               0\n",
      "     BatchNorm2d-374            [-1, 300, 4, 4]             600\n",
      "            ReLU-375            [-1, 300, 4, 4]               0\n",
      "          Conv2d-376             [-1, 48, 4, 4]          14,400\n",
      "     BatchNorm2d-377             [-1, 48, 4, 4]              96\n",
      "            ReLU-378             [-1, 48, 4, 4]               0\n",
      "          Conv2d-379             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-380            [-1, 312, 4, 4]               0\n",
      "     BatchNorm2d-381            [-1, 312, 4, 4]             624\n",
      "            ReLU-382            [-1, 312, 4, 4]               0\n",
      "          Conv2d-383             [-1, 48, 4, 4]          14,976\n",
      "     BatchNorm2d-384             [-1, 48, 4, 4]              96\n",
      "            ReLU-385             [-1, 48, 4, 4]               0\n",
      "          Conv2d-386             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-387            [-1, 324, 4, 4]               0\n",
      "     BatchNorm2d-388            [-1, 324, 4, 4]             648\n",
      "            ReLU-389            [-1, 324, 4, 4]               0\n",
      "          Conv2d-390             [-1, 48, 4, 4]          15,552\n",
      "     BatchNorm2d-391             [-1, 48, 4, 4]              96\n",
      "            ReLU-392             [-1, 48, 4, 4]               0\n",
      "          Conv2d-393             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-394            [-1, 336, 4, 4]               0\n",
      "     BatchNorm2d-395            [-1, 336, 4, 4]             672\n",
      "            ReLU-396            [-1, 336, 4, 4]               0\n",
      "          Conv2d-397             [-1, 48, 4, 4]          16,128\n",
      "     BatchNorm2d-398             [-1, 48, 4, 4]              96\n",
      "            ReLU-399             [-1, 48, 4, 4]               0\n",
      "          Conv2d-400             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-401            [-1, 348, 4, 4]               0\n",
      "     BatchNorm2d-402            [-1, 348, 4, 4]             696\n",
      "            ReLU-403            [-1, 348, 4, 4]               0\n",
      "          Conv2d-404             [-1, 48, 4, 4]          16,704\n",
      "     BatchNorm2d-405             [-1, 48, 4, 4]              96\n",
      "            ReLU-406             [-1, 48, 4, 4]               0\n",
      "          Conv2d-407             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-408            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-409            [-1, 360, 4, 4]             720\n",
      "            ReLU-410            [-1, 360, 4, 4]               0\n",
      "          Conv2d-411             [-1, 48, 4, 4]          17,280\n",
      "     BatchNorm2d-412             [-1, 48, 4, 4]              96\n",
      "            ReLU-413             [-1, 48, 4, 4]               0\n",
      "          Conv2d-414             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-415            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-416            [-1, 372, 4, 4]             744\n",
      "            ReLU-417            [-1, 372, 4, 4]               0\n",
      "          Conv2d-418             [-1, 48, 4, 4]          17,856\n",
      "     BatchNorm2d-419             [-1, 48, 4, 4]              96\n",
      "            ReLU-420             [-1, 48, 4, 4]               0\n",
      "          Conv2d-421             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-422            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-423            [-1, 384, 4, 4]             768\n",
      "            ReLU-424            [-1, 384, 4, 4]               0\n",
      "       AvgPool2d-425            [-1, 384, 1, 1]               0\n",
      "          Linear-426                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 997,538\n",
      "Trainable params: 997,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 43.49\n",
      "Params size (MB): 3.81\n",
      "Estimated Total Size (MB): 47.31\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 132640896.0\n",
      "MACs: 66320448.0\n",
      "Parameters: 997538.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.6404 seconds\n",
      "TP: 56.00\n",
      "FN: 7.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 91.59%\n",
      "Se: 88.89%\n",
      "Sp: 95.45%\n",
      "MAcc: 92.17%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
      "             ReLU-34           [-1, 48, 32, 32]               0\n",
      "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-36           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
      "             ReLU-38           [-1, 84, 32, 32]               0\n",
      "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "             ReLU-41           [-1, 48, 32, 32]               0\n",
      "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-43           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
      "             ReLU-45           [-1, 96, 32, 32]               0\n",
      "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
      "        AvgPool2d-47           [-1, 48, 16, 16]               0\n",
      "       Transition-48           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 48, 16, 16]              96\n",
      "             ReLU-50           [-1, 48, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 60, 16, 16]             120\n",
      "             ReLU-57           [-1, 60, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 72, 16, 16]             144\n",
      "             ReLU-64           [-1, 72, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 84, 16, 16]             168\n",
      "             ReLU-71           [-1, 84, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 96, 16, 16]             192\n",
      "             ReLU-78           [-1, 96, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 108, 16, 16]             216\n",
      "             ReLU-85          [-1, 108, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 120, 16, 16]             240\n",
      "             ReLU-92          [-1, 120, 16, 16]               0\n",
      "           Conv2d-93           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-94           [-1, 48, 16, 16]              96\n",
      "             ReLU-95           [-1, 48, 16, 16]               0\n",
      "           Conv2d-96           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-97          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-98          [-1, 132, 16, 16]             264\n",
      "             ReLU-99          [-1, 132, 16, 16]               0\n",
      "          Conv2d-100           [-1, 48, 16, 16]           6,336\n",
      "     BatchNorm2d-101           [-1, 48, 16, 16]              96\n",
      "            ReLU-102           [-1, 48, 16, 16]               0\n",
      "          Conv2d-103           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-104          [-1, 144, 16, 16]               0\n",
      "     BatchNorm2d-105          [-1, 144, 16, 16]             288\n",
      "            ReLU-106          [-1, 144, 16, 16]               0\n",
      "          Conv2d-107           [-1, 48, 16, 16]           6,912\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "            ReLU-109           [-1, 48, 16, 16]               0\n",
      "          Conv2d-110           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-111          [-1, 156, 16, 16]               0\n",
      "     BatchNorm2d-112          [-1, 156, 16, 16]             312\n",
      "            ReLU-113          [-1, 156, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           7,488\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-118          [-1, 168, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 168, 16, 16]             336\n",
      "            ReLU-120          [-1, 168, 16, 16]               0\n",
      "          Conv2d-121           [-1, 48, 16, 16]           8,064\n",
      "     BatchNorm2d-122           [-1, 48, 16, 16]              96\n",
      "            ReLU-123           [-1, 48, 16, 16]               0\n",
      "          Conv2d-124           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-125          [-1, 180, 16, 16]               0\n",
      "     BatchNorm2d-126          [-1, 180, 16, 16]             360\n",
      "            ReLU-127          [-1, 180, 16, 16]               0\n",
      "          Conv2d-128           [-1, 48, 16, 16]           8,640\n",
      "     BatchNorm2d-129           [-1, 48, 16, 16]              96\n",
      "            ReLU-130           [-1, 48, 16, 16]               0\n",
      "          Conv2d-131           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-132          [-1, 192, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 192, 16, 16]             384\n",
      "            ReLU-134          [-1, 192, 16, 16]               0\n",
      "          Conv2d-135           [-1, 96, 16, 16]          18,432\n",
      "       AvgPool2d-136             [-1, 96, 8, 8]               0\n",
      "      Transition-137             [-1, 96, 8, 8]               0\n",
      "     BatchNorm2d-138             [-1, 96, 8, 8]             192\n",
      "            ReLU-139             [-1, 96, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           4,608\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 108, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 108, 8, 8]             216\n",
      "            ReLU-146            [-1, 108, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           5,184\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 120, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 120, 8, 8]             240\n",
      "            ReLU-153            [-1, 120, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           5,760\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 132, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 132, 8, 8]             264\n",
      "            ReLU-160            [-1, 132, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           6,336\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 144, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 144, 8, 8]             288\n",
      "            ReLU-167            [-1, 144, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           6,912\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 156, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 156, 8, 8]             312\n",
      "            ReLU-174            [-1, 156, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           7,488\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 168, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 168, 8, 8]             336\n",
      "            ReLU-181            [-1, 168, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           8,064\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 180, 8, 8]             360\n",
      "            ReLU-188            [-1, 180, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           8,640\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 192, 8, 8]             384\n",
      "            ReLU-195            [-1, 192, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           9,216\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 204, 8, 8]             408\n",
      "            ReLU-202            [-1, 204, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           9,792\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 216, 8, 8]             432\n",
      "            ReLU-209            [-1, 216, 8, 8]               0\n",
      "          Conv2d-210             [-1, 48, 8, 8]          10,368\n",
      "     BatchNorm2d-211             [-1, 48, 8, 8]              96\n",
      "            ReLU-212             [-1, 48, 8, 8]               0\n",
      "          Conv2d-213             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-214            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-215            [-1, 228, 8, 8]             456\n",
      "            ReLU-216            [-1, 228, 8, 8]               0\n",
      "          Conv2d-217             [-1, 48, 8, 8]          10,944\n",
      "     BatchNorm2d-218             [-1, 48, 8, 8]              96\n",
      "            ReLU-219             [-1, 48, 8, 8]               0\n",
      "          Conv2d-220             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-221            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-222            [-1, 240, 8, 8]             480\n",
      "            ReLU-223            [-1, 240, 8, 8]               0\n",
      "          Conv2d-224             [-1, 48, 8, 8]          11,520\n",
      "     BatchNorm2d-225             [-1, 48, 8, 8]              96\n",
      "            ReLU-226             [-1, 48, 8, 8]               0\n",
      "          Conv2d-227             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-228            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-229            [-1, 252, 8, 8]             504\n",
      "            ReLU-230            [-1, 252, 8, 8]               0\n",
      "          Conv2d-231             [-1, 48, 8, 8]          12,096\n",
      "     BatchNorm2d-232             [-1, 48, 8, 8]              96\n",
      "            ReLU-233             [-1, 48, 8, 8]               0\n",
      "          Conv2d-234             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-235            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-236            [-1, 264, 8, 8]             528\n",
      "            ReLU-237            [-1, 264, 8, 8]               0\n",
      "          Conv2d-238             [-1, 48, 8, 8]          12,672\n",
      "     BatchNorm2d-239             [-1, 48, 8, 8]              96\n",
      "            ReLU-240             [-1, 48, 8, 8]               0\n",
      "          Conv2d-241             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-242            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-243            [-1, 276, 8, 8]             552\n",
      "            ReLU-244            [-1, 276, 8, 8]               0\n",
      "          Conv2d-245             [-1, 48, 8, 8]          13,248\n",
      "     BatchNorm2d-246             [-1, 48, 8, 8]              96\n",
      "            ReLU-247             [-1, 48, 8, 8]               0\n",
      "          Conv2d-248             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-249            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-250            [-1, 288, 8, 8]             576\n",
      "            ReLU-251            [-1, 288, 8, 8]               0\n",
      "          Conv2d-252             [-1, 48, 8, 8]          13,824\n",
      "     BatchNorm2d-253             [-1, 48, 8, 8]              96\n",
      "            ReLU-254             [-1, 48, 8, 8]               0\n",
      "          Conv2d-255             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-256            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-257            [-1, 300, 8, 8]             600\n",
      "            ReLU-258            [-1, 300, 8, 8]               0\n",
      "          Conv2d-259             [-1, 48, 8, 8]          14,400\n",
      "     BatchNorm2d-260             [-1, 48, 8, 8]              96\n",
      "            ReLU-261             [-1, 48, 8, 8]               0\n",
      "          Conv2d-262             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-263            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-264            [-1, 312, 8, 8]             624\n",
      "            ReLU-265            [-1, 312, 8, 8]               0\n",
      "          Conv2d-266             [-1, 48, 8, 8]          14,976\n",
      "     BatchNorm2d-267             [-1, 48, 8, 8]              96\n",
      "            ReLU-268             [-1, 48, 8, 8]               0\n",
      "          Conv2d-269             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-270            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-271            [-1, 324, 8, 8]             648\n",
      "            ReLU-272            [-1, 324, 8, 8]               0\n",
      "          Conv2d-273             [-1, 48, 8, 8]          15,552\n",
      "     BatchNorm2d-274             [-1, 48, 8, 8]              96\n",
      "            ReLU-275             [-1, 48, 8, 8]               0\n",
      "          Conv2d-276             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-277            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-278            [-1, 336, 8, 8]             672\n",
      "            ReLU-279            [-1, 336, 8, 8]               0\n",
      "          Conv2d-280             [-1, 48, 8, 8]          16,128\n",
      "     BatchNorm2d-281             [-1, 48, 8, 8]              96\n",
      "            ReLU-282             [-1, 48, 8, 8]               0\n",
      "          Conv2d-283             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-284            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-285            [-1, 348, 8, 8]             696\n",
      "            ReLU-286            [-1, 348, 8, 8]               0\n",
      "          Conv2d-287             [-1, 48, 8, 8]          16,704\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-291            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 360, 8, 8]             720\n",
      "            ReLU-293            [-1, 360, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]          17,280\n",
      "     BatchNorm2d-295             [-1, 48, 8, 8]              96\n",
      "            ReLU-296             [-1, 48, 8, 8]               0\n",
      "          Conv2d-297             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-298            [-1, 372, 8, 8]               0\n",
      "     BatchNorm2d-299            [-1, 372, 8, 8]             744\n",
      "            ReLU-300            [-1, 372, 8, 8]               0\n",
      "          Conv2d-301             [-1, 48, 8, 8]          17,856\n",
      "     BatchNorm2d-302             [-1, 48, 8, 8]              96\n",
      "            ReLU-303             [-1, 48, 8, 8]               0\n",
      "          Conv2d-304             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-305            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-306            [-1, 384, 8, 8]             768\n",
      "            ReLU-307            [-1, 384, 8, 8]               0\n",
      "          Conv2d-308            [-1, 192, 8, 8]          73,728\n",
      "       AvgPool2d-309            [-1, 192, 4, 4]               0\n",
      "      Transition-310            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-311            [-1, 192, 4, 4]             384\n",
      "            ReLU-312            [-1, 192, 4, 4]               0\n",
      "          Conv2d-313             [-1, 48, 4, 4]           9,216\n",
      "     BatchNorm2d-314             [-1, 48, 4, 4]              96\n",
      "            ReLU-315             [-1, 48, 4, 4]               0\n",
      "          Conv2d-316             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-317            [-1, 204, 4, 4]               0\n",
      "     BatchNorm2d-318            [-1, 204, 4, 4]             408\n",
      "            ReLU-319            [-1, 204, 4, 4]               0\n",
      "          Conv2d-320             [-1, 48, 4, 4]           9,792\n",
      "     BatchNorm2d-321             [-1, 48, 4, 4]              96\n",
      "            ReLU-322             [-1, 48, 4, 4]               0\n",
      "          Conv2d-323             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-324            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-325            [-1, 216, 4, 4]             432\n",
      "            ReLU-326            [-1, 216, 4, 4]               0\n",
      "          Conv2d-327             [-1, 48, 4, 4]          10,368\n",
      "     BatchNorm2d-328             [-1, 48, 4, 4]              96\n",
      "            ReLU-329             [-1, 48, 4, 4]               0\n",
      "          Conv2d-330             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-331            [-1, 228, 4, 4]               0\n",
      "     BatchNorm2d-332            [-1, 228, 4, 4]             456\n",
      "            ReLU-333            [-1, 228, 4, 4]               0\n",
      "          Conv2d-334             [-1, 48, 4, 4]          10,944\n",
      "     BatchNorm2d-335             [-1, 48, 4, 4]              96\n",
      "            ReLU-336             [-1, 48, 4, 4]               0\n",
      "          Conv2d-337             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-338            [-1, 240, 4, 4]               0\n",
      "     BatchNorm2d-339            [-1, 240, 4, 4]             480\n",
      "            ReLU-340            [-1, 240, 4, 4]               0\n",
      "          Conv2d-341             [-1, 48, 4, 4]          11,520\n",
      "     BatchNorm2d-342             [-1, 48, 4, 4]              96\n",
      "            ReLU-343             [-1, 48, 4, 4]               0\n",
      "          Conv2d-344             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-345            [-1, 252, 4, 4]               0\n",
      "     BatchNorm2d-346            [-1, 252, 4, 4]             504\n",
      "            ReLU-347            [-1, 252, 4, 4]               0\n",
      "          Conv2d-348             [-1, 48, 4, 4]          12,096\n",
      "     BatchNorm2d-349             [-1, 48, 4, 4]              96\n",
      "            ReLU-350             [-1, 48, 4, 4]               0\n",
      "          Conv2d-351             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-352            [-1, 264, 4, 4]               0\n",
      "     BatchNorm2d-353            [-1, 264, 4, 4]             528\n",
      "            ReLU-354            [-1, 264, 4, 4]               0\n",
      "          Conv2d-355             [-1, 48, 4, 4]          12,672\n",
      "     BatchNorm2d-356             [-1, 48, 4, 4]              96\n",
      "            ReLU-357             [-1, 48, 4, 4]               0\n",
      "          Conv2d-358             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-359            [-1, 276, 4, 4]               0\n",
      "     BatchNorm2d-360            [-1, 276, 4, 4]             552\n",
      "            ReLU-361            [-1, 276, 4, 4]               0\n",
      "          Conv2d-362             [-1, 48, 4, 4]          13,248\n",
      "     BatchNorm2d-363             [-1, 48, 4, 4]              96\n",
      "            ReLU-364             [-1, 48, 4, 4]               0\n",
      "          Conv2d-365             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-366            [-1, 288, 4, 4]               0\n",
      "     BatchNorm2d-367            [-1, 288, 4, 4]             576\n",
      "            ReLU-368            [-1, 288, 4, 4]               0\n",
      "          Conv2d-369             [-1, 48, 4, 4]          13,824\n",
      "     BatchNorm2d-370             [-1, 48, 4, 4]              96\n",
      "            ReLU-371             [-1, 48, 4, 4]               0\n",
      "          Conv2d-372             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-373            [-1, 300, 4, 4]               0\n",
      "     BatchNorm2d-374            [-1, 300, 4, 4]             600\n",
      "            ReLU-375            [-1, 300, 4, 4]               0\n",
      "          Conv2d-376             [-1, 48, 4, 4]          14,400\n",
      "     BatchNorm2d-377             [-1, 48, 4, 4]              96\n",
      "            ReLU-378             [-1, 48, 4, 4]               0\n",
      "          Conv2d-379             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-380            [-1, 312, 4, 4]               0\n",
      "     BatchNorm2d-381            [-1, 312, 4, 4]             624\n",
      "            ReLU-382            [-1, 312, 4, 4]               0\n",
      "          Conv2d-383             [-1, 48, 4, 4]          14,976\n",
      "     BatchNorm2d-384             [-1, 48, 4, 4]              96\n",
      "            ReLU-385             [-1, 48, 4, 4]               0\n",
      "          Conv2d-386             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-387            [-1, 324, 4, 4]               0\n",
      "     BatchNorm2d-388            [-1, 324, 4, 4]             648\n",
      "            ReLU-389            [-1, 324, 4, 4]               0\n",
      "          Conv2d-390             [-1, 48, 4, 4]          15,552\n",
      "     BatchNorm2d-391             [-1, 48, 4, 4]              96\n",
      "            ReLU-392             [-1, 48, 4, 4]               0\n",
      "          Conv2d-393             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-394            [-1, 336, 4, 4]               0\n",
      "     BatchNorm2d-395            [-1, 336, 4, 4]             672\n",
      "            ReLU-396            [-1, 336, 4, 4]               0\n",
      "          Conv2d-397             [-1, 48, 4, 4]          16,128\n",
      "     BatchNorm2d-398             [-1, 48, 4, 4]              96\n",
      "            ReLU-399             [-1, 48, 4, 4]               0\n",
      "          Conv2d-400             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-401            [-1, 348, 4, 4]               0\n",
      "     BatchNorm2d-402            [-1, 348, 4, 4]             696\n",
      "            ReLU-403            [-1, 348, 4, 4]               0\n",
      "          Conv2d-404             [-1, 48, 4, 4]          16,704\n",
      "     BatchNorm2d-405             [-1, 48, 4, 4]              96\n",
      "            ReLU-406             [-1, 48, 4, 4]               0\n",
      "          Conv2d-407             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-408            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-409            [-1, 360, 4, 4]             720\n",
      "            ReLU-410            [-1, 360, 4, 4]               0\n",
      "          Conv2d-411             [-1, 48, 4, 4]          17,280\n",
      "     BatchNorm2d-412             [-1, 48, 4, 4]              96\n",
      "            ReLU-413             [-1, 48, 4, 4]               0\n",
      "          Conv2d-414             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-415            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-416            [-1, 372, 4, 4]             744\n",
      "            ReLU-417            [-1, 372, 4, 4]               0\n",
      "          Conv2d-418             [-1, 48, 4, 4]          17,856\n",
      "     BatchNorm2d-419             [-1, 48, 4, 4]              96\n",
      "            ReLU-420             [-1, 48, 4, 4]               0\n",
      "          Conv2d-421             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-422            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-423            [-1, 384, 4, 4]             768\n",
      "            ReLU-424            [-1, 384, 4, 4]               0\n",
      "       AvgPool2d-425            [-1, 384, 1, 1]               0\n",
      "          Linear-426                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 997,538\n",
      "Trainable params: 997,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 43.49\n",
      "Params size (MB): 3.81\n",
      "Estimated Total Size (MB): 47.31\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 132640896.0\n",
      "MACs: 66320448.0\n",
      "Parameters: 997538.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.6323 seconds\n",
      "TP: 59.00\n",
      "FN: 4.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 94.39%\n",
      "Se: 93.65%\n",
      "Sp: 95.45%\n",
      "MAcc: 94.55%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No augment and bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 12, 32, 32]           2,592\n",
      "  SimpleDenseLayer-5           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-6           [-1, 36, 32, 32]              72\n",
      "              ReLU-7           [-1, 36, 32, 32]               0\n",
      "            Conv2d-8           [-1, 12, 32, 32]           3,888\n",
      "  SimpleDenseLayer-9           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-10           [-1, 48, 32, 32]              96\n",
      "             ReLU-11           [-1, 48, 32, 32]               0\n",
      "           Conv2d-12           [-1, 12, 32, 32]           5,184\n",
      " SimpleDenseLayer-13           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-14           [-1, 60, 32, 32]             120\n",
      "             ReLU-15           [-1, 60, 32, 32]               0\n",
      "           Conv2d-16           [-1, 12, 32, 32]           6,480\n",
      " SimpleDenseLayer-17           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 72, 32, 32]             144\n",
      "             ReLU-19           [-1, 72, 32, 32]               0\n",
      "           Conv2d-20           [-1, 12, 32, 32]           7,776\n",
      " SimpleDenseLayer-21           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-22           [-1, 84, 32, 32]             168\n",
      "             ReLU-23           [-1, 84, 32, 32]               0\n",
      "           Conv2d-24           [-1, 12, 32, 32]           9,072\n",
      " SimpleDenseLayer-25           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-26           [-1, 96, 32, 32]             192\n",
      "             ReLU-27           [-1, 96, 32, 32]               0\n",
      "           Conv2d-28           [-1, 48, 32, 32]           4,608\n",
      "        AvgPool2d-29           [-1, 48, 16, 16]               0\n",
      "       Transition-30           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-31           [-1, 48, 16, 16]              96\n",
      "             ReLU-32           [-1, 48, 16, 16]               0\n",
      "           Conv2d-33           [-1, 12, 16, 16]           5,184\n",
      " SimpleDenseLayer-34           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 60, 16, 16]             120\n",
      "             ReLU-36           [-1, 60, 16, 16]               0\n",
      "           Conv2d-37           [-1, 12, 16, 16]           6,480\n",
      " SimpleDenseLayer-38           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-39           [-1, 72, 16, 16]             144\n",
      "             ReLU-40           [-1, 72, 16, 16]               0\n",
      "           Conv2d-41           [-1, 12, 16, 16]           7,776\n",
      " SimpleDenseLayer-42           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-43           [-1, 84, 16, 16]             168\n",
      "             ReLU-44           [-1, 84, 16, 16]               0\n",
      "           Conv2d-45           [-1, 12, 16, 16]           9,072\n",
      " SimpleDenseLayer-46           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-47           [-1, 96, 16, 16]             192\n",
      "             ReLU-48           [-1, 96, 16, 16]               0\n",
      "           Conv2d-49           [-1, 12, 16, 16]          10,368\n",
      " SimpleDenseLayer-50          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-51          [-1, 108, 16, 16]             216\n",
      "             ReLU-52          [-1, 108, 16, 16]               0\n",
      "           Conv2d-53           [-1, 12, 16, 16]          11,664\n",
      " SimpleDenseLayer-54          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-55          [-1, 120, 16, 16]             240\n",
      "             ReLU-56          [-1, 120, 16, 16]               0\n",
      "           Conv2d-57           [-1, 12, 16, 16]          12,960\n",
      " SimpleDenseLayer-58          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-59          [-1, 132, 16, 16]             264\n",
      "             ReLU-60          [-1, 132, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]          14,256\n",
      " SimpleDenseLayer-62          [-1, 144, 16, 16]               0\n",
      "      BatchNorm2d-63          [-1, 144, 16, 16]             288\n",
      "             ReLU-64          [-1, 144, 16, 16]               0\n",
      "           Conv2d-65           [-1, 12, 16, 16]          15,552\n",
      " SimpleDenseLayer-66          [-1, 156, 16, 16]               0\n",
      "      BatchNorm2d-67          [-1, 156, 16, 16]             312\n",
      "             ReLU-68          [-1, 156, 16, 16]               0\n",
      "           Conv2d-69           [-1, 12, 16, 16]          16,848\n",
      " SimpleDenseLayer-70          [-1, 168, 16, 16]               0\n",
      "      BatchNorm2d-71          [-1, 168, 16, 16]             336\n",
      "             ReLU-72          [-1, 168, 16, 16]               0\n",
      "           Conv2d-73           [-1, 12, 16, 16]          18,144\n",
      " SimpleDenseLayer-74          [-1, 180, 16, 16]               0\n",
      "      BatchNorm2d-75          [-1, 180, 16, 16]             360\n",
      "             ReLU-76          [-1, 180, 16, 16]               0\n",
      "           Conv2d-77           [-1, 12, 16, 16]          19,440\n",
      " SimpleDenseLayer-78          [-1, 192, 16, 16]               0\n",
      "      BatchNorm2d-79          [-1, 192, 16, 16]             384\n",
      "             ReLU-80          [-1, 192, 16, 16]               0\n",
      "           Conv2d-81           [-1, 96, 16, 16]          18,432\n",
      "        AvgPool2d-82             [-1, 96, 8, 8]               0\n",
      "       Transition-83             [-1, 96, 8, 8]               0\n",
      "      BatchNorm2d-84             [-1, 96, 8, 8]             192\n",
      "             ReLU-85             [-1, 96, 8, 8]               0\n",
      "           Conv2d-86             [-1, 12, 8, 8]          10,368\n",
      " SimpleDenseLayer-87            [-1, 108, 8, 8]               0\n",
      "      BatchNorm2d-88            [-1, 108, 8, 8]             216\n",
      "             ReLU-89            [-1, 108, 8, 8]               0\n",
      "           Conv2d-90             [-1, 12, 8, 8]          11,664\n",
      " SimpleDenseLayer-91            [-1, 120, 8, 8]               0\n",
      "      BatchNorm2d-92            [-1, 120, 8, 8]             240\n",
      "             ReLU-93            [-1, 120, 8, 8]               0\n",
      "           Conv2d-94             [-1, 12, 8, 8]          12,960\n",
      " SimpleDenseLayer-95            [-1, 132, 8, 8]               0\n",
      "      BatchNorm2d-96            [-1, 132, 8, 8]             264\n",
      "             ReLU-97            [-1, 132, 8, 8]               0\n",
      "           Conv2d-98             [-1, 12, 8, 8]          14,256\n",
      " SimpleDenseLayer-99            [-1, 144, 8, 8]               0\n",
      "     BatchNorm2d-100            [-1, 144, 8, 8]             288\n",
      "            ReLU-101            [-1, 144, 8, 8]               0\n",
      "          Conv2d-102             [-1, 12, 8, 8]          15,552\n",
      "SimpleDenseLayer-103            [-1, 156, 8, 8]               0\n",
      "     BatchNorm2d-104            [-1, 156, 8, 8]             312\n",
      "            ReLU-105            [-1, 156, 8, 8]               0\n",
      "          Conv2d-106             [-1, 12, 8, 8]          16,848\n",
      "SimpleDenseLayer-107            [-1, 168, 8, 8]               0\n",
      "     BatchNorm2d-108            [-1, 168, 8, 8]             336\n",
      "            ReLU-109            [-1, 168, 8, 8]               0\n",
      "          Conv2d-110             [-1, 12, 8, 8]          18,144\n",
      "SimpleDenseLayer-111            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-112            [-1, 180, 8, 8]             360\n",
      "            ReLU-113            [-1, 180, 8, 8]               0\n",
      "          Conv2d-114             [-1, 12, 8, 8]          19,440\n",
      "SimpleDenseLayer-115            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-116            [-1, 192, 8, 8]             384\n",
      "            ReLU-117            [-1, 192, 8, 8]               0\n",
      "          Conv2d-118             [-1, 12, 8, 8]          20,736\n",
      "SimpleDenseLayer-119            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-120            [-1, 204, 8, 8]             408\n",
      "            ReLU-121            [-1, 204, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]          22,032\n",
      "SimpleDenseLayer-123            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 216, 8, 8]             432\n",
      "            ReLU-125            [-1, 216, 8, 8]               0\n",
      "          Conv2d-126             [-1, 12, 8, 8]          23,328\n",
      "SimpleDenseLayer-127            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-128            [-1, 228, 8, 8]             456\n",
      "            ReLU-129            [-1, 228, 8, 8]               0\n",
      "          Conv2d-130             [-1, 12, 8, 8]          24,624\n",
      "SimpleDenseLayer-131            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-132            [-1, 240, 8, 8]             480\n",
      "            ReLU-133            [-1, 240, 8, 8]               0\n",
      "          Conv2d-134             [-1, 12, 8, 8]          25,920\n",
      "SimpleDenseLayer-135            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-136            [-1, 252, 8, 8]             504\n",
      "            ReLU-137            [-1, 252, 8, 8]               0\n",
      "          Conv2d-138             [-1, 12, 8, 8]          27,216\n",
      "SimpleDenseLayer-139            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-140            [-1, 264, 8, 8]             528\n",
      "            ReLU-141            [-1, 264, 8, 8]               0\n",
      "          Conv2d-142             [-1, 12, 8, 8]          28,512\n",
      "SimpleDenseLayer-143            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-144            [-1, 276, 8, 8]             552\n",
      "            ReLU-145            [-1, 276, 8, 8]               0\n",
      "          Conv2d-146             [-1, 12, 8, 8]          29,808\n",
      "SimpleDenseLayer-147            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-148            [-1, 288, 8, 8]             576\n",
      "            ReLU-149            [-1, 288, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]          31,104\n",
      "SimpleDenseLayer-151            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 300, 8, 8]             600\n",
      "            ReLU-153            [-1, 300, 8, 8]               0\n",
      "          Conv2d-154             [-1, 12, 8, 8]          32,400\n",
      "SimpleDenseLayer-155            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-156            [-1, 312, 8, 8]             624\n",
      "            ReLU-157            [-1, 312, 8, 8]               0\n",
      "          Conv2d-158             [-1, 12, 8, 8]          33,696\n",
      "SimpleDenseLayer-159            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-160            [-1, 324, 8, 8]             648\n",
      "            ReLU-161            [-1, 324, 8, 8]               0\n",
      "          Conv2d-162             [-1, 12, 8, 8]          34,992\n",
      "SimpleDenseLayer-163            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-164            [-1, 336, 8, 8]             672\n",
      "            ReLU-165            [-1, 336, 8, 8]               0\n",
      "          Conv2d-166             [-1, 12, 8, 8]          36,288\n",
      "SimpleDenseLayer-167            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-168            [-1, 348, 8, 8]             696\n",
      "            ReLU-169            [-1, 348, 8, 8]               0\n",
      "          Conv2d-170             [-1, 12, 8, 8]          37,584\n",
      "SimpleDenseLayer-171            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-172            [-1, 360, 8, 8]             720\n",
      "            ReLU-173            [-1, 360, 8, 8]               0\n",
      "          Conv2d-174             [-1, 12, 8, 8]          38,880\n",
      "SimpleDenseLayer-175            [-1, 372, 8, 8]               0\n",
      "     BatchNorm2d-176            [-1, 372, 8, 8]             744\n",
      "            ReLU-177            [-1, 372, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]          40,176\n",
      "SimpleDenseLayer-179            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 384, 8, 8]             768\n",
      "            ReLU-181            [-1, 384, 8, 8]               0\n",
      "          Conv2d-182            [-1, 192, 8, 8]          73,728\n",
      "       AvgPool2d-183            [-1, 192, 4, 4]               0\n",
      "      Transition-184            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-185            [-1, 192, 4, 4]             384\n",
      "            ReLU-186            [-1, 192, 4, 4]               0\n",
      "          Conv2d-187             [-1, 12, 4, 4]          20,736\n",
      "SimpleDenseLayer-188            [-1, 204, 4, 4]               0\n",
      "     BatchNorm2d-189            [-1, 204, 4, 4]             408\n",
      "            ReLU-190            [-1, 204, 4, 4]               0\n",
      "          Conv2d-191             [-1, 12, 4, 4]          22,032\n",
      "SimpleDenseLayer-192            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-193            [-1, 216, 4, 4]             432\n",
      "            ReLU-194            [-1, 216, 4, 4]               0\n",
      "          Conv2d-195             [-1, 12, 4, 4]          23,328\n",
      "SimpleDenseLayer-196            [-1, 228, 4, 4]               0\n",
      "     BatchNorm2d-197            [-1, 228, 4, 4]             456\n",
      "            ReLU-198            [-1, 228, 4, 4]               0\n",
      "          Conv2d-199             [-1, 12, 4, 4]          24,624\n",
      "SimpleDenseLayer-200            [-1, 240, 4, 4]               0\n",
      "     BatchNorm2d-201            [-1, 240, 4, 4]             480\n",
      "            ReLU-202            [-1, 240, 4, 4]               0\n",
      "          Conv2d-203             [-1, 12, 4, 4]          25,920\n",
      "SimpleDenseLayer-204            [-1, 252, 4, 4]               0\n",
      "     BatchNorm2d-205            [-1, 252, 4, 4]             504\n",
      "            ReLU-206            [-1, 252, 4, 4]               0\n",
      "          Conv2d-207             [-1, 12, 4, 4]          27,216\n",
      "SimpleDenseLayer-208            [-1, 264, 4, 4]               0\n",
      "     BatchNorm2d-209            [-1, 264, 4, 4]             528\n",
      "            ReLU-210            [-1, 264, 4, 4]               0\n",
      "          Conv2d-211             [-1, 12, 4, 4]          28,512\n",
      "SimpleDenseLayer-212            [-1, 276, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 276, 4, 4]             552\n",
      "            ReLU-214            [-1, 276, 4, 4]               0\n",
      "          Conv2d-215             [-1, 12, 4, 4]          29,808\n",
      "SimpleDenseLayer-216            [-1, 288, 4, 4]               0\n",
      "     BatchNorm2d-217            [-1, 288, 4, 4]             576\n",
      "            ReLU-218            [-1, 288, 4, 4]               0\n",
      "          Conv2d-219             [-1, 12, 4, 4]          31,104\n",
      "SimpleDenseLayer-220            [-1, 300, 4, 4]               0\n",
      "     BatchNorm2d-221            [-1, 300, 4, 4]             600\n",
      "            ReLU-222            [-1, 300, 4, 4]               0\n",
      "          Conv2d-223             [-1, 12, 4, 4]          32,400\n",
      "SimpleDenseLayer-224            [-1, 312, 4, 4]               0\n",
      "     BatchNorm2d-225            [-1, 312, 4, 4]             624\n",
      "            ReLU-226            [-1, 312, 4, 4]               0\n",
      "          Conv2d-227             [-1, 12, 4, 4]          33,696\n",
      "SimpleDenseLayer-228            [-1, 324, 4, 4]               0\n",
      "     BatchNorm2d-229            [-1, 324, 4, 4]             648\n",
      "            ReLU-230            [-1, 324, 4, 4]               0\n",
      "          Conv2d-231             [-1, 12, 4, 4]          34,992\n",
      "SimpleDenseLayer-232            [-1, 336, 4, 4]               0\n",
      "     BatchNorm2d-233            [-1, 336, 4, 4]             672\n",
      "            ReLU-234            [-1, 336, 4, 4]               0\n",
      "          Conv2d-235             [-1, 12, 4, 4]          36,288\n",
      "SimpleDenseLayer-236            [-1, 348, 4, 4]               0\n",
      "     BatchNorm2d-237            [-1, 348, 4, 4]             696\n",
      "            ReLU-238            [-1, 348, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]          37,584\n",
      "SimpleDenseLayer-240            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 360, 4, 4]             720\n",
      "            ReLU-242            [-1, 360, 4, 4]               0\n",
      "          Conv2d-243             [-1, 12, 4, 4]          38,880\n",
      "SimpleDenseLayer-244            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-245            [-1, 372, 4, 4]             744\n",
      "            ReLU-246            [-1, 372, 4, 4]               0\n",
      "          Conv2d-247             [-1, 12, 4, 4]          40,176\n",
      "SimpleDenseLayer-248            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-249            [-1, 384, 4, 4]             768\n",
      "            ReLU-250            [-1, 384, 4, 4]               0\n",
      "       AvgPool2d-251            [-1, 384, 1, 1]               0\n",
      "          Linear-252                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 1,400,498\n",
      "Trainable params: 1,400,498\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 31.40\n",
      "Params size (MB): 5.34\n",
      "Estimated Total Size (MB): 36.75\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 140277888.0\n",
      "MACs: 70138944.0\n",
      "Parameters: 1400498.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.7705 seconds\n",
      "TP: 58.00\n",
      "FN: 5.00\n",
      "TN: 43.00\n",
      "FP: 1.00\n",
      "Acc: 94.39%\n",
      "Se: 92.06%\n",
      "Sp: 97.73%\n",
      "MAcc: 94.90%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1.pth'\\\n",
    "--no_augment \\\n",
    "--no_bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 12, 32, 32]           2,592\n",
      "  SimpleDenseLayer-5           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-6           [-1, 36, 32, 32]              72\n",
      "              ReLU-7           [-1, 36, 32, 32]               0\n",
      "            Conv2d-8           [-1, 12, 32, 32]           3,888\n",
      "  SimpleDenseLayer-9           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-10           [-1, 48, 32, 32]              96\n",
      "             ReLU-11           [-1, 48, 32, 32]               0\n",
      "           Conv2d-12           [-1, 12, 32, 32]           5,184\n",
      " SimpleDenseLayer-13           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-14           [-1, 60, 32, 32]             120\n",
      "             ReLU-15           [-1, 60, 32, 32]               0\n",
      "           Conv2d-16           [-1, 12, 32, 32]           6,480\n",
      " SimpleDenseLayer-17           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 72, 32, 32]             144\n",
      "             ReLU-19           [-1, 72, 32, 32]               0\n",
      "           Conv2d-20           [-1, 12, 32, 32]           7,776\n",
      " SimpleDenseLayer-21           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-22           [-1, 84, 32, 32]             168\n",
      "             ReLU-23           [-1, 84, 32, 32]               0\n",
      "           Conv2d-24           [-1, 12, 32, 32]           9,072\n",
      " SimpleDenseLayer-25           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-26           [-1, 96, 32, 32]             192\n",
      "             ReLU-27           [-1, 96, 32, 32]               0\n",
      "           Conv2d-28           [-1, 48, 32, 32]           4,608\n",
      "        AvgPool2d-29           [-1, 48, 16, 16]               0\n",
      "       Transition-30           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-31           [-1, 48, 16, 16]              96\n",
      "             ReLU-32           [-1, 48, 16, 16]               0\n",
      "           Conv2d-33           [-1, 12, 16, 16]           5,184\n",
      " SimpleDenseLayer-34           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 60, 16, 16]             120\n",
      "             ReLU-36           [-1, 60, 16, 16]               0\n",
      "           Conv2d-37           [-1, 12, 16, 16]           6,480\n",
      " SimpleDenseLayer-38           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-39           [-1, 72, 16, 16]             144\n",
      "             ReLU-40           [-1, 72, 16, 16]               0\n",
      "           Conv2d-41           [-1, 12, 16, 16]           7,776\n",
      " SimpleDenseLayer-42           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-43           [-1, 84, 16, 16]             168\n",
      "             ReLU-44           [-1, 84, 16, 16]               0\n",
      "           Conv2d-45           [-1, 12, 16, 16]           9,072\n",
      " SimpleDenseLayer-46           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-47           [-1, 96, 16, 16]             192\n",
      "             ReLU-48           [-1, 96, 16, 16]               0\n",
      "           Conv2d-49           [-1, 12, 16, 16]          10,368\n",
      " SimpleDenseLayer-50          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-51          [-1, 108, 16, 16]             216\n",
      "             ReLU-52          [-1, 108, 16, 16]               0\n",
      "           Conv2d-53           [-1, 12, 16, 16]          11,664\n",
      " SimpleDenseLayer-54          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-55          [-1, 120, 16, 16]             240\n",
      "             ReLU-56          [-1, 120, 16, 16]               0\n",
      "           Conv2d-57           [-1, 12, 16, 16]          12,960\n",
      " SimpleDenseLayer-58          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-59          [-1, 132, 16, 16]             264\n",
      "             ReLU-60          [-1, 132, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]          14,256\n",
      " SimpleDenseLayer-62          [-1, 144, 16, 16]               0\n",
      "      BatchNorm2d-63          [-1, 144, 16, 16]             288\n",
      "             ReLU-64          [-1, 144, 16, 16]               0\n",
      "           Conv2d-65           [-1, 12, 16, 16]          15,552\n",
      " SimpleDenseLayer-66          [-1, 156, 16, 16]               0\n",
      "      BatchNorm2d-67          [-1, 156, 16, 16]             312\n",
      "             ReLU-68          [-1, 156, 16, 16]               0\n",
      "           Conv2d-69           [-1, 12, 16, 16]          16,848\n",
      " SimpleDenseLayer-70          [-1, 168, 16, 16]               0\n",
      "      BatchNorm2d-71          [-1, 168, 16, 16]             336\n",
      "             ReLU-72          [-1, 168, 16, 16]               0\n",
      "           Conv2d-73           [-1, 12, 16, 16]          18,144\n",
      " SimpleDenseLayer-74          [-1, 180, 16, 16]               0\n",
      "      BatchNorm2d-75          [-1, 180, 16, 16]             360\n",
      "             ReLU-76          [-1, 180, 16, 16]               0\n",
      "           Conv2d-77           [-1, 12, 16, 16]          19,440\n",
      " SimpleDenseLayer-78          [-1, 192, 16, 16]               0\n",
      "      BatchNorm2d-79          [-1, 192, 16, 16]             384\n",
      "             ReLU-80          [-1, 192, 16, 16]               0\n",
      "           Conv2d-81           [-1, 96, 16, 16]          18,432\n",
      "        AvgPool2d-82             [-1, 96, 8, 8]               0\n",
      "       Transition-83             [-1, 96, 8, 8]               0\n",
      "      BatchNorm2d-84             [-1, 96, 8, 8]             192\n",
      "             ReLU-85             [-1, 96, 8, 8]               0\n",
      "           Conv2d-86             [-1, 12, 8, 8]          10,368\n",
      " SimpleDenseLayer-87            [-1, 108, 8, 8]               0\n",
      "      BatchNorm2d-88            [-1, 108, 8, 8]             216\n",
      "             ReLU-89            [-1, 108, 8, 8]               0\n",
      "           Conv2d-90             [-1, 12, 8, 8]          11,664\n",
      " SimpleDenseLayer-91            [-1, 120, 8, 8]               0\n",
      "      BatchNorm2d-92            [-1, 120, 8, 8]             240\n",
      "             ReLU-93            [-1, 120, 8, 8]               0\n",
      "           Conv2d-94             [-1, 12, 8, 8]          12,960\n",
      " SimpleDenseLayer-95            [-1, 132, 8, 8]               0\n",
      "      BatchNorm2d-96            [-1, 132, 8, 8]             264\n",
      "             ReLU-97            [-1, 132, 8, 8]               0\n",
      "           Conv2d-98             [-1, 12, 8, 8]          14,256\n",
      " SimpleDenseLayer-99            [-1, 144, 8, 8]               0\n",
      "     BatchNorm2d-100            [-1, 144, 8, 8]             288\n",
      "            ReLU-101            [-1, 144, 8, 8]               0\n",
      "          Conv2d-102             [-1, 12, 8, 8]          15,552\n",
      "SimpleDenseLayer-103            [-1, 156, 8, 8]               0\n",
      "     BatchNorm2d-104            [-1, 156, 8, 8]             312\n",
      "            ReLU-105            [-1, 156, 8, 8]               0\n",
      "          Conv2d-106             [-1, 12, 8, 8]          16,848\n",
      "SimpleDenseLayer-107            [-1, 168, 8, 8]               0\n",
      "     BatchNorm2d-108            [-1, 168, 8, 8]             336\n",
      "            ReLU-109            [-1, 168, 8, 8]               0\n",
      "          Conv2d-110             [-1, 12, 8, 8]          18,144\n",
      "SimpleDenseLayer-111            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-112            [-1, 180, 8, 8]             360\n",
      "            ReLU-113            [-1, 180, 8, 8]               0\n",
      "          Conv2d-114             [-1, 12, 8, 8]          19,440\n",
      "SimpleDenseLayer-115            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-116            [-1, 192, 8, 8]             384\n",
      "            ReLU-117            [-1, 192, 8, 8]               0\n",
      "          Conv2d-118             [-1, 12, 8, 8]          20,736\n",
      "SimpleDenseLayer-119            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-120            [-1, 204, 8, 8]             408\n",
      "            ReLU-121            [-1, 204, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]          22,032\n",
      "SimpleDenseLayer-123            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 216, 8, 8]             432\n",
      "            ReLU-125            [-1, 216, 8, 8]               0\n",
      "          Conv2d-126             [-1, 12, 8, 8]          23,328\n",
      "SimpleDenseLayer-127            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-128            [-1, 228, 8, 8]             456\n",
      "            ReLU-129            [-1, 228, 8, 8]               0\n",
      "          Conv2d-130             [-1, 12, 8, 8]          24,624\n",
      "SimpleDenseLayer-131            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-132            [-1, 240, 8, 8]             480\n",
      "            ReLU-133            [-1, 240, 8, 8]               0\n",
      "          Conv2d-134             [-1, 12, 8, 8]          25,920\n",
      "SimpleDenseLayer-135            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-136            [-1, 252, 8, 8]             504\n",
      "            ReLU-137            [-1, 252, 8, 8]               0\n",
      "          Conv2d-138             [-1, 12, 8, 8]          27,216\n",
      "SimpleDenseLayer-139            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-140            [-1, 264, 8, 8]             528\n",
      "            ReLU-141            [-1, 264, 8, 8]               0\n",
      "          Conv2d-142             [-1, 12, 8, 8]          28,512\n",
      "SimpleDenseLayer-143            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-144            [-1, 276, 8, 8]             552\n",
      "            ReLU-145            [-1, 276, 8, 8]               0\n",
      "          Conv2d-146             [-1, 12, 8, 8]          29,808\n",
      "SimpleDenseLayer-147            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-148            [-1, 288, 8, 8]             576\n",
      "            ReLU-149            [-1, 288, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]          31,104\n",
      "SimpleDenseLayer-151            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 300, 8, 8]             600\n",
      "            ReLU-153            [-1, 300, 8, 8]               0\n",
      "          Conv2d-154             [-1, 12, 8, 8]          32,400\n",
      "SimpleDenseLayer-155            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-156            [-1, 312, 8, 8]             624\n",
      "            ReLU-157            [-1, 312, 8, 8]               0\n",
      "          Conv2d-158             [-1, 12, 8, 8]          33,696\n",
      "SimpleDenseLayer-159            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-160            [-1, 324, 8, 8]             648\n",
      "            ReLU-161            [-1, 324, 8, 8]               0\n",
      "          Conv2d-162             [-1, 12, 8, 8]          34,992\n",
      "SimpleDenseLayer-163            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-164            [-1, 336, 8, 8]             672\n",
      "            ReLU-165            [-1, 336, 8, 8]               0\n",
      "          Conv2d-166             [-1, 12, 8, 8]          36,288\n",
      "SimpleDenseLayer-167            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-168            [-1, 348, 8, 8]             696\n",
      "            ReLU-169            [-1, 348, 8, 8]               0\n",
      "          Conv2d-170             [-1, 12, 8, 8]          37,584\n",
      "SimpleDenseLayer-171            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-172            [-1, 360, 8, 8]             720\n",
      "            ReLU-173            [-1, 360, 8, 8]               0\n",
      "          Conv2d-174             [-1, 12, 8, 8]          38,880\n",
      "SimpleDenseLayer-175            [-1, 372, 8, 8]               0\n",
      "     BatchNorm2d-176            [-1, 372, 8, 8]             744\n",
      "            ReLU-177            [-1, 372, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]          40,176\n",
      "SimpleDenseLayer-179            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 384, 8, 8]             768\n",
      "            ReLU-181            [-1, 384, 8, 8]               0\n",
      "          Conv2d-182            [-1, 192, 8, 8]          73,728\n",
      "       AvgPool2d-183            [-1, 192, 4, 4]               0\n",
      "      Transition-184            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-185            [-1, 192, 4, 4]             384\n",
      "            ReLU-186            [-1, 192, 4, 4]               0\n",
      "          Conv2d-187             [-1, 12, 4, 4]          20,736\n",
      "SimpleDenseLayer-188            [-1, 204, 4, 4]               0\n",
      "     BatchNorm2d-189            [-1, 204, 4, 4]             408\n",
      "            ReLU-190            [-1, 204, 4, 4]               0\n",
      "          Conv2d-191             [-1, 12, 4, 4]          22,032\n",
      "SimpleDenseLayer-192            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-193            [-1, 216, 4, 4]             432\n",
      "            ReLU-194            [-1, 216, 4, 4]               0\n",
      "          Conv2d-195             [-1, 12, 4, 4]          23,328\n",
      "SimpleDenseLayer-196            [-1, 228, 4, 4]               0\n",
      "     BatchNorm2d-197            [-1, 228, 4, 4]             456\n",
      "            ReLU-198            [-1, 228, 4, 4]               0\n",
      "          Conv2d-199             [-1, 12, 4, 4]          24,624\n",
      "SimpleDenseLayer-200            [-1, 240, 4, 4]               0\n",
      "     BatchNorm2d-201            [-1, 240, 4, 4]             480\n",
      "            ReLU-202            [-1, 240, 4, 4]               0\n",
      "          Conv2d-203             [-1, 12, 4, 4]          25,920\n",
      "SimpleDenseLayer-204            [-1, 252, 4, 4]               0\n",
      "     BatchNorm2d-205            [-1, 252, 4, 4]             504\n",
      "            ReLU-206            [-1, 252, 4, 4]               0\n",
      "          Conv2d-207             [-1, 12, 4, 4]          27,216\n",
      "SimpleDenseLayer-208            [-1, 264, 4, 4]               0\n",
      "     BatchNorm2d-209            [-1, 264, 4, 4]             528\n",
      "            ReLU-210            [-1, 264, 4, 4]               0\n",
      "          Conv2d-211             [-1, 12, 4, 4]          28,512\n",
      "SimpleDenseLayer-212            [-1, 276, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 276, 4, 4]             552\n",
      "            ReLU-214            [-1, 276, 4, 4]               0\n",
      "          Conv2d-215             [-1, 12, 4, 4]          29,808\n",
      "SimpleDenseLayer-216            [-1, 288, 4, 4]               0\n",
      "     BatchNorm2d-217            [-1, 288, 4, 4]             576\n",
      "            ReLU-218            [-1, 288, 4, 4]               0\n",
      "          Conv2d-219             [-1, 12, 4, 4]          31,104\n",
      "SimpleDenseLayer-220            [-1, 300, 4, 4]               0\n",
      "     BatchNorm2d-221            [-1, 300, 4, 4]             600\n",
      "            ReLU-222            [-1, 300, 4, 4]               0\n",
      "          Conv2d-223             [-1, 12, 4, 4]          32,400\n",
      "SimpleDenseLayer-224            [-1, 312, 4, 4]               0\n",
      "     BatchNorm2d-225            [-1, 312, 4, 4]             624\n",
      "            ReLU-226            [-1, 312, 4, 4]               0\n",
      "          Conv2d-227             [-1, 12, 4, 4]          33,696\n",
      "SimpleDenseLayer-228            [-1, 324, 4, 4]               0\n",
      "     BatchNorm2d-229            [-1, 324, 4, 4]             648\n",
      "            ReLU-230            [-1, 324, 4, 4]               0\n",
      "          Conv2d-231             [-1, 12, 4, 4]          34,992\n",
      "SimpleDenseLayer-232            [-1, 336, 4, 4]               0\n",
      "     BatchNorm2d-233            [-1, 336, 4, 4]             672\n",
      "            ReLU-234            [-1, 336, 4, 4]               0\n",
      "          Conv2d-235             [-1, 12, 4, 4]          36,288\n",
      "SimpleDenseLayer-236            [-1, 348, 4, 4]               0\n",
      "     BatchNorm2d-237            [-1, 348, 4, 4]             696\n",
      "            ReLU-238            [-1, 348, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]          37,584\n",
      "SimpleDenseLayer-240            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 360, 4, 4]             720\n",
      "            ReLU-242            [-1, 360, 4, 4]               0\n",
      "          Conv2d-243             [-1, 12, 4, 4]          38,880\n",
      "SimpleDenseLayer-244            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-245            [-1, 372, 4, 4]             744\n",
      "            ReLU-246            [-1, 372, 4, 4]               0\n",
      "          Conv2d-247             [-1, 12, 4, 4]          40,176\n",
      "SimpleDenseLayer-248            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-249            [-1, 384, 4, 4]             768\n",
      "            ReLU-250            [-1, 384, 4, 4]               0\n",
      "       AvgPool2d-251            [-1, 384, 1, 1]               0\n",
      "          Linear-252                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 1,400,498\n",
      "Trainable params: 1,400,498\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 31.40\n",
      "Params size (MB): 5.34\n",
      "Estimated Total Size (MB): 36.75\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 140277888.0\n",
      "MACs: 70138944.0\n",
      "Parameters: 1400498.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.7803 seconds\n",
      "TP: 58.00\n",
      "FN: 5.00\n",
      "TN: 43.00\n",
      "FP: 1.00\n",
      "Acc: 94.39%\n",
      "Se: 92.06%\n",
      "Sp: 97.73%\n",
      "MAcc: 94.90%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_no_bottleneck.pth' \\\n",
    "--no_augment \\\n",
    "--no_bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No augment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
      "             ReLU-34           [-1, 48, 32, 32]               0\n",
      "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-36           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
      "             ReLU-38           [-1, 84, 32, 32]               0\n",
      "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "             ReLU-41           [-1, 48, 32, 32]               0\n",
      "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-43           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
      "             ReLU-45           [-1, 96, 32, 32]               0\n",
      "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
      "        AvgPool2d-47           [-1, 48, 16, 16]               0\n",
      "       Transition-48           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 48, 16, 16]              96\n",
      "             ReLU-50           [-1, 48, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 60, 16, 16]             120\n",
      "             ReLU-57           [-1, 60, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 72, 16, 16]             144\n",
      "             ReLU-64           [-1, 72, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 84, 16, 16]             168\n",
      "             ReLU-71           [-1, 84, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 96, 16, 16]             192\n",
      "             ReLU-78           [-1, 96, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 108, 16, 16]             216\n",
      "             ReLU-85          [-1, 108, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 120, 16, 16]             240\n",
      "             ReLU-92          [-1, 120, 16, 16]               0\n",
      "           Conv2d-93           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-94           [-1, 48, 16, 16]              96\n",
      "             ReLU-95           [-1, 48, 16, 16]               0\n",
      "           Conv2d-96           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-97          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-98          [-1, 132, 16, 16]             264\n",
      "             ReLU-99          [-1, 132, 16, 16]               0\n",
      "          Conv2d-100           [-1, 48, 16, 16]           6,336\n",
      "     BatchNorm2d-101           [-1, 48, 16, 16]              96\n",
      "            ReLU-102           [-1, 48, 16, 16]               0\n",
      "          Conv2d-103           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-104          [-1, 144, 16, 16]               0\n",
      "     BatchNorm2d-105          [-1, 144, 16, 16]             288\n",
      "            ReLU-106          [-1, 144, 16, 16]               0\n",
      "          Conv2d-107           [-1, 48, 16, 16]           6,912\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "            ReLU-109           [-1, 48, 16, 16]               0\n",
      "          Conv2d-110           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-111          [-1, 156, 16, 16]               0\n",
      "     BatchNorm2d-112          [-1, 156, 16, 16]             312\n",
      "            ReLU-113          [-1, 156, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           7,488\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-118          [-1, 168, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 168, 16, 16]             336\n",
      "            ReLU-120          [-1, 168, 16, 16]               0\n",
      "          Conv2d-121           [-1, 48, 16, 16]           8,064\n",
      "     BatchNorm2d-122           [-1, 48, 16, 16]              96\n",
      "            ReLU-123           [-1, 48, 16, 16]               0\n",
      "          Conv2d-124           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-125          [-1, 180, 16, 16]               0\n",
      "     BatchNorm2d-126          [-1, 180, 16, 16]             360\n",
      "            ReLU-127          [-1, 180, 16, 16]               0\n",
      "          Conv2d-128           [-1, 48, 16, 16]           8,640\n",
      "     BatchNorm2d-129           [-1, 48, 16, 16]              96\n",
      "            ReLU-130           [-1, 48, 16, 16]               0\n",
      "          Conv2d-131           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-132          [-1, 192, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 192, 16, 16]             384\n",
      "            ReLU-134          [-1, 192, 16, 16]               0\n",
      "          Conv2d-135           [-1, 96, 16, 16]          18,432\n",
      "       AvgPool2d-136             [-1, 96, 8, 8]               0\n",
      "      Transition-137             [-1, 96, 8, 8]               0\n",
      "     BatchNorm2d-138             [-1, 96, 8, 8]             192\n",
      "            ReLU-139             [-1, 96, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           4,608\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 108, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 108, 8, 8]             216\n",
      "            ReLU-146            [-1, 108, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           5,184\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 120, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 120, 8, 8]             240\n",
      "            ReLU-153            [-1, 120, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           5,760\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 132, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 132, 8, 8]             264\n",
      "            ReLU-160            [-1, 132, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           6,336\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 144, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 144, 8, 8]             288\n",
      "            ReLU-167            [-1, 144, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           6,912\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 156, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 156, 8, 8]             312\n",
      "            ReLU-174            [-1, 156, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           7,488\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 168, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 168, 8, 8]             336\n",
      "            ReLU-181            [-1, 168, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           8,064\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 180, 8, 8]             360\n",
      "            ReLU-188            [-1, 180, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           8,640\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 192, 8, 8]             384\n",
      "            ReLU-195            [-1, 192, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           9,216\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 204, 8, 8]             408\n",
      "            ReLU-202            [-1, 204, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           9,792\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 216, 8, 8]             432\n",
      "            ReLU-209            [-1, 216, 8, 8]               0\n",
      "          Conv2d-210             [-1, 48, 8, 8]          10,368\n",
      "     BatchNorm2d-211             [-1, 48, 8, 8]              96\n",
      "            ReLU-212             [-1, 48, 8, 8]               0\n",
      "          Conv2d-213             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-214            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-215            [-1, 228, 8, 8]             456\n",
      "            ReLU-216            [-1, 228, 8, 8]               0\n",
      "          Conv2d-217             [-1, 48, 8, 8]          10,944\n",
      "     BatchNorm2d-218             [-1, 48, 8, 8]              96\n",
      "            ReLU-219             [-1, 48, 8, 8]               0\n",
      "          Conv2d-220             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-221            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-222            [-1, 240, 8, 8]             480\n",
      "            ReLU-223            [-1, 240, 8, 8]               0\n",
      "          Conv2d-224             [-1, 48, 8, 8]          11,520\n",
      "     BatchNorm2d-225             [-1, 48, 8, 8]              96\n",
      "            ReLU-226             [-1, 48, 8, 8]               0\n",
      "          Conv2d-227             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-228            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-229            [-1, 252, 8, 8]             504\n",
      "            ReLU-230            [-1, 252, 8, 8]               0\n",
      "          Conv2d-231             [-1, 48, 8, 8]          12,096\n",
      "     BatchNorm2d-232             [-1, 48, 8, 8]              96\n",
      "            ReLU-233             [-1, 48, 8, 8]               0\n",
      "          Conv2d-234             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-235            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-236            [-1, 264, 8, 8]             528\n",
      "            ReLU-237            [-1, 264, 8, 8]               0\n",
      "          Conv2d-238             [-1, 48, 8, 8]          12,672\n",
      "     BatchNorm2d-239             [-1, 48, 8, 8]              96\n",
      "            ReLU-240             [-1, 48, 8, 8]               0\n",
      "          Conv2d-241             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-242            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-243            [-1, 276, 8, 8]             552\n",
      "            ReLU-244            [-1, 276, 8, 8]               0\n",
      "          Conv2d-245             [-1, 48, 8, 8]          13,248\n",
      "     BatchNorm2d-246             [-1, 48, 8, 8]              96\n",
      "            ReLU-247             [-1, 48, 8, 8]               0\n",
      "          Conv2d-248             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-249            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-250            [-1, 288, 8, 8]             576\n",
      "            ReLU-251            [-1, 288, 8, 8]               0\n",
      "          Conv2d-252             [-1, 48, 8, 8]          13,824\n",
      "     BatchNorm2d-253             [-1, 48, 8, 8]              96\n",
      "            ReLU-254             [-1, 48, 8, 8]               0\n",
      "          Conv2d-255             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-256            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-257            [-1, 300, 8, 8]             600\n",
      "            ReLU-258            [-1, 300, 8, 8]               0\n",
      "          Conv2d-259             [-1, 48, 8, 8]          14,400\n",
      "     BatchNorm2d-260             [-1, 48, 8, 8]              96\n",
      "            ReLU-261             [-1, 48, 8, 8]               0\n",
      "          Conv2d-262             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-263            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-264            [-1, 312, 8, 8]             624\n",
      "            ReLU-265            [-1, 312, 8, 8]               0\n",
      "          Conv2d-266             [-1, 48, 8, 8]          14,976\n",
      "     BatchNorm2d-267             [-1, 48, 8, 8]              96\n",
      "            ReLU-268             [-1, 48, 8, 8]               0\n",
      "          Conv2d-269             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-270            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-271            [-1, 324, 8, 8]             648\n",
      "            ReLU-272            [-1, 324, 8, 8]               0\n",
      "          Conv2d-273             [-1, 48, 8, 8]          15,552\n",
      "     BatchNorm2d-274             [-1, 48, 8, 8]              96\n",
      "            ReLU-275             [-1, 48, 8, 8]               0\n",
      "          Conv2d-276             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-277            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-278            [-1, 336, 8, 8]             672\n",
      "            ReLU-279            [-1, 336, 8, 8]               0\n",
      "          Conv2d-280             [-1, 48, 8, 8]          16,128\n",
      "     BatchNorm2d-281             [-1, 48, 8, 8]              96\n",
      "            ReLU-282             [-1, 48, 8, 8]               0\n",
      "          Conv2d-283             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-284            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-285            [-1, 348, 8, 8]             696\n",
      "            ReLU-286            [-1, 348, 8, 8]               0\n",
      "          Conv2d-287             [-1, 48, 8, 8]          16,704\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-291            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 360, 8, 8]             720\n",
      "            ReLU-293            [-1, 360, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]          17,280\n",
      "     BatchNorm2d-295             [-1, 48, 8, 8]              96\n",
      "            ReLU-296             [-1, 48, 8, 8]               0\n",
      "          Conv2d-297             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-298            [-1, 372, 8, 8]               0\n",
      "     BatchNorm2d-299            [-1, 372, 8, 8]             744\n",
      "            ReLU-300            [-1, 372, 8, 8]               0\n",
      "          Conv2d-301             [-1, 48, 8, 8]          17,856\n",
      "     BatchNorm2d-302             [-1, 48, 8, 8]              96\n",
      "            ReLU-303             [-1, 48, 8, 8]               0\n",
      "          Conv2d-304             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-305            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-306            [-1, 384, 8, 8]             768\n",
      "            ReLU-307            [-1, 384, 8, 8]               0\n",
      "          Conv2d-308            [-1, 192, 8, 8]          73,728\n",
      "       AvgPool2d-309            [-1, 192, 4, 4]               0\n",
      "      Transition-310            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-311            [-1, 192, 4, 4]             384\n",
      "            ReLU-312            [-1, 192, 4, 4]               0\n",
      "          Conv2d-313             [-1, 48, 4, 4]           9,216\n",
      "     BatchNorm2d-314             [-1, 48, 4, 4]              96\n",
      "            ReLU-315             [-1, 48, 4, 4]               0\n",
      "          Conv2d-316             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-317            [-1, 204, 4, 4]               0\n",
      "     BatchNorm2d-318            [-1, 204, 4, 4]             408\n",
      "            ReLU-319            [-1, 204, 4, 4]               0\n",
      "          Conv2d-320             [-1, 48, 4, 4]           9,792\n",
      "     BatchNorm2d-321             [-1, 48, 4, 4]              96\n",
      "            ReLU-322             [-1, 48, 4, 4]               0\n",
      "          Conv2d-323             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-324            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-325            [-1, 216, 4, 4]             432\n",
      "            ReLU-326            [-1, 216, 4, 4]               0\n",
      "          Conv2d-327             [-1, 48, 4, 4]          10,368\n",
      "     BatchNorm2d-328             [-1, 48, 4, 4]              96\n",
      "            ReLU-329             [-1, 48, 4, 4]               0\n",
      "          Conv2d-330             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-331            [-1, 228, 4, 4]               0\n",
      "     BatchNorm2d-332            [-1, 228, 4, 4]             456\n",
      "            ReLU-333            [-1, 228, 4, 4]               0\n",
      "          Conv2d-334             [-1, 48, 4, 4]          10,944\n",
      "     BatchNorm2d-335             [-1, 48, 4, 4]              96\n",
      "            ReLU-336             [-1, 48, 4, 4]               0\n",
      "          Conv2d-337             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-338            [-1, 240, 4, 4]               0\n",
      "     BatchNorm2d-339            [-1, 240, 4, 4]             480\n",
      "            ReLU-340            [-1, 240, 4, 4]               0\n",
      "          Conv2d-341             [-1, 48, 4, 4]          11,520\n",
      "     BatchNorm2d-342             [-1, 48, 4, 4]              96\n",
      "            ReLU-343             [-1, 48, 4, 4]               0\n",
      "          Conv2d-344             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-345            [-1, 252, 4, 4]               0\n",
      "     BatchNorm2d-346            [-1, 252, 4, 4]             504\n",
      "            ReLU-347            [-1, 252, 4, 4]               0\n",
      "          Conv2d-348             [-1, 48, 4, 4]          12,096\n",
      "     BatchNorm2d-349             [-1, 48, 4, 4]              96\n",
      "            ReLU-350             [-1, 48, 4, 4]               0\n",
      "          Conv2d-351             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-352            [-1, 264, 4, 4]               0\n",
      "     BatchNorm2d-353            [-1, 264, 4, 4]             528\n",
      "            ReLU-354            [-1, 264, 4, 4]               0\n",
      "          Conv2d-355             [-1, 48, 4, 4]          12,672\n",
      "     BatchNorm2d-356             [-1, 48, 4, 4]              96\n",
      "            ReLU-357             [-1, 48, 4, 4]               0\n",
      "          Conv2d-358             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-359            [-1, 276, 4, 4]               0\n",
      "     BatchNorm2d-360            [-1, 276, 4, 4]             552\n",
      "            ReLU-361            [-1, 276, 4, 4]               0\n",
      "          Conv2d-362             [-1, 48, 4, 4]          13,248\n",
      "     BatchNorm2d-363             [-1, 48, 4, 4]              96\n",
      "            ReLU-364             [-1, 48, 4, 4]               0\n",
      "          Conv2d-365             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-366            [-1, 288, 4, 4]               0\n",
      "     BatchNorm2d-367            [-1, 288, 4, 4]             576\n",
      "            ReLU-368            [-1, 288, 4, 4]               0\n",
      "          Conv2d-369             [-1, 48, 4, 4]          13,824\n",
      "     BatchNorm2d-370             [-1, 48, 4, 4]              96\n",
      "            ReLU-371             [-1, 48, 4, 4]               0\n",
      "          Conv2d-372             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-373            [-1, 300, 4, 4]               0\n",
      "     BatchNorm2d-374            [-1, 300, 4, 4]             600\n",
      "            ReLU-375            [-1, 300, 4, 4]               0\n",
      "          Conv2d-376             [-1, 48, 4, 4]          14,400\n",
      "     BatchNorm2d-377             [-1, 48, 4, 4]              96\n",
      "            ReLU-378             [-1, 48, 4, 4]               0\n",
      "          Conv2d-379             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-380            [-1, 312, 4, 4]               0\n",
      "     BatchNorm2d-381            [-1, 312, 4, 4]             624\n",
      "            ReLU-382            [-1, 312, 4, 4]               0\n",
      "          Conv2d-383             [-1, 48, 4, 4]          14,976\n",
      "     BatchNorm2d-384             [-1, 48, 4, 4]              96\n",
      "            ReLU-385             [-1, 48, 4, 4]               0\n",
      "          Conv2d-386             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-387            [-1, 324, 4, 4]               0\n",
      "     BatchNorm2d-388            [-1, 324, 4, 4]             648\n",
      "            ReLU-389            [-1, 324, 4, 4]               0\n",
      "          Conv2d-390             [-1, 48, 4, 4]          15,552\n",
      "     BatchNorm2d-391             [-1, 48, 4, 4]              96\n",
      "            ReLU-392             [-1, 48, 4, 4]               0\n",
      "          Conv2d-393             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-394            [-1, 336, 4, 4]               0\n",
      "     BatchNorm2d-395            [-1, 336, 4, 4]             672\n",
      "            ReLU-396            [-1, 336, 4, 4]               0\n",
      "          Conv2d-397             [-1, 48, 4, 4]          16,128\n",
      "     BatchNorm2d-398             [-1, 48, 4, 4]              96\n",
      "            ReLU-399             [-1, 48, 4, 4]               0\n",
      "          Conv2d-400             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-401            [-1, 348, 4, 4]               0\n",
      "     BatchNorm2d-402            [-1, 348, 4, 4]             696\n",
      "            ReLU-403            [-1, 348, 4, 4]               0\n",
      "          Conv2d-404             [-1, 48, 4, 4]          16,704\n",
      "     BatchNorm2d-405             [-1, 48, 4, 4]              96\n",
      "            ReLU-406             [-1, 48, 4, 4]               0\n",
      "          Conv2d-407             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-408            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-409            [-1, 360, 4, 4]             720\n",
      "            ReLU-410            [-1, 360, 4, 4]               0\n",
      "          Conv2d-411             [-1, 48, 4, 4]          17,280\n",
      "     BatchNorm2d-412             [-1, 48, 4, 4]              96\n",
      "            ReLU-413             [-1, 48, 4, 4]               0\n",
      "          Conv2d-414             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-415            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-416            [-1, 372, 4, 4]             744\n",
      "            ReLU-417            [-1, 372, 4, 4]               0\n",
      "          Conv2d-418             [-1, 48, 4, 4]          17,856\n",
      "     BatchNorm2d-419             [-1, 48, 4, 4]              96\n",
      "            ReLU-420             [-1, 48, 4, 4]               0\n",
      "          Conv2d-421             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-422            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-423            [-1, 384, 4, 4]             768\n",
      "            ReLU-424            [-1, 384, 4, 4]               0\n",
      "       AvgPool2d-425            [-1, 384, 1, 1]               0\n",
      "          Linear-426                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 997,538\n",
      "Trainable params: 997,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 43.49\n",
      "Params size (MB): 3.81\n",
      "Estimated Total Size (MB): 47.31\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 132640896.0\n",
      "MACs: 66320448.0\n",
      "Parameters: 997538.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.6214 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 43.00\n",
      "FP: 1.00\n",
      "Acc: 96.26%\n",
      "Se: 95.24%\n",
      "Sp: 97.73%\n",
      "MAcc: 96.48%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_with_augmentation.pth'\\\n",
    "--no_augment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 36, 32, 32]           2,592\n",
      "        AvgPool2d-33           [-1, 36, 16, 16]               0\n",
      "       Transition-34           [-1, 36, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 36, 16, 16]              72\n",
      "             ReLU-36           [-1, 36, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           1,728\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 48, 16, 16]              96\n",
      "             ReLU-43           [-1, 48, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 60, 16, 16]             120\n",
      "             ReLU-50           [-1, 60, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 72, 16, 16]             144\n",
      "             ReLU-57           [-1, 72, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 84, 16, 16]             168\n",
      "             ReLU-64           [-1, 84, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 96, 16, 16]             192\n",
      "             ReLU-71           [-1, 96, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-77          [-1, 108, 16, 16]             216\n",
      "             ReLU-78          [-1, 108, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 120, 16, 16]             240\n",
      "             ReLU-85          [-1, 120, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 132, 16, 16]             264\n",
      "             ReLU-92          [-1, 132, 16, 16]               0\n",
      "           Conv2d-93           [-1, 66, 16, 16]           8,712\n",
      "        AvgPool2d-94             [-1, 66, 8, 8]               0\n",
      "       Transition-95             [-1, 66, 8, 8]               0\n",
      "      BatchNorm2d-96             [-1, 66, 8, 8]             132\n",
      "             ReLU-97             [-1, 66, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           3,168\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102             [-1, 78, 8, 8]               0\n",
      "     BatchNorm2d-103             [-1, 78, 8, 8]             156\n",
      "            ReLU-104             [-1, 78, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           3,744\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109             [-1, 90, 8, 8]               0\n",
      "     BatchNorm2d-110             [-1, 90, 8, 8]             180\n",
      "            ReLU-111             [-1, 90, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           4,320\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116            [-1, 102, 8, 8]               0\n",
      "     BatchNorm2d-117            [-1, 102, 8, 8]             204\n",
      "            ReLU-118            [-1, 102, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           4,896\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123            [-1, 114, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 114, 8, 8]             228\n",
      "            ReLU-125            [-1, 114, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           5,472\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130            [-1, 126, 8, 8]               0\n",
      "     BatchNorm2d-131            [-1, 126, 8, 8]             252\n",
      "            ReLU-132            [-1, 126, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           6,048\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 138, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 138, 8, 8]             276\n",
      "            ReLU-139            [-1, 138, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           6,624\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 150, 8, 8]             300\n",
      "            ReLU-146            [-1, 150, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           7,200\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 162, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 162, 8, 8]             324\n",
      "            ReLU-153            [-1, 162, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           7,776\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 174, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 174, 8, 8]             348\n",
      "            ReLU-160            [-1, 174, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           8,352\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 186, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 186, 8, 8]             372\n",
      "            ReLU-167            [-1, 186, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           8,928\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 198, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 198, 8, 8]             396\n",
      "            ReLU-174            [-1, 198, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           9,504\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 210, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 210, 8, 8]             420\n",
      "            ReLU-181            [-1, 210, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]          10,080\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 222, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 222, 8, 8]             444\n",
      "            ReLU-188            [-1, 222, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]          10,656\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 234, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 234, 8, 8]             468\n",
      "            ReLU-195            [-1, 234, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]          11,232\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 246, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 246, 8, 8]             492\n",
      "            ReLU-202            [-1, 246, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          11,808\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 258, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 258, 8, 8]             516\n",
      "            ReLU-209            [-1, 258, 8, 8]               0\n",
      "          Conv2d-210            [-1, 129, 8, 8]          33,282\n",
      "       AvgPool2d-211            [-1, 129, 4, 4]               0\n",
      "      Transition-212            [-1, 129, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 129, 4, 4]             258\n",
      "            ReLU-214            [-1, 129, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]           6,192\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219            [-1, 141, 4, 4]               0\n",
      "     BatchNorm2d-220            [-1, 141, 4, 4]             282\n",
      "            ReLU-221            [-1, 141, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]           6,768\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226            [-1, 153, 4, 4]               0\n",
      "     BatchNorm2d-227            [-1, 153, 4, 4]             306\n",
      "            ReLU-228            [-1, 153, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]           7,344\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 165, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 165, 4, 4]             330\n",
      "            ReLU-235            [-1, 165, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]           7,920\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 177, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 177, 4, 4]             354\n",
      "            ReLU-242            [-1, 177, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]           8,496\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 189, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 189, 4, 4]             378\n",
      "            ReLU-249            [-1, 189, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]           9,072\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 201, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 201, 4, 4]             402\n",
      "            ReLU-256            [-1, 201, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]           9,648\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 213, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 213, 4, 4]             426\n",
      "            ReLU-263            [-1, 213, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]          10,224\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 225, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 225, 4, 4]             450\n",
      "            ReLU-270            [-1, 225, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 225, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             452\n",
      "================================================================\n",
      "Total params: 469,940\n",
      "Trainable params: 469,940\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 23.95\n",
      "Params size (MB): 1.79\n",
      "Estimated Total Size (MB): 25.75\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 74125299.0\n",
      "MACs: 37062649.5\n",
      "Parameters: 469940.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.3976 seconds\n",
      "TP: 59.00\n",
      "FN: 4.00\n",
      "TN: 41.00\n",
      "FP: 3.00\n",
      "Acc: 93.46%\n",
      "Se: 93.65%\n",
      "Sp: 93.18%\n",
      "MAcc: 93.42%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_different_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
      "             ReLU-34           [-1, 48, 32, 32]               0\n",
      "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-36           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
      "             ReLU-38           [-1, 84, 32, 32]               0\n",
      "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "             ReLU-41           [-1, 48, 32, 32]               0\n",
      "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-43           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
      "             ReLU-45           [-1, 96, 32, 32]               0\n",
      "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
      "      BatchNorm2d-47           [-1, 48, 32, 32]              96\n",
      "             ReLU-48           [-1, 48, 32, 32]               0\n",
      "           Conv2d-49           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-50          [-1, 108, 32, 32]               0\n",
      "      BatchNorm2d-51          [-1, 108, 32, 32]             216\n",
      "             ReLU-52          [-1, 108, 32, 32]               0\n",
      "           Conv2d-53           [-1, 48, 32, 32]           5,184\n",
      "      BatchNorm2d-54           [-1, 48, 32, 32]              96\n",
      "             ReLU-55           [-1, 48, 32, 32]               0\n",
      "           Conv2d-56           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-57          [-1, 120, 32, 32]               0\n",
      "      BatchNorm2d-58          [-1, 120, 32, 32]             240\n",
      "             ReLU-59          [-1, 120, 32, 32]               0\n",
      "           Conv2d-60           [-1, 60, 32, 32]           7,200\n",
      "        AvgPool2d-61           [-1, 60, 16, 16]               0\n",
      "       Transition-62           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 60, 16, 16]             120\n",
      "             ReLU-64           [-1, 60, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 72, 16, 16]             144\n",
      "             ReLU-71           [-1, 72, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 84, 16, 16]             168\n",
      "             ReLU-78           [-1, 84, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-84           [-1, 96, 16, 16]             192\n",
      "             ReLU-85           [-1, 96, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 108, 16, 16]             216\n",
      "             ReLU-92          [-1, 108, 16, 16]               0\n",
      "           Conv2d-93           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-94           [-1, 48, 16, 16]              96\n",
      "             ReLU-95           [-1, 48, 16, 16]               0\n",
      "           Conv2d-96           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-97          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-98          [-1, 120, 16, 16]             240\n",
      "             ReLU-99          [-1, 120, 16, 16]               0\n",
      "          Conv2d-100           [-1, 48, 16, 16]           5,760\n",
      "     BatchNorm2d-101           [-1, 48, 16, 16]              96\n",
      "            ReLU-102           [-1, 48, 16, 16]               0\n",
      "          Conv2d-103           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-104          [-1, 132, 16, 16]               0\n",
      "     BatchNorm2d-105          [-1, 132, 16, 16]             264\n",
      "            ReLU-106          [-1, 132, 16, 16]               0\n",
      "          Conv2d-107           [-1, 48, 16, 16]           6,336\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "            ReLU-109           [-1, 48, 16, 16]               0\n",
      "          Conv2d-110           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-111          [-1, 144, 16, 16]               0\n",
      "     BatchNorm2d-112          [-1, 144, 16, 16]             288\n",
      "            ReLU-113          [-1, 144, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           6,912\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-118          [-1, 156, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 156, 16, 16]             312\n",
      "            ReLU-120          [-1, 156, 16, 16]               0\n",
      "          Conv2d-121           [-1, 48, 16, 16]           7,488\n",
      "     BatchNorm2d-122           [-1, 48, 16, 16]              96\n",
      "            ReLU-123           [-1, 48, 16, 16]               0\n",
      "          Conv2d-124           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-125          [-1, 168, 16, 16]               0\n",
      "     BatchNorm2d-126          [-1, 168, 16, 16]             336\n",
      "            ReLU-127          [-1, 168, 16, 16]               0\n",
      "          Conv2d-128           [-1, 48, 16, 16]           8,064\n",
      "     BatchNorm2d-129           [-1, 48, 16, 16]              96\n",
      "            ReLU-130           [-1, 48, 16, 16]               0\n",
      "          Conv2d-131           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-132          [-1, 180, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 180, 16, 16]             360\n",
      "            ReLU-134          [-1, 180, 16, 16]               0\n",
      "          Conv2d-135           [-1, 48, 16, 16]           8,640\n",
      "     BatchNorm2d-136           [-1, 48, 16, 16]              96\n",
      "            ReLU-137           [-1, 48, 16, 16]               0\n",
      "          Conv2d-138           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-139          [-1, 192, 16, 16]               0\n",
      "     BatchNorm2d-140          [-1, 192, 16, 16]             384\n",
      "            ReLU-141          [-1, 192, 16, 16]               0\n",
      "          Conv2d-142           [-1, 48, 16, 16]           9,216\n",
      "     BatchNorm2d-143           [-1, 48, 16, 16]              96\n",
      "            ReLU-144           [-1, 48, 16, 16]               0\n",
      "          Conv2d-145           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-146          [-1, 204, 16, 16]               0\n",
      "     BatchNorm2d-147          [-1, 204, 16, 16]             408\n",
      "            ReLU-148          [-1, 204, 16, 16]               0\n",
      "          Conv2d-149           [-1, 48, 16, 16]           9,792\n",
      "     BatchNorm2d-150           [-1, 48, 16, 16]              96\n",
      "            ReLU-151           [-1, 48, 16, 16]               0\n",
      "          Conv2d-152           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-153          [-1, 216, 16, 16]               0\n",
      "     BatchNorm2d-154          [-1, 216, 16, 16]             432\n",
      "            ReLU-155          [-1, 216, 16, 16]               0\n",
      "          Conv2d-156           [-1, 48, 16, 16]          10,368\n",
      "     BatchNorm2d-157           [-1, 48, 16, 16]              96\n",
      "            ReLU-158           [-1, 48, 16, 16]               0\n",
      "          Conv2d-159           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-160          [-1, 228, 16, 16]               0\n",
      "     BatchNorm2d-161          [-1, 228, 16, 16]             456\n",
      "            ReLU-162          [-1, 228, 16, 16]               0\n",
      "          Conv2d-163           [-1, 48, 16, 16]          10,944\n",
      "     BatchNorm2d-164           [-1, 48, 16, 16]              96\n",
      "            ReLU-165           [-1, 48, 16, 16]               0\n",
      "          Conv2d-166           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-167          [-1, 240, 16, 16]               0\n",
      "     BatchNorm2d-168          [-1, 240, 16, 16]             480\n",
      "            ReLU-169          [-1, 240, 16, 16]               0\n",
      "          Conv2d-170           [-1, 48, 16, 16]          11,520\n",
      "     BatchNorm2d-171           [-1, 48, 16, 16]              96\n",
      "            ReLU-172           [-1, 48, 16, 16]               0\n",
      "          Conv2d-173           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-174          [-1, 252, 16, 16]               0\n",
      "     BatchNorm2d-175          [-1, 252, 16, 16]             504\n",
      "            ReLU-176          [-1, 252, 16, 16]               0\n",
      "          Conv2d-177          [-1, 126, 16, 16]          31,752\n",
      "       AvgPool2d-178            [-1, 126, 8, 8]               0\n",
      "      Transition-179            [-1, 126, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 126, 8, 8]             252\n",
      "            ReLU-181            [-1, 126, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           6,048\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 138, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 138, 8, 8]             276\n",
      "            ReLU-188            [-1, 138, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           6,624\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 150, 8, 8]             300\n",
      "            ReLU-195            [-1, 150, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           7,200\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 162, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 162, 8, 8]             324\n",
      "            ReLU-202            [-1, 162, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           7,776\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 174, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 174, 8, 8]             348\n",
      "            ReLU-209            [-1, 174, 8, 8]               0\n",
      "          Conv2d-210             [-1, 48, 8, 8]           8,352\n",
      "     BatchNorm2d-211             [-1, 48, 8, 8]              96\n",
      "            ReLU-212             [-1, 48, 8, 8]               0\n",
      "          Conv2d-213             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-214            [-1, 186, 8, 8]               0\n",
      "     BatchNorm2d-215            [-1, 186, 8, 8]             372\n",
      "            ReLU-216            [-1, 186, 8, 8]               0\n",
      "          Conv2d-217             [-1, 48, 8, 8]           8,928\n",
      "     BatchNorm2d-218             [-1, 48, 8, 8]              96\n",
      "            ReLU-219             [-1, 48, 8, 8]               0\n",
      "          Conv2d-220             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-221            [-1, 198, 8, 8]               0\n",
      "     BatchNorm2d-222            [-1, 198, 8, 8]             396\n",
      "            ReLU-223            [-1, 198, 8, 8]               0\n",
      "          Conv2d-224             [-1, 48, 8, 8]           9,504\n",
      "     BatchNorm2d-225             [-1, 48, 8, 8]              96\n",
      "            ReLU-226             [-1, 48, 8, 8]               0\n",
      "          Conv2d-227             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-228            [-1, 210, 8, 8]               0\n",
      "     BatchNorm2d-229            [-1, 210, 8, 8]             420\n",
      "            ReLU-230            [-1, 210, 8, 8]               0\n",
      "          Conv2d-231             [-1, 48, 8, 8]          10,080\n",
      "     BatchNorm2d-232             [-1, 48, 8, 8]              96\n",
      "            ReLU-233             [-1, 48, 8, 8]               0\n",
      "          Conv2d-234             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-235            [-1, 222, 8, 8]               0\n",
      "     BatchNorm2d-236            [-1, 222, 8, 8]             444\n",
      "            ReLU-237            [-1, 222, 8, 8]               0\n",
      "          Conv2d-238             [-1, 48, 8, 8]          10,656\n",
      "     BatchNorm2d-239             [-1, 48, 8, 8]              96\n",
      "            ReLU-240             [-1, 48, 8, 8]               0\n",
      "          Conv2d-241             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-242            [-1, 234, 8, 8]               0\n",
      "     BatchNorm2d-243            [-1, 234, 8, 8]             468\n",
      "            ReLU-244            [-1, 234, 8, 8]               0\n",
      "          Conv2d-245             [-1, 48, 8, 8]          11,232\n",
      "     BatchNorm2d-246             [-1, 48, 8, 8]              96\n",
      "            ReLU-247             [-1, 48, 8, 8]               0\n",
      "          Conv2d-248             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-249            [-1, 246, 8, 8]               0\n",
      "     BatchNorm2d-250            [-1, 246, 8, 8]             492\n",
      "            ReLU-251            [-1, 246, 8, 8]               0\n",
      "          Conv2d-252             [-1, 48, 8, 8]          11,808\n",
      "     BatchNorm2d-253             [-1, 48, 8, 8]              96\n",
      "            ReLU-254             [-1, 48, 8, 8]               0\n",
      "          Conv2d-255             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-256            [-1, 258, 8, 8]               0\n",
      "     BatchNorm2d-257            [-1, 258, 8, 8]             516\n",
      "            ReLU-258            [-1, 258, 8, 8]               0\n",
      "          Conv2d-259             [-1, 48, 8, 8]          12,384\n",
      "     BatchNorm2d-260             [-1, 48, 8, 8]              96\n",
      "            ReLU-261             [-1, 48, 8, 8]               0\n",
      "          Conv2d-262             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-263            [-1, 270, 8, 8]               0\n",
      "     BatchNorm2d-264            [-1, 270, 8, 8]             540\n",
      "            ReLU-265            [-1, 270, 8, 8]               0\n",
      "          Conv2d-266             [-1, 48, 8, 8]          12,960\n",
      "     BatchNorm2d-267             [-1, 48, 8, 8]              96\n",
      "            ReLU-268             [-1, 48, 8, 8]               0\n",
      "          Conv2d-269             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-270            [-1, 282, 8, 8]               0\n",
      "     BatchNorm2d-271            [-1, 282, 8, 8]             564\n",
      "            ReLU-272            [-1, 282, 8, 8]               0\n",
      "          Conv2d-273             [-1, 48, 8, 8]          13,536\n",
      "     BatchNorm2d-274             [-1, 48, 8, 8]              96\n",
      "            ReLU-275             [-1, 48, 8, 8]               0\n",
      "          Conv2d-276             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-277            [-1, 294, 8, 8]               0\n",
      "     BatchNorm2d-278            [-1, 294, 8, 8]             588\n",
      "            ReLU-279            [-1, 294, 8, 8]               0\n",
      "          Conv2d-280             [-1, 48, 8, 8]          14,112\n",
      "     BatchNorm2d-281             [-1, 48, 8, 8]              96\n",
      "            ReLU-282             [-1, 48, 8, 8]               0\n",
      "          Conv2d-283             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-284            [-1, 306, 8, 8]               0\n",
      "     BatchNorm2d-285            [-1, 306, 8, 8]             612\n",
      "            ReLU-286            [-1, 306, 8, 8]               0\n",
      "          Conv2d-287             [-1, 48, 8, 8]          14,688\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-291            [-1, 318, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 318, 8, 8]             636\n",
      "            ReLU-293            [-1, 318, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]          15,264\n",
      "     BatchNorm2d-295             [-1, 48, 8, 8]              96\n",
      "            ReLU-296             [-1, 48, 8, 8]               0\n",
      "          Conv2d-297             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-298            [-1, 330, 8, 8]               0\n",
      "     BatchNorm2d-299            [-1, 330, 8, 8]             660\n",
      "            ReLU-300            [-1, 330, 8, 8]               0\n",
      "          Conv2d-301             [-1, 48, 8, 8]          15,840\n",
      "     BatchNorm2d-302             [-1, 48, 8, 8]              96\n",
      "            ReLU-303             [-1, 48, 8, 8]               0\n",
      "          Conv2d-304             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-305            [-1, 342, 8, 8]               0\n",
      "     BatchNorm2d-306            [-1, 342, 8, 8]             684\n",
      "            ReLU-307            [-1, 342, 8, 8]               0\n",
      "          Conv2d-308             [-1, 48, 8, 8]          16,416\n",
      "     BatchNorm2d-309             [-1, 48, 8, 8]              96\n",
      "            ReLU-310             [-1, 48, 8, 8]               0\n",
      "          Conv2d-311             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-312            [-1, 354, 8, 8]               0\n",
      "     BatchNorm2d-313            [-1, 354, 8, 8]             708\n",
      "            ReLU-314            [-1, 354, 8, 8]               0\n",
      "          Conv2d-315             [-1, 48, 8, 8]          16,992\n",
      "     BatchNorm2d-316             [-1, 48, 8, 8]              96\n",
      "            ReLU-317             [-1, 48, 8, 8]               0\n",
      "          Conv2d-318             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-319            [-1, 366, 8, 8]               0\n",
      "     BatchNorm2d-320            [-1, 366, 8, 8]             732\n",
      "            ReLU-321            [-1, 366, 8, 8]               0\n",
      "          Conv2d-322             [-1, 48, 8, 8]          17,568\n",
      "     BatchNorm2d-323             [-1, 48, 8, 8]              96\n",
      "            ReLU-324             [-1, 48, 8, 8]               0\n",
      "          Conv2d-325             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-326            [-1, 378, 8, 8]               0\n",
      "     BatchNorm2d-327            [-1, 378, 8, 8]             756\n",
      "            ReLU-328            [-1, 378, 8, 8]               0\n",
      "          Conv2d-329             [-1, 48, 8, 8]          18,144\n",
      "     BatchNorm2d-330             [-1, 48, 8, 8]              96\n",
      "            ReLU-331             [-1, 48, 8, 8]               0\n",
      "          Conv2d-332             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-333            [-1, 390, 8, 8]               0\n",
      "     BatchNorm2d-334            [-1, 390, 8, 8]             780\n",
      "            ReLU-335            [-1, 390, 8, 8]               0\n",
      "          Conv2d-336             [-1, 48, 8, 8]          18,720\n",
      "     BatchNorm2d-337             [-1, 48, 8, 8]              96\n",
      "            ReLU-338             [-1, 48, 8, 8]               0\n",
      "          Conv2d-339             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-340            [-1, 402, 8, 8]               0\n",
      "     BatchNorm2d-341            [-1, 402, 8, 8]             804\n",
      "            ReLU-342            [-1, 402, 8, 8]               0\n",
      "          Conv2d-343             [-1, 48, 8, 8]          19,296\n",
      "     BatchNorm2d-344             [-1, 48, 8, 8]              96\n",
      "            ReLU-345             [-1, 48, 8, 8]               0\n",
      "          Conv2d-346             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-347            [-1, 414, 8, 8]               0\n",
      "     BatchNorm2d-348            [-1, 414, 8, 8]             828\n",
      "            ReLU-349            [-1, 414, 8, 8]               0\n",
      "          Conv2d-350             [-1, 48, 8, 8]          19,872\n",
      "     BatchNorm2d-351             [-1, 48, 8, 8]              96\n",
      "            ReLU-352             [-1, 48, 8, 8]               0\n",
      "          Conv2d-353             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-354            [-1, 426, 8, 8]               0\n",
      "     BatchNorm2d-355            [-1, 426, 8, 8]             852\n",
      "            ReLU-356            [-1, 426, 8, 8]               0\n",
      "          Conv2d-357             [-1, 48, 8, 8]          20,448\n",
      "     BatchNorm2d-358             [-1, 48, 8, 8]              96\n",
      "            ReLU-359             [-1, 48, 8, 8]               0\n",
      "          Conv2d-360             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-361            [-1, 438, 8, 8]               0\n",
      "     BatchNorm2d-362            [-1, 438, 8, 8]             876\n",
      "            ReLU-363            [-1, 438, 8, 8]               0\n",
      "          Conv2d-364             [-1, 48, 8, 8]          21,024\n",
      "     BatchNorm2d-365             [-1, 48, 8, 8]              96\n",
      "            ReLU-366             [-1, 48, 8, 8]               0\n",
      "          Conv2d-367             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-368            [-1, 450, 8, 8]               0\n",
      "     BatchNorm2d-369            [-1, 450, 8, 8]             900\n",
      "            ReLU-370            [-1, 450, 8, 8]               0\n",
      "          Conv2d-371             [-1, 48, 8, 8]          21,600\n",
      "     BatchNorm2d-372             [-1, 48, 8, 8]              96\n",
      "            ReLU-373             [-1, 48, 8, 8]               0\n",
      "          Conv2d-374             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-375            [-1, 462, 8, 8]               0\n",
      "     BatchNorm2d-376            [-1, 462, 8, 8]             924\n",
      "            ReLU-377            [-1, 462, 8, 8]               0\n",
      "          Conv2d-378             [-1, 48, 8, 8]          22,176\n",
      "     BatchNorm2d-379             [-1, 48, 8, 8]              96\n",
      "            ReLU-380             [-1, 48, 8, 8]               0\n",
      "          Conv2d-381             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-382            [-1, 474, 8, 8]               0\n",
      "     BatchNorm2d-383            [-1, 474, 8, 8]             948\n",
      "            ReLU-384            [-1, 474, 8, 8]               0\n",
      "          Conv2d-385             [-1, 48, 8, 8]          22,752\n",
      "     BatchNorm2d-386             [-1, 48, 8, 8]              96\n",
      "            ReLU-387             [-1, 48, 8, 8]               0\n",
      "          Conv2d-388             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-389            [-1, 486, 8, 8]               0\n",
      "     BatchNorm2d-390            [-1, 486, 8, 8]             972\n",
      "            ReLU-391            [-1, 486, 8, 8]               0\n",
      "          Conv2d-392             [-1, 48, 8, 8]          23,328\n",
      "     BatchNorm2d-393             [-1, 48, 8, 8]              96\n",
      "            ReLU-394             [-1, 48, 8, 8]               0\n",
      "          Conv2d-395             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-396            [-1, 498, 8, 8]               0\n",
      "     BatchNorm2d-397            [-1, 498, 8, 8]             996\n",
      "            ReLU-398            [-1, 498, 8, 8]               0\n",
      "          Conv2d-399             [-1, 48, 8, 8]          23,904\n",
      "     BatchNorm2d-400             [-1, 48, 8, 8]              96\n",
      "            ReLU-401             [-1, 48, 8, 8]               0\n",
      "          Conv2d-402             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-403            [-1, 510, 8, 8]               0\n",
      "     BatchNorm2d-404            [-1, 510, 8, 8]           1,020\n",
      "            ReLU-405            [-1, 510, 8, 8]               0\n",
      "          Conv2d-406            [-1, 255, 8, 8]         130,050\n",
      "       AvgPool2d-407            [-1, 255, 4, 4]               0\n",
      "      Transition-408            [-1, 255, 4, 4]               0\n",
      "     BatchNorm2d-409            [-1, 255, 4, 4]             510\n",
      "            ReLU-410            [-1, 255, 4, 4]               0\n",
      "          Conv2d-411             [-1, 48, 4, 4]          12,240\n",
      "     BatchNorm2d-412             [-1, 48, 4, 4]              96\n",
      "            ReLU-413             [-1, 48, 4, 4]               0\n",
      "          Conv2d-414             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-415            [-1, 267, 4, 4]               0\n",
      "     BatchNorm2d-416            [-1, 267, 4, 4]             534\n",
      "            ReLU-417            [-1, 267, 4, 4]               0\n",
      "          Conv2d-418             [-1, 48, 4, 4]          12,816\n",
      "     BatchNorm2d-419             [-1, 48, 4, 4]              96\n",
      "            ReLU-420             [-1, 48, 4, 4]               0\n",
      "          Conv2d-421             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-422            [-1, 279, 4, 4]               0\n",
      "     BatchNorm2d-423            [-1, 279, 4, 4]             558\n",
      "            ReLU-424            [-1, 279, 4, 4]               0\n",
      "          Conv2d-425             [-1, 48, 4, 4]          13,392\n",
      "     BatchNorm2d-426             [-1, 48, 4, 4]              96\n",
      "            ReLU-427             [-1, 48, 4, 4]               0\n",
      "          Conv2d-428             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-429            [-1, 291, 4, 4]               0\n",
      "     BatchNorm2d-430            [-1, 291, 4, 4]             582\n",
      "            ReLU-431            [-1, 291, 4, 4]               0\n",
      "          Conv2d-432             [-1, 48, 4, 4]          13,968\n",
      "     BatchNorm2d-433             [-1, 48, 4, 4]              96\n",
      "            ReLU-434             [-1, 48, 4, 4]               0\n",
      "          Conv2d-435             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-436            [-1, 303, 4, 4]               0\n",
      "     BatchNorm2d-437            [-1, 303, 4, 4]             606\n",
      "            ReLU-438            [-1, 303, 4, 4]               0\n",
      "          Conv2d-439             [-1, 48, 4, 4]          14,544\n",
      "     BatchNorm2d-440             [-1, 48, 4, 4]              96\n",
      "            ReLU-441             [-1, 48, 4, 4]               0\n",
      "          Conv2d-442             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-443            [-1, 315, 4, 4]               0\n",
      "     BatchNorm2d-444            [-1, 315, 4, 4]             630\n",
      "            ReLU-445            [-1, 315, 4, 4]               0\n",
      "          Conv2d-446             [-1, 48, 4, 4]          15,120\n",
      "     BatchNorm2d-447             [-1, 48, 4, 4]              96\n",
      "            ReLU-448             [-1, 48, 4, 4]               0\n",
      "          Conv2d-449             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-450            [-1, 327, 4, 4]               0\n",
      "     BatchNorm2d-451            [-1, 327, 4, 4]             654\n",
      "            ReLU-452            [-1, 327, 4, 4]               0\n",
      "          Conv2d-453             [-1, 48, 4, 4]          15,696\n",
      "     BatchNorm2d-454             [-1, 48, 4, 4]              96\n",
      "            ReLU-455             [-1, 48, 4, 4]               0\n",
      "          Conv2d-456             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-457            [-1, 339, 4, 4]               0\n",
      "     BatchNorm2d-458            [-1, 339, 4, 4]             678\n",
      "            ReLU-459            [-1, 339, 4, 4]               0\n",
      "          Conv2d-460             [-1, 48, 4, 4]          16,272\n",
      "     BatchNorm2d-461             [-1, 48, 4, 4]              96\n",
      "            ReLU-462             [-1, 48, 4, 4]               0\n",
      "          Conv2d-463             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-464            [-1, 351, 4, 4]               0\n",
      "     BatchNorm2d-465            [-1, 351, 4, 4]             702\n",
      "            ReLU-466            [-1, 351, 4, 4]               0\n",
      "          Conv2d-467             [-1, 48, 4, 4]          16,848\n",
      "     BatchNorm2d-468             [-1, 48, 4, 4]              96\n",
      "            ReLU-469             [-1, 48, 4, 4]               0\n",
      "          Conv2d-470             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-471            [-1, 363, 4, 4]               0\n",
      "     BatchNorm2d-472            [-1, 363, 4, 4]             726\n",
      "            ReLU-473            [-1, 363, 4, 4]               0\n",
      "          Conv2d-474             [-1, 48, 4, 4]          17,424\n",
      "     BatchNorm2d-475             [-1, 48, 4, 4]              96\n",
      "            ReLU-476             [-1, 48, 4, 4]               0\n",
      "          Conv2d-477             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-478            [-1, 375, 4, 4]               0\n",
      "     BatchNorm2d-479            [-1, 375, 4, 4]             750\n",
      "            ReLU-480            [-1, 375, 4, 4]               0\n",
      "          Conv2d-481             [-1, 48, 4, 4]          18,000\n",
      "     BatchNorm2d-482             [-1, 48, 4, 4]              96\n",
      "            ReLU-483             [-1, 48, 4, 4]               0\n",
      "          Conv2d-484             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-485            [-1, 387, 4, 4]               0\n",
      "     BatchNorm2d-486            [-1, 387, 4, 4]             774\n",
      "            ReLU-487            [-1, 387, 4, 4]               0\n",
      "          Conv2d-488             [-1, 48, 4, 4]          18,576\n",
      "     BatchNorm2d-489             [-1, 48, 4, 4]              96\n",
      "            ReLU-490             [-1, 48, 4, 4]               0\n",
      "          Conv2d-491             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-492            [-1, 399, 4, 4]               0\n",
      "     BatchNorm2d-493            [-1, 399, 4, 4]             798\n",
      "            ReLU-494            [-1, 399, 4, 4]               0\n",
      "          Conv2d-495             [-1, 48, 4, 4]          19,152\n",
      "     BatchNorm2d-496             [-1, 48, 4, 4]              96\n",
      "            ReLU-497             [-1, 48, 4, 4]               0\n",
      "          Conv2d-498             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-499            [-1, 411, 4, 4]               0\n",
      "     BatchNorm2d-500            [-1, 411, 4, 4]             822\n",
      "            ReLU-501            [-1, 411, 4, 4]               0\n",
      "          Conv2d-502             [-1, 48, 4, 4]          19,728\n",
      "     BatchNorm2d-503             [-1, 48, 4, 4]              96\n",
      "            ReLU-504             [-1, 48, 4, 4]               0\n",
      "          Conv2d-505             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-506            [-1, 423, 4, 4]               0\n",
      "     BatchNorm2d-507            [-1, 423, 4, 4]             846\n",
      "            ReLU-508            [-1, 423, 4, 4]               0\n",
      "          Conv2d-509             [-1, 48, 4, 4]          20,304\n",
      "     BatchNorm2d-510             [-1, 48, 4, 4]              96\n",
      "            ReLU-511             [-1, 48, 4, 4]               0\n",
      "          Conv2d-512             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-513            [-1, 435, 4, 4]               0\n",
      "     BatchNorm2d-514            [-1, 435, 4, 4]             870\n",
      "            ReLU-515            [-1, 435, 4, 4]               0\n",
      "          Conv2d-516             [-1, 48, 4, 4]          20,880\n",
      "     BatchNorm2d-517             [-1, 48, 4, 4]              96\n",
      "            ReLU-518             [-1, 48, 4, 4]               0\n",
      "          Conv2d-519             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-520            [-1, 447, 4, 4]               0\n",
      "     BatchNorm2d-521            [-1, 447, 4, 4]             894\n",
      "            ReLU-522            [-1, 447, 4, 4]               0\n",
      "       AvgPool2d-523            [-1, 447, 1, 1]               0\n",
      "          Linear-524                    [-1, 2]             896\n",
      "================================================================\n",
      "Total params: 1,474,964\n",
      "Trainable params: 1,474,964\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.70\n",
      "Params size (MB): 5.63\n",
      "Estimated Total Size (MB): 72.34\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 201755373.0\n",
      "MACs: 100877686.5\n",
      "Parameters: 1474964.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.7915 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 95.33%\n",
      "Se: 95.24%\n",
      "Sp: 95.45%\n",
      "MAcc: 95.35%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 8 16 32 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32            [-1, 7, 32, 32]             504\n",
      "        AvgPool2d-33            [-1, 7, 16, 16]               0\n",
      "       Transition-34            [-1, 7, 16, 16]               0\n",
      "      BatchNorm2d-35            [-1, 7, 16, 16]              14\n",
      "             ReLU-36            [-1, 7, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]             336\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 19, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 19, 16, 16]              38\n",
      "             ReLU-43           [-1, 19, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]             912\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 31, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 31, 16, 16]              62\n",
      "             ReLU-50           [-1, 31, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           1,488\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 43, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 43, 16, 16]              86\n",
      "             ReLU-57           [-1, 43, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,064\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 55, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 55, 16, 16]             110\n",
      "             ReLU-64           [-1, 55, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           2,640\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 67, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 67, 16, 16]             134\n",
      "             ReLU-71           [-1, 67, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           3,216\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 79, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 79, 16, 16]             158\n",
      "             ReLU-78           [-1, 79, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           3,792\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83           [-1, 91, 16, 16]               0\n",
      "      BatchNorm2d-84           [-1, 91, 16, 16]             182\n",
      "             ReLU-85           [-1, 91, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           4,368\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 103, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 103, 16, 16]             206\n",
      "             ReLU-92          [-1, 103, 16, 16]               0\n",
      "           Conv2d-93           [-1, 10, 16, 16]           1,030\n",
      "        AvgPool2d-94             [-1, 10, 8, 8]               0\n",
      "       Transition-95             [-1, 10, 8, 8]               0\n",
      "      BatchNorm2d-96             [-1, 10, 8, 8]              20\n",
      "             ReLU-97             [-1, 10, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]             480\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102             [-1, 22, 8, 8]               0\n",
      "     BatchNorm2d-103             [-1, 22, 8, 8]              44\n",
      "            ReLU-104             [-1, 22, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           1,056\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109             [-1, 34, 8, 8]               0\n",
      "     BatchNorm2d-110             [-1, 34, 8, 8]              68\n",
      "            ReLU-111             [-1, 34, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           1,632\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116             [-1, 46, 8, 8]               0\n",
      "     BatchNorm2d-117             [-1, 46, 8, 8]              92\n",
      "            ReLU-118             [-1, 46, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           2,208\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123             [-1, 58, 8, 8]               0\n",
      "     BatchNorm2d-124             [-1, 58, 8, 8]             116\n",
      "            ReLU-125             [-1, 58, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           2,784\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130             [-1, 70, 8, 8]               0\n",
      "     BatchNorm2d-131             [-1, 70, 8, 8]             140\n",
      "            ReLU-132             [-1, 70, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           3,360\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137             [-1, 82, 8, 8]               0\n",
      "     BatchNorm2d-138             [-1, 82, 8, 8]             164\n",
      "            ReLU-139             [-1, 82, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           3,936\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144             [-1, 94, 8, 8]               0\n",
      "     BatchNorm2d-145             [-1, 94, 8, 8]             188\n",
      "            ReLU-146             [-1, 94, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           4,512\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 106, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 106, 8, 8]             212\n",
      "            ReLU-153            [-1, 106, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           5,088\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 118, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 118, 8, 8]             236\n",
      "            ReLU-160            [-1, 118, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           5,664\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 130, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 130, 8, 8]             260\n",
      "            ReLU-167            [-1, 130, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           6,240\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 142, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 142, 8, 8]             284\n",
      "            ReLU-174            [-1, 142, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           6,816\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 154, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 154, 8, 8]             308\n",
      "            ReLU-181            [-1, 154, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           7,392\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 166, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 166, 8, 8]             332\n",
      "            ReLU-188            [-1, 166, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           7,968\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 178, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 178, 8, 8]             356\n",
      "            ReLU-195            [-1, 178, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           8,544\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 190, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 190, 8, 8]             380\n",
      "            ReLU-202            [-1, 190, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           9,120\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 202, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 202, 8, 8]             404\n",
      "            ReLU-209            [-1, 202, 8, 8]               0\n",
      "          Conv2d-210             [-1, 20, 8, 8]           4,040\n",
      "       AvgPool2d-211             [-1, 20, 4, 4]               0\n",
      "      Transition-212             [-1, 20, 4, 4]               0\n",
      "     BatchNorm2d-213             [-1, 20, 4, 4]              40\n",
      "            ReLU-214             [-1, 20, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]             960\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219             [-1, 32, 4, 4]               0\n",
      "     BatchNorm2d-220             [-1, 32, 4, 4]              64\n",
      "            ReLU-221             [-1, 32, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]           1,536\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226             [-1, 44, 4, 4]               0\n",
      "     BatchNorm2d-227             [-1, 44, 4, 4]              88\n",
      "            ReLU-228             [-1, 44, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]           2,112\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233             [-1, 56, 4, 4]               0\n",
      "     BatchNorm2d-234             [-1, 56, 4, 4]             112\n",
      "            ReLU-235             [-1, 56, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]           2,688\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240             [-1, 68, 4, 4]               0\n",
      "     BatchNorm2d-241             [-1, 68, 4, 4]             136\n",
      "            ReLU-242             [-1, 68, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]           3,264\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247             [-1, 80, 4, 4]               0\n",
      "     BatchNorm2d-248             [-1, 80, 4, 4]             160\n",
      "            ReLU-249             [-1, 80, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]           3,840\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254             [-1, 92, 4, 4]               0\n",
      "     BatchNorm2d-255             [-1, 92, 4, 4]             184\n",
      "            ReLU-256             [-1, 92, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]           4,416\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 104, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 104, 4, 4]             208\n",
      "            ReLU-263            [-1, 104, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]           4,992\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 116, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 116, 4, 4]             232\n",
      "            ReLU-270            [-1, 116, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 116, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             234\n",
      "================================================================\n",
      "Total params: 330,322\n",
      "Trainable params: 330,322\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 20.18\n",
      "Params size (MB): 1.26\n",
      "Estimated Total Size (MB): 21.45\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 61289244.0\n",
      "MACs: 30644622.0\n",
      "Parameters: 330322.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.3668 seconds\n",
      "TP: 58.00\n",
      "FN: 5.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 93.46%\n",
      "Se: 92.06%\n",
      "Sp: 95.45%\n",
      "MAcc: 93.76%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 14, 32, 32]           1,008\n",
      "        AvgPool2d-33           [-1, 14, 16, 16]               0\n",
      "       Transition-34           [-1, 14, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 14, 16, 16]              28\n",
      "             ReLU-36           [-1, 14, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]             672\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 26, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 26, 16, 16]              52\n",
      "             ReLU-43           [-1, 26, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           1,248\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 38, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 38, 16, 16]              76\n",
      "             ReLU-50           [-1, 38, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           1,824\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 50, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 50, 16, 16]             100\n",
      "             ReLU-57           [-1, 50, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,400\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 62, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 62, 16, 16]             124\n",
      "             ReLU-64           [-1, 62, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           2,976\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 74, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 74, 16, 16]             148\n",
      "             ReLU-71           [-1, 74, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           3,552\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 86, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 86, 16, 16]             172\n",
      "             ReLU-78           [-1, 86, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,128\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83           [-1, 98, 16, 16]               0\n",
      "      BatchNorm2d-84           [-1, 98, 16, 16]             196\n",
      "             ReLU-85           [-1, 98, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           4,704\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 110, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 110, 16, 16]             220\n",
      "             ReLU-92          [-1, 110, 16, 16]               0\n",
      "           Conv2d-93           [-1, 22, 16, 16]           2,420\n",
      "        AvgPool2d-94             [-1, 22, 8, 8]               0\n",
      "       Transition-95             [-1, 22, 8, 8]               0\n",
      "      BatchNorm2d-96             [-1, 22, 8, 8]              44\n",
      "             ReLU-97             [-1, 22, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           1,056\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102             [-1, 34, 8, 8]               0\n",
      "     BatchNorm2d-103             [-1, 34, 8, 8]              68\n",
      "            ReLU-104             [-1, 34, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           1,632\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109             [-1, 46, 8, 8]               0\n",
      "     BatchNorm2d-110             [-1, 46, 8, 8]              92\n",
      "            ReLU-111             [-1, 46, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           2,208\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116             [-1, 58, 8, 8]               0\n",
      "     BatchNorm2d-117             [-1, 58, 8, 8]             116\n",
      "            ReLU-118             [-1, 58, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           2,784\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123             [-1, 70, 8, 8]               0\n",
      "     BatchNorm2d-124             [-1, 70, 8, 8]             140\n",
      "            ReLU-125             [-1, 70, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           3,360\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130             [-1, 82, 8, 8]               0\n",
      "     BatchNorm2d-131             [-1, 82, 8, 8]             164\n",
      "            ReLU-132             [-1, 82, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           3,936\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137             [-1, 94, 8, 8]               0\n",
      "     BatchNorm2d-138             [-1, 94, 8, 8]             188\n",
      "            ReLU-139             [-1, 94, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           4,512\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 106, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 106, 8, 8]             212\n",
      "            ReLU-146            [-1, 106, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           5,088\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 118, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 118, 8, 8]             236\n",
      "            ReLU-153            [-1, 118, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           5,664\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 130, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 130, 8, 8]             260\n",
      "            ReLU-160            [-1, 130, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           6,240\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 142, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 142, 8, 8]             284\n",
      "            ReLU-167            [-1, 142, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           6,816\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 154, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 154, 8, 8]             308\n",
      "            ReLU-174            [-1, 154, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           7,392\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 166, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 166, 8, 8]             332\n",
      "            ReLU-181            [-1, 166, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           7,968\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 178, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 178, 8, 8]             356\n",
      "            ReLU-188            [-1, 178, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           8,544\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 190, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 190, 8, 8]             380\n",
      "            ReLU-195            [-1, 190, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           9,120\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 202, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 202, 8, 8]             404\n",
      "            ReLU-202            [-1, 202, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           9,696\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 214, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 214, 8, 8]             428\n",
      "            ReLU-209            [-1, 214, 8, 8]               0\n",
      "          Conv2d-210             [-1, 42, 8, 8]           8,988\n",
      "       AvgPool2d-211             [-1, 42, 4, 4]               0\n",
      "      Transition-212             [-1, 42, 4, 4]               0\n",
      "     BatchNorm2d-213             [-1, 42, 4, 4]              84\n",
      "            ReLU-214             [-1, 42, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]           2,016\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219             [-1, 54, 4, 4]               0\n",
      "     BatchNorm2d-220             [-1, 54, 4, 4]             108\n",
      "            ReLU-221             [-1, 54, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]           2,592\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226             [-1, 66, 4, 4]               0\n",
      "     BatchNorm2d-227             [-1, 66, 4, 4]             132\n",
      "            ReLU-228             [-1, 66, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]           3,168\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233             [-1, 78, 4, 4]               0\n",
      "     BatchNorm2d-234             [-1, 78, 4, 4]             156\n",
      "            ReLU-235             [-1, 78, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]           3,744\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240             [-1, 90, 4, 4]               0\n",
      "     BatchNorm2d-241             [-1, 90, 4, 4]             180\n",
      "            ReLU-242             [-1, 90, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]           4,320\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 102, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 102, 4, 4]             204\n",
      "            ReLU-249            [-1, 102, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]           4,896\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 114, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 114, 4, 4]             228\n",
      "            ReLU-256            [-1, 114, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]           5,472\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 126, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 126, 4, 4]             252\n",
      "            ReLU-263            [-1, 126, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]           6,048\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 138, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 138, 4, 4]             276\n",
      "            ReLU-270            [-1, 138, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 138, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             278\n",
      "================================================================\n",
      "Total params: 358,490\n",
      "Trainable params: 358,490\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 21.03\n",
      "Params size (MB): 1.37\n",
      "Estimated Total Size (MB): 22.41\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 64023358.0\n",
      "MACs: 32011679.0\n",
      "Parameters: 358490.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.3552 seconds\n",
      "TP: 58.00\n",
      "FN: 5.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 93.46%\n",
      "Se: 92.06%\n",
      "Sp: 95.45%\n",
      "MAcc: 93.76%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 21, 32, 32]           1,512\n",
      "        AvgPool2d-33           [-1, 21, 16, 16]               0\n",
      "       Transition-34           [-1, 21, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 21, 16, 16]              42\n",
      "             ReLU-36           [-1, 21, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           1,008\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 33, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 33, 16, 16]              66\n",
      "             ReLU-43           [-1, 33, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           1,584\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 45, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 45, 16, 16]              90\n",
      "             ReLU-50           [-1, 45, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,160\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 57, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 57, 16, 16]             114\n",
      "             ReLU-57           [-1, 57, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,736\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 69, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 69, 16, 16]             138\n",
      "             ReLU-64           [-1, 69, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           3,312\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 81, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 81, 16, 16]             162\n",
      "             ReLU-71           [-1, 81, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           3,888\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 93, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 93, 16, 16]             186\n",
      "             ReLU-78           [-1, 93, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,464\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 105, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 105, 16, 16]             210\n",
      "             ReLU-85          [-1, 105, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,040\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 117, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 117, 16, 16]             234\n",
      "             ReLU-92          [-1, 117, 16, 16]               0\n",
      "           Conv2d-93           [-1, 35, 16, 16]           4,095\n",
      "        AvgPool2d-94             [-1, 35, 8, 8]               0\n",
      "       Transition-95             [-1, 35, 8, 8]               0\n",
      "      BatchNorm2d-96             [-1, 35, 8, 8]              70\n",
      "             ReLU-97             [-1, 35, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           1,680\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102             [-1, 47, 8, 8]               0\n",
      "     BatchNorm2d-103             [-1, 47, 8, 8]              94\n",
      "            ReLU-104             [-1, 47, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           2,256\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109             [-1, 59, 8, 8]               0\n",
      "     BatchNorm2d-110             [-1, 59, 8, 8]             118\n",
      "            ReLU-111             [-1, 59, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           2,832\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116             [-1, 71, 8, 8]               0\n",
      "     BatchNorm2d-117             [-1, 71, 8, 8]             142\n",
      "            ReLU-118             [-1, 71, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           3,408\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123             [-1, 83, 8, 8]               0\n",
      "     BatchNorm2d-124             [-1, 83, 8, 8]             166\n",
      "            ReLU-125             [-1, 83, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           3,984\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130             [-1, 95, 8, 8]               0\n",
      "     BatchNorm2d-131             [-1, 95, 8, 8]             190\n",
      "            ReLU-132             [-1, 95, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           4,560\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 107, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 107, 8, 8]             214\n",
      "            ReLU-139            [-1, 107, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           5,136\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 119, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 119, 8, 8]             238\n",
      "            ReLU-146            [-1, 119, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           5,712\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 131, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 131, 8, 8]             262\n",
      "            ReLU-153            [-1, 131, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           6,288\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 143, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 143, 8, 8]             286\n",
      "            ReLU-160            [-1, 143, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           6,864\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 155, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 155, 8, 8]             310\n",
      "            ReLU-167            [-1, 155, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           7,440\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 167, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 167, 8, 8]             334\n",
      "            ReLU-174            [-1, 167, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           8,016\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 179, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 179, 8, 8]             358\n",
      "            ReLU-181            [-1, 179, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           8,592\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 191, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 191, 8, 8]             382\n",
      "            ReLU-188            [-1, 191, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           9,168\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 203, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 203, 8, 8]             406\n",
      "            ReLU-195            [-1, 203, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           9,744\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 215, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 215, 8, 8]             430\n",
      "            ReLU-202            [-1, 215, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          10,320\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 227, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 227, 8, 8]             454\n",
      "            ReLU-209            [-1, 227, 8, 8]               0\n",
      "          Conv2d-210             [-1, 68, 8, 8]          15,436\n",
      "       AvgPool2d-211             [-1, 68, 4, 4]               0\n",
      "      Transition-212             [-1, 68, 4, 4]               0\n",
      "     BatchNorm2d-213             [-1, 68, 4, 4]             136\n",
      "            ReLU-214             [-1, 68, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]           3,264\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219             [-1, 80, 4, 4]               0\n",
      "     BatchNorm2d-220             [-1, 80, 4, 4]             160\n",
      "            ReLU-221             [-1, 80, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]           3,840\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226             [-1, 92, 4, 4]               0\n",
      "     BatchNorm2d-227             [-1, 92, 4, 4]             184\n",
      "            ReLU-228             [-1, 92, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]           4,416\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 104, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 104, 4, 4]             208\n",
      "            ReLU-235            [-1, 104, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]           4,992\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 116, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 116, 4, 4]             232\n",
      "            ReLU-242            [-1, 116, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]           5,568\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 128, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 128, 4, 4]             256\n",
      "            ReLU-249            [-1, 128, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]           6,144\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 140, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 140, 4, 4]             280\n",
      "            ReLU-256            [-1, 140, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]           6,720\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 152, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 152, 4, 4]             304\n",
      "            ReLU-263            [-1, 152, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]           7,296\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 164, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 164, 4, 4]             328\n",
      "            ReLU-270            [-1, 164, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 164, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             330\n",
      "================================================================\n",
      "Total params: 390,861\n",
      "Trainable params: 390,861\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 21.93\n",
      "Params size (MB): 1.49\n",
      "Estimated Total Size (MB): 23.43\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 67006956.0\n",
      "MACs: 33503478.0\n",
      "Parameters: 390861.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.3778 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 95.33%\n",
      "Se: 95.24%\n",
      "Sp: 95.45%\n",
      "MAcc: 95.35%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 28, 32, 32]           2,016\n",
      "        AvgPool2d-33           [-1, 28, 16, 16]               0\n",
      "       Transition-34           [-1, 28, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 28, 16, 16]              56\n",
      "             ReLU-36           [-1, 28, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           1,344\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 40, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 40, 16, 16]              80\n",
      "             ReLU-43           [-1, 40, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           1,920\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 52, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 52, 16, 16]             104\n",
      "             ReLU-50           [-1, 52, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,496\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 64, 16, 16]             128\n",
      "             ReLU-57           [-1, 64, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           3,072\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 76, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 76, 16, 16]             152\n",
      "             ReLU-64           [-1, 76, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           3,648\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 88, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 88, 16, 16]             176\n",
      "             ReLU-71           [-1, 88, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,224\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76          [-1, 100, 16, 16]               0\n",
      "      BatchNorm2d-77          [-1, 100, 16, 16]             200\n",
      "             ReLU-78          [-1, 100, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,800\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 112, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 112, 16, 16]             224\n",
      "             ReLU-85          [-1, 112, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,376\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 124, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 124, 16, 16]             248\n",
      "             ReLU-92          [-1, 124, 16, 16]               0\n",
      "           Conv2d-93           [-1, 49, 16, 16]           6,076\n",
      "        AvgPool2d-94             [-1, 49, 8, 8]               0\n",
      "       Transition-95             [-1, 49, 8, 8]               0\n",
      "      BatchNorm2d-96             [-1, 49, 8, 8]              98\n",
      "             ReLU-97             [-1, 49, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           2,352\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102             [-1, 61, 8, 8]               0\n",
      "     BatchNorm2d-103             [-1, 61, 8, 8]             122\n",
      "            ReLU-104             [-1, 61, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           2,928\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109             [-1, 73, 8, 8]               0\n",
      "     BatchNorm2d-110             [-1, 73, 8, 8]             146\n",
      "            ReLU-111             [-1, 73, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           3,504\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116             [-1, 85, 8, 8]               0\n",
      "     BatchNorm2d-117             [-1, 85, 8, 8]             170\n",
      "            ReLU-118             [-1, 85, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           4,080\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123             [-1, 97, 8, 8]               0\n",
      "     BatchNorm2d-124             [-1, 97, 8, 8]             194\n",
      "            ReLU-125             [-1, 97, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           4,656\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130            [-1, 109, 8, 8]               0\n",
      "     BatchNorm2d-131            [-1, 109, 8, 8]             218\n",
      "            ReLU-132            [-1, 109, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           5,232\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 121, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 121, 8, 8]             242\n",
      "            ReLU-139            [-1, 121, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           5,808\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 133, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 133, 8, 8]             266\n",
      "            ReLU-146            [-1, 133, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           6,384\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 145, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 145, 8, 8]             290\n",
      "            ReLU-153            [-1, 145, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           6,960\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 157, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 157, 8, 8]             314\n",
      "            ReLU-160            [-1, 157, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           7,536\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 169, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 169, 8, 8]             338\n",
      "            ReLU-167            [-1, 169, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           8,112\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 181, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 181, 8, 8]             362\n",
      "            ReLU-174            [-1, 181, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           8,688\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 193, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 193, 8, 8]             386\n",
      "            ReLU-181            [-1, 193, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           9,264\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 205, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 205, 8, 8]             410\n",
      "            ReLU-188            [-1, 205, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           9,840\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 217, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 217, 8, 8]             434\n",
      "            ReLU-195            [-1, 217, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]          10,416\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 229, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 229, 8, 8]             458\n",
      "            ReLU-202            [-1, 229, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          10,992\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 241, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 241, 8, 8]             482\n",
      "            ReLU-209            [-1, 241, 8, 8]               0\n",
      "          Conv2d-210             [-1, 96, 8, 8]          23,136\n",
      "       AvgPool2d-211             [-1, 96, 4, 4]               0\n",
      "      Transition-212             [-1, 96, 4, 4]               0\n",
      "     BatchNorm2d-213             [-1, 96, 4, 4]             192\n",
      "            ReLU-214             [-1, 96, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]           4,608\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219            [-1, 108, 4, 4]               0\n",
      "     BatchNorm2d-220            [-1, 108, 4, 4]             216\n",
      "            ReLU-221            [-1, 108, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]           5,184\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226            [-1, 120, 4, 4]               0\n",
      "     BatchNorm2d-227            [-1, 120, 4, 4]             240\n",
      "            ReLU-228            [-1, 120, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]           5,760\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 132, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 132, 4, 4]             264\n",
      "            ReLU-235            [-1, 132, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]           6,336\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 144, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 144, 4, 4]             288\n",
      "            ReLU-242            [-1, 144, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]           6,912\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 156, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 156, 4, 4]             312\n",
      "            ReLU-249            [-1, 156, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]           7,488\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 168, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 168, 4, 4]             336\n",
      "            ReLU-256            [-1, 168, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]           8,064\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 180, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 180, 4, 4]             360\n",
      "            ReLU-263            [-1, 180, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]           8,640\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 192, 4, 4]             384\n",
      "            ReLU-270            [-1, 192, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 192, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             386\n",
      "================================================================\n",
      "Total params: 426,400\n",
      "Trainable params: 426,400\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 22.85\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 24.49\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 70216064.0\n",
      "MACs: 35108032.0\n",
      "Parameters: 426400.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.3778 seconds\n",
      "TP: 59.00\n",
      "FN: 4.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 94.39%\n",
      "Se: 93.65%\n",
      "Sp: 95.45%\n",
      "MAcc: 94.55%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 36, 32, 32]           2,592\n",
      "        AvgPool2d-33           [-1, 36, 16, 16]               0\n",
      "       Transition-34           [-1, 36, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 36, 16, 16]              72\n",
      "             ReLU-36           [-1, 36, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           1,728\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 48, 16, 16]              96\n",
      "             ReLU-43           [-1, 48, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 60, 16, 16]             120\n",
      "             ReLU-50           [-1, 60, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 72, 16, 16]             144\n",
      "             ReLU-57           [-1, 72, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 84, 16, 16]             168\n",
      "             ReLU-64           [-1, 84, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 96, 16, 16]             192\n",
      "             ReLU-71           [-1, 96, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-77          [-1, 108, 16, 16]             216\n",
      "             ReLU-78          [-1, 108, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 120, 16, 16]             240\n",
      "             ReLU-85          [-1, 120, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 132, 16, 16]             264\n",
      "             ReLU-92          [-1, 132, 16, 16]               0\n",
      "           Conv2d-93           [-1, 66, 16, 16]           8,712\n",
      "        AvgPool2d-94             [-1, 66, 8, 8]               0\n",
      "       Transition-95             [-1, 66, 8, 8]               0\n",
      "      BatchNorm2d-96             [-1, 66, 8, 8]             132\n",
      "             ReLU-97             [-1, 66, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           3,168\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102             [-1, 78, 8, 8]               0\n",
      "     BatchNorm2d-103             [-1, 78, 8, 8]             156\n",
      "            ReLU-104             [-1, 78, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           3,744\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109             [-1, 90, 8, 8]               0\n",
      "     BatchNorm2d-110             [-1, 90, 8, 8]             180\n",
      "            ReLU-111             [-1, 90, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           4,320\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116            [-1, 102, 8, 8]               0\n",
      "     BatchNorm2d-117            [-1, 102, 8, 8]             204\n",
      "            ReLU-118            [-1, 102, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           4,896\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123            [-1, 114, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 114, 8, 8]             228\n",
      "            ReLU-125            [-1, 114, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           5,472\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130            [-1, 126, 8, 8]               0\n",
      "     BatchNorm2d-131            [-1, 126, 8, 8]             252\n",
      "            ReLU-132            [-1, 126, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           6,048\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 138, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 138, 8, 8]             276\n",
      "            ReLU-139            [-1, 138, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           6,624\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 150, 8, 8]             300\n",
      "            ReLU-146            [-1, 150, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           7,200\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 162, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 162, 8, 8]             324\n",
      "            ReLU-153            [-1, 162, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           7,776\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 174, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 174, 8, 8]             348\n",
      "            ReLU-160            [-1, 174, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           8,352\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 186, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 186, 8, 8]             372\n",
      "            ReLU-167            [-1, 186, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           8,928\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 198, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 198, 8, 8]             396\n",
      "            ReLU-174            [-1, 198, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           9,504\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 210, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 210, 8, 8]             420\n",
      "            ReLU-181            [-1, 210, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]          10,080\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 222, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 222, 8, 8]             444\n",
      "            ReLU-188            [-1, 222, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]          10,656\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 234, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 234, 8, 8]             468\n",
      "            ReLU-195            [-1, 234, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]          11,232\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 246, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 246, 8, 8]             492\n",
      "            ReLU-202            [-1, 246, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          11,808\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 258, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 258, 8, 8]             516\n",
      "            ReLU-209            [-1, 258, 8, 8]               0\n",
      "          Conv2d-210            [-1, 129, 8, 8]          33,282\n",
      "       AvgPool2d-211            [-1, 129, 4, 4]               0\n",
      "      Transition-212            [-1, 129, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 129, 4, 4]             258\n",
      "            ReLU-214            [-1, 129, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]           6,192\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219            [-1, 141, 4, 4]               0\n",
      "     BatchNorm2d-220            [-1, 141, 4, 4]             282\n",
      "            ReLU-221            [-1, 141, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]           6,768\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226            [-1, 153, 4, 4]               0\n",
      "     BatchNorm2d-227            [-1, 153, 4, 4]             306\n",
      "            ReLU-228            [-1, 153, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]           7,344\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 165, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 165, 4, 4]             330\n",
      "            ReLU-235            [-1, 165, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]           7,920\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 177, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 177, 4, 4]             354\n",
      "            ReLU-242            [-1, 177, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]           8,496\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 189, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 189, 4, 4]             378\n",
      "            ReLU-249            [-1, 189, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]           9,072\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 201, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 201, 4, 4]             402\n",
      "            ReLU-256            [-1, 201, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]           9,648\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 213, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 213, 4, 4]             426\n",
      "            ReLU-263            [-1, 213, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]          10,224\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 225, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 225, 4, 4]             450\n",
      "            ReLU-270            [-1, 225, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 225, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             452\n",
      "================================================================\n",
      "Total params: 469,940\n",
      "Trainable params: 469,940\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 23.95\n",
      "Params size (MB): 1.79\n",
      "Estimated Total Size (MB): 25.75\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 74125299.0\n",
      "MACs: 37062649.5\n",
      "Parameters: 469940.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.4203 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 95.33%\n",
      "Se: 95.24%\n",
      "Sp: 95.45%\n",
      "MAcc: 95.35%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
      "             ReLU-34           [-1, 48, 32, 32]               0\n",
      "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-36           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
      "             ReLU-38           [-1, 84, 32, 32]               0\n",
      "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "             ReLU-41           [-1, 48, 32, 32]               0\n",
      "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-43           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
      "             ReLU-45           [-1, 96, 32, 32]               0\n",
      "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
      "        AvgPool2d-47           [-1, 48, 16, 16]               0\n",
      "       Transition-48           [-1, 48, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 48, 16, 16]              96\n",
      "             ReLU-50           [-1, 48, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           2,304\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 60, 16, 16]             120\n",
      "             ReLU-57           [-1, 60, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 72, 16, 16]             144\n",
      "             ReLU-64           [-1, 72, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 84, 16, 16]             168\n",
      "             ReLU-71           [-1, 84, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 96, 16, 16]             192\n",
      "             ReLU-78           [-1, 96, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 108, 16, 16]             216\n",
      "             ReLU-85          [-1, 108, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 120, 16, 16]             240\n",
      "             ReLU-92          [-1, 120, 16, 16]               0\n",
      "           Conv2d-93           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-94           [-1, 48, 16, 16]              96\n",
      "             ReLU-95           [-1, 48, 16, 16]               0\n",
      "           Conv2d-96           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-97          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-98          [-1, 132, 16, 16]             264\n",
      "             ReLU-99          [-1, 132, 16, 16]               0\n",
      "          Conv2d-100           [-1, 48, 16, 16]           6,336\n",
      "     BatchNorm2d-101           [-1, 48, 16, 16]              96\n",
      "            ReLU-102           [-1, 48, 16, 16]               0\n",
      "          Conv2d-103           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-104          [-1, 144, 16, 16]               0\n",
      "     BatchNorm2d-105          [-1, 144, 16, 16]             288\n",
      "            ReLU-106          [-1, 144, 16, 16]               0\n",
      "          Conv2d-107           [-1, 48, 16, 16]           6,912\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "            ReLU-109           [-1, 48, 16, 16]               0\n",
      "          Conv2d-110           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-111          [-1, 156, 16, 16]               0\n",
      "     BatchNorm2d-112          [-1, 156, 16, 16]             312\n",
      "            ReLU-113          [-1, 156, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           7,488\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-118          [-1, 168, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 168, 16, 16]             336\n",
      "            ReLU-120          [-1, 168, 16, 16]               0\n",
      "          Conv2d-121           [-1, 48, 16, 16]           8,064\n",
      "     BatchNorm2d-122           [-1, 48, 16, 16]              96\n",
      "            ReLU-123           [-1, 48, 16, 16]               0\n",
      "          Conv2d-124           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-125          [-1, 180, 16, 16]               0\n",
      "     BatchNorm2d-126          [-1, 180, 16, 16]             360\n",
      "            ReLU-127          [-1, 180, 16, 16]               0\n",
      "          Conv2d-128           [-1, 48, 16, 16]           8,640\n",
      "     BatchNorm2d-129           [-1, 48, 16, 16]              96\n",
      "            ReLU-130           [-1, 48, 16, 16]               0\n",
      "          Conv2d-131           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-132          [-1, 192, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 192, 16, 16]             384\n",
      "            ReLU-134          [-1, 192, 16, 16]               0\n",
      "          Conv2d-135           [-1, 96, 16, 16]          18,432\n",
      "       AvgPool2d-136             [-1, 96, 8, 8]               0\n",
      "      Transition-137             [-1, 96, 8, 8]               0\n",
      "     BatchNorm2d-138             [-1, 96, 8, 8]             192\n",
      "            ReLU-139             [-1, 96, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           4,608\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 108, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 108, 8, 8]             216\n",
      "            ReLU-146            [-1, 108, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           5,184\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 120, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 120, 8, 8]             240\n",
      "            ReLU-153            [-1, 120, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           5,760\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 132, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 132, 8, 8]             264\n",
      "            ReLU-160            [-1, 132, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]           6,336\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 144, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 144, 8, 8]             288\n",
      "            ReLU-167            [-1, 144, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]           6,912\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 156, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 156, 8, 8]             312\n",
      "            ReLU-174            [-1, 156, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]           7,488\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 168, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 168, 8, 8]             336\n",
      "            ReLU-181            [-1, 168, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           8,064\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 180, 8, 8]             360\n",
      "            ReLU-188            [-1, 180, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           8,640\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 192, 8, 8]             384\n",
      "            ReLU-195            [-1, 192, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           9,216\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 204, 8, 8]             408\n",
      "            ReLU-202            [-1, 204, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           9,792\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 216, 8, 8]             432\n",
      "            ReLU-209            [-1, 216, 8, 8]               0\n",
      "          Conv2d-210             [-1, 48, 8, 8]          10,368\n",
      "     BatchNorm2d-211             [-1, 48, 8, 8]              96\n",
      "            ReLU-212             [-1, 48, 8, 8]               0\n",
      "          Conv2d-213             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-214            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-215            [-1, 228, 8, 8]             456\n",
      "            ReLU-216            [-1, 228, 8, 8]               0\n",
      "          Conv2d-217             [-1, 48, 8, 8]          10,944\n",
      "     BatchNorm2d-218             [-1, 48, 8, 8]              96\n",
      "            ReLU-219             [-1, 48, 8, 8]               0\n",
      "          Conv2d-220             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-221            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-222            [-1, 240, 8, 8]             480\n",
      "            ReLU-223            [-1, 240, 8, 8]               0\n",
      "          Conv2d-224             [-1, 48, 8, 8]          11,520\n",
      "     BatchNorm2d-225             [-1, 48, 8, 8]              96\n",
      "            ReLU-226             [-1, 48, 8, 8]               0\n",
      "          Conv2d-227             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-228            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-229            [-1, 252, 8, 8]             504\n",
      "            ReLU-230            [-1, 252, 8, 8]               0\n",
      "          Conv2d-231             [-1, 48, 8, 8]          12,096\n",
      "     BatchNorm2d-232             [-1, 48, 8, 8]              96\n",
      "            ReLU-233             [-1, 48, 8, 8]               0\n",
      "          Conv2d-234             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-235            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-236            [-1, 264, 8, 8]             528\n",
      "            ReLU-237            [-1, 264, 8, 8]               0\n",
      "          Conv2d-238             [-1, 48, 8, 8]          12,672\n",
      "     BatchNorm2d-239             [-1, 48, 8, 8]              96\n",
      "            ReLU-240             [-1, 48, 8, 8]               0\n",
      "          Conv2d-241             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-242            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-243            [-1, 276, 8, 8]             552\n",
      "            ReLU-244            [-1, 276, 8, 8]               0\n",
      "          Conv2d-245             [-1, 48, 8, 8]          13,248\n",
      "     BatchNorm2d-246             [-1, 48, 8, 8]              96\n",
      "            ReLU-247             [-1, 48, 8, 8]               0\n",
      "          Conv2d-248             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-249            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-250            [-1, 288, 8, 8]             576\n",
      "            ReLU-251            [-1, 288, 8, 8]               0\n",
      "          Conv2d-252             [-1, 48, 8, 8]          13,824\n",
      "     BatchNorm2d-253             [-1, 48, 8, 8]              96\n",
      "            ReLU-254             [-1, 48, 8, 8]               0\n",
      "          Conv2d-255             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-256            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-257            [-1, 300, 8, 8]             600\n",
      "            ReLU-258            [-1, 300, 8, 8]               0\n",
      "          Conv2d-259             [-1, 48, 8, 8]          14,400\n",
      "     BatchNorm2d-260             [-1, 48, 8, 8]              96\n",
      "            ReLU-261             [-1, 48, 8, 8]               0\n",
      "          Conv2d-262             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-263            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-264            [-1, 312, 8, 8]             624\n",
      "            ReLU-265            [-1, 312, 8, 8]               0\n",
      "          Conv2d-266             [-1, 48, 8, 8]          14,976\n",
      "     BatchNorm2d-267             [-1, 48, 8, 8]              96\n",
      "            ReLU-268             [-1, 48, 8, 8]               0\n",
      "          Conv2d-269             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-270            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-271            [-1, 324, 8, 8]             648\n",
      "            ReLU-272            [-1, 324, 8, 8]               0\n",
      "          Conv2d-273             [-1, 48, 8, 8]          15,552\n",
      "     BatchNorm2d-274             [-1, 48, 8, 8]              96\n",
      "            ReLU-275             [-1, 48, 8, 8]               0\n",
      "          Conv2d-276             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-277            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-278            [-1, 336, 8, 8]             672\n",
      "            ReLU-279            [-1, 336, 8, 8]               0\n",
      "          Conv2d-280             [-1, 48, 8, 8]          16,128\n",
      "     BatchNorm2d-281             [-1, 48, 8, 8]              96\n",
      "            ReLU-282             [-1, 48, 8, 8]               0\n",
      "          Conv2d-283             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-284            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-285            [-1, 348, 8, 8]             696\n",
      "            ReLU-286            [-1, 348, 8, 8]               0\n",
      "          Conv2d-287             [-1, 48, 8, 8]          16,704\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-291            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 360, 8, 8]             720\n",
      "            ReLU-293            [-1, 360, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]          17,280\n",
      "     BatchNorm2d-295             [-1, 48, 8, 8]              96\n",
      "            ReLU-296             [-1, 48, 8, 8]               0\n",
      "          Conv2d-297             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-298            [-1, 372, 8, 8]               0\n",
      "     BatchNorm2d-299            [-1, 372, 8, 8]             744\n",
      "            ReLU-300            [-1, 372, 8, 8]               0\n",
      "          Conv2d-301             [-1, 48, 8, 8]          17,856\n",
      "     BatchNorm2d-302             [-1, 48, 8, 8]              96\n",
      "            ReLU-303             [-1, 48, 8, 8]               0\n",
      "          Conv2d-304             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-305            [-1, 384, 8, 8]               0\n",
      "     BatchNorm2d-306            [-1, 384, 8, 8]             768\n",
      "            ReLU-307            [-1, 384, 8, 8]               0\n",
      "          Conv2d-308            [-1, 192, 8, 8]          73,728\n",
      "       AvgPool2d-309            [-1, 192, 4, 4]               0\n",
      "      Transition-310            [-1, 192, 4, 4]               0\n",
      "     BatchNorm2d-311            [-1, 192, 4, 4]             384\n",
      "            ReLU-312            [-1, 192, 4, 4]               0\n",
      "          Conv2d-313             [-1, 48, 4, 4]           9,216\n",
      "     BatchNorm2d-314             [-1, 48, 4, 4]              96\n",
      "            ReLU-315             [-1, 48, 4, 4]               0\n",
      "          Conv2d-316             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-317            [-1, 204, 4, 4]               0\n",
      "     BatchNorm2d-318            [-1, 204, 4, 4]             408\n",
      "            ReLU-319            [-1, 204, 4, 4]               0\n",
      "          Conv2d-320             [-1, 48, 4, 4]           9,792\n",
      "     BatchNorm2d-321             [-1, 48, 4, 4]              96\n",
      "            ReLU-322             [-1, 48, 4, 4]               0\n",
      "          Conv2d-323             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-324            [-1, 216, 4, 4]               0\n",
      "     BatchNorm2d-325            [-1, 216, 4, 4]             432\n",
      "            ReLU-326            [-1, 216, 4, 4]               0\n",
      "          Conv2d-327             [-1, 48, 4, 4]          10,368\n",
      "     BatchNorm2d-328             [-1, 48, 4, 4]              96\n",
      "            ReLU-329             [-1, 48, 4, 4]               0\n",
      "          Conv2d-330             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-331            [-1, 228, 4, 4]               0\n",
      "     BatchNorm2d-332            [-1, 228, 4, 4]             456\n",
      "            ReLU-333            [-1, 228, 4, 4]               0\n",
      "          Conv2d-334             [-1, 48, 4, 4]          10,944\n",
      "     BatchNorm2d-335             [-1, 48, 4, 4]              96\n",
      "            ReLU-336             [-1, 48, 4, 4]               0\n",
      "          Conv2d-337             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-338            [-1, 240, 4, 4]               0\n",
      "     BatchNorm2d-339            [-1, 240, 4, 4]             480\n",
      "            ReLU-340            [-1, 240, 4, 4]               0\n",
      "          Conv2d-341             [-1, 48, 4, 4]          11,520\n",
      "     BatchNorm2d-342             [-1, 48, 4, 4]              96\n",
      "            ReLU-343             [-1, 48, 4, 4]               0\n",
      "          Conv2d-344             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-345            [-1, 252, 4, 4]               0\n",
      "     BatchNorm2d-346            [-1, 252, 4, 4]             504\n",
      "            ReLU-347            [-1, 252, 4, 4]               0\n",
      "          Conv2d-348             [-1, 48, 4, 4]          12,096\n",
      "     BatchNorm2d-349             [-1, 48, 4, 4]              96\n",
      "            ReLU-350             [-1, 48, 4, 4]               0\n",
      "          Conv2d-351             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-352            [-1, 264, 4, 4]               0\n",
      "     BatchNorm2d-353            [-1, 264, 4, 4]             528\n",
      "            ReLU-354            [-1, 264, 4, 4]               0\n",
      "          Conv2d-355             [-1, 48, 4, 4]          12,672\n",
      "     BatchNorm2d-356             [-1, 48, 4, 4]              96\n",
      "            ReLU-357             [-1, 48, 4, 4]               0\n",
      "          Conv2d-358             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-359            [-1, 276, 4, 4]               0\n",
      "     BatchNorm2d-360            [-1, 276, 4, 4]             552\n",
      "            ReLU-361            [-1, 276, 4, 4]               0\n",
      "          Conv2d-362             [-1, 48, 4, 4]          13,248\n",
      "     BatchNorm2d-363             [-1, 48, 4, 4]              96\n",
      "            ReLU-364             [-1, 48, 4, 4]               0\n",
      "          Conv2d-365             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-366            [-1, 288, 4, 4]               0\n",
      "     BatchNorm2d-367            [-1, 288, 4, 4]             576\n",
      "            ReLU-368            [-1, 288, 4, 4]               0\n",
      "          Conv2d-369             [-1, 48, 4, 4]          13,824\n",
      "     BatchNorm2d-370             [-1, 48, 4, 4]              96\n",
      "            ReLU-371             [-1, 48, 4, 4]               0\n",
      "          Conv2d-372             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-373            [-1, 300, 4, 4]               0\n",
      "     BatchNorm2d-374            [-1, 300, 4, 4]             600\n",
      "            ReLU-375            [-1, 300, 4, 4]               0\n",
      "          Conv2d-376             [-1, 48, 4, 4]          14,400\n",
      "     BatchNorm2d-377             [-1, 48, 4, 4]              96\n",
      "            ReLU-378             [-1, 48, 4, 4]               0\n",
      "          Conv2d-379             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-380            [-1, 312, 4, 4]               0\n",
      "     BatchNorm2d-381            [-1, 312, 4, 4]             624\n",
      "            ReLU-382            [-1, 312, 4, 4]               0\n",
      "          Conv2d-383             [-1, 48, 4, 4]          14,976\n",
      "     BatchNorm2d-384             [-1, 48, 4, 4]              96\n",
      "            ReLU-385             [-1, 48, 4, 4]               0\n",
      "          Conv2d-386             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-387            [-1, 324, 4, 4]               0\n",
      "     BatchNorm2d-388            [-1, 324, 4, 4]             648\n",
      "            ReLU-389            [-1, 324, 4, 4]               0\n",
      "          Conv2d-390             [-1, 48, 4, 4]          15,552\n",
      "     BatchNorm2d-391             [-1, 48, 4, 4]              96\n",
      "            ReLU-392             [-1, 48, 4, 4]               0\n",
      "          Conv2d-393             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-394            [-1, 336, 4, 4]               0\n",
      "     BatchNorm2d-395            [-1, 336, 4, 4]             672\n",
      "            ReLU-396            [-1, 336, 4, 4]               0\n",
      "          Conv2d-397             [-1, 48, 4, 4]          16,128\n",
      "     BatchNorm2d-398             [-1, 48, 4, 4]              96\n",
      "            ReLU-399             [-1, 48, 4, 4]               0\n",
      "          Conv2d-400             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-401            [-1, 348, 4, 4]               0\n",
      "     BatchNorm2d-402            [-1, 348, 4, 4]             696\n",
      "            ReLU-403            [-1, 348, 4, 4]               0\n",
      "          Conv2d-404             [-1, 48, 4, 4]          16,704\n",
      "     BatchNorm2d-405             [-1, 48, 4, 4]              96\n",
      "            ReLU-406             [-1, 48, 4, 4]               0\n",
      "          Conv2d-407             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-408            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-409            [-1, 360, 4, 4]             720\n",
      "            ReLU-410            [-1, 360, 4, 4]               0\n",
      "          Conv2d-411             [-1, 48, 4, 4]          17,280\n",
      "     BatchNorm2d-412             [-1, 48, 4, 4]              96\n",
      "            ReLU-413             [-1, 48, 4, 4]               0\n",
      "          Conv2d-414             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-415            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-416            [-1, 372, 4, 4]             744\n",
      "            ReLU-417            [-1, 372, 4, 4]               0\n",
      "          Conv2d-418             [-1, 48, 4, 4]          17,856\n",
      "     BatchNorm2d-419             [-1, 48, 4, 4]              96\n",
      "            ReLU-420             [-1, 48, 4, 4]               0\n",
      "          Conv2d-421             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-422            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-423            [-1, 384, 4, 4]             768\n",
      "            ReLU-424            [-1, 384, 4, 4]               0\n",
      "       AvgPool2d-425            [-1, 384, 1, 1]               0\n",
      "          Linear-426                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 997,538\n",
      "Trainable params: 997,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 43.49\n",
      "Params size (MB): 3.81\n",
      "Estimated Total Size (MB): 47.31\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 132640896.0\n",
      "MACs: 66320448.0\n",
      "Parameters: 997538.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.6404 seconds\n",
      "TP: 57.00\n",
      "FN: 6.00\n",
      "TN: 43.00\n",
      "FP: 1.00\n",
      "Acc: 93.46%\n",
      "Se: 90.48%\n",
      "Sp: 97.73%\n",
      "MAcc: 94.10%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_small_compression.pth' \\\n",
    "--num_blocks 6 12 24 16 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 48, 32, 32]           3,456\n",
      "      BatchNorm2d-33           [-1, 48, 32, 32]              96\n",
      "             ReLU-34           [-1, 48, 32, 32]               0\n",
      "           Conv2d-35           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-36           [-1, 84, 32, 32]               0\n",
      "      BatchNorm2d-37           [-1, 84, 32, 32]             168\n",
      "             ReLU-38           [-1, 84, 32, 32]               0\n",
      "           Conv2d-39           [-1, 48, 32, 32]           4,032\n",
      "      BatchNorm2d-40           [-1, 48, 32, 32]              96\n",
      "             ReLU-41           [-1, 48, 32, 32]               0\n",
      "           Conv2d-42           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-43           [-1, 96, 32, 32]               0\n",
      "      BatchNorm2d-44           [-1, 96, 32, 32]             192\n",
      "             ReLU-45           [-1, 96, 32, 32]               0\n",
      "           Conv2d-46           [-1, 48, 32, 32]           4,608\n",
      "      BatchNorm2d-47           [-1, 48, 32, 32]              96\n",
      "             ReLU-48           [-1, 48, 32, 32]               0\n",
      "           Conv2d-49           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-50          [-1, 108, 32, 32]               0\n",
      "      BatchNorm2d-51          [-1, 108, 32, 32]             216\n",
      "             ReLU-52          [-1, 108, 32, 32]               0\n",
      "           Conv2d-53           [-1, 48, 32, 32]           5,184\n",
      "      BatchNorm2d-54           [-1, 48, 32, 32]              96\n",
      "             ReLU-55           [-1, 48, 32, 32]               0\n",
      "           Conv2d-56           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-57          [-1, 120, 32, 32]               0\n",
      "      BatchNorm2d-58          [-1, 120, 32, 32]             240\n",
      "             ReLU-59          [-1, 120, 32, 32]               0\n",
      "           Conv2d-60           [-1, 60, 32, 32]           7,200\n",
      "        AvgPool2d-61           [-1, 60, 16, 16]               0\n",
      "       Transition-62           [-1, 60, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 60, 16, 16]             120\n",
      "             ReLU-64           [-1, 60, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           2,880\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 72, 16, 16]             144\n",
      "             ReLU-71           [-1, 72, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-77           [-1, 84, 16, 16]             168\n",
      "             ReLU-78           [-1, 84, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-84           [-1, 96, 16, 16]             192\n",
      "             ReLU-85           [-1, 96, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 108, 16, 16]             216\n",
      "             ReLU-92          [-1, 108, 16, 16]               0\n",
      "           Conv2d-93           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-94           [-1, 48, 16, 16]              96\n",
      "             ReLU-95           [-1, 48, 16, 16]               0\n",
      "           Conv2d-96           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-97          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-98          [-1, 120, 16, 16]             240\n",
      "             ReLU-99          [-1, 120, 16, 16]               0\n",
      "          Conv2d-100           [-1, 48, 16, 16]           5,760\n",
      "     BatchNorm2d-101           [-1, 48, 16, 16]              96\n",
      "            ReLU-102           [-1, 48, 16, 16]               0\n",
      "          Conv2d-103           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-104          [-1, 132, 16, 16]               0\n",
      "     BatchNorm2d-105          [-1, 132, 16, 16]             264\n",
      "            ReLU-106          [-1, 132, 16, 16]               0\n",
      "          Conv2d-107           [-1, 48, 16, 16]           6,336\n",
      "     BatchNorm2d-108           [-1, 48, 16, 16]              96\n",
      "            ReLU-109           [-1, 48, 16, 16]               0\n",
      "          Conv2d-110           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-111          [-1, 144, 16, 16]               0\n",
      "     BatchNorm2d-112          [-1, 144, 16, 16]             288\n",
      "            ReLU-113          [-1, 144, 16, 16]               0\n",
      "          Conv2d-114           [-1, 48, 16, 16]           6,912\n",
      "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
      "            ReLU-116           [-1, 48, 16, 16]               0\n",
      "          Conv2d-117           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-118          [-1, 156, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 156, 16, 16]             312\n",
      "            ReLU-120          [-1, 156, 16, 16]               0\n",
      "          Conv2d-121           [-1, 48, 16, 16]           7,488\n",
      "     BatchNorm2d-122           [-1, 48, 16, 16]              96\n",
      "            ReLU-123           [-1, 48, 16, 16]               0\n",
      "          Conv2d-124           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-125          [-1, 168, 16, 16]               0\n",
      "     BatchNorm2d-126          [-1, 168, 16, 16]             336\n",
      "            ReLU-127          [-1, 168, 16, 16]               0\n",
      "          Conv2d-128           [-1, 48, 16, 16]           8,064\n",
      "     BatchNorm2d-129           [-1, 48, 16, 16]              96\n",
      "            ReLU-130           [-1, 48, 16, 16]               0\n",
      "          Conv2d-131           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-132          [-1, 180, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 180, 16, 16]             360\n",
      "            ReLU-134          [-1, 180, 16, 16]               0\n",
      "          Conv2d-135           [-1, 48, 16, 16]           8,640\n",
      "     BatchNorm2d-136           [-1, 48, 16, 16]              96\n",
      "            ReLU-137           [-1, 48, 16, 16]               0\n",
      "          Conv2d-138           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-139          [-1, 192, 16, 16]               0\n",
      "     BatchNorm2d-140          [-1, 192, 16, 16]             384\n",
      "            ReLU-141          [-1, 192, 16, 16]               0\n",
      "          Conv2d-142           [-1, 48, 16, 16]           9,216\n",
      "     BatchNorm2d-143           [-1, 48, 16, 16]              96\n",
      "            ReLU-144           [-1, 48, 16, 16]               0\n",
      "          Conv2d-145           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-146          [-1, 204, 16, 16]               0\n",
      "     BatchNorm2d-147          [-1, 204, 16, 16]             408\n",
      "            ReLU-148          [-1, 204, 16, 16]               0\n",
      "          Conv2d-149           [-1, 48, 16, 16]           9,792\n",
      "     BatchNorm2d-150           [-1, 48, 16, 16]              96\n",
      "            ReLU-151           [-1, 48, 16, 16]               0\n",
      "          Conv2d-152           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-153          [-1, 216, 16, 16]               0\n",
      "     BatchNorm2d-154          [-1, 216, 16, 16]             432\n",
      "            ReLU-155          [-1, 216, 16, 16]               0\n",
      "          Conv2d-156           [-1, 48, 16, 16]          10,368\n",
      "     BatchNorm2d-157           [-1, 48, 16, 16]              96\n",
      "            ReLU-158           [-1, 48, 16, 16]               0\n",
      "          Conv2d-159           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-160          [-1, 228, 16, 16]               0\n",
      "     BatchNorm2d-161          [-1, 228, 16, 16]             456\n",
      "            ReLU-162          [-1, 228, 16, 16]               0\n",
      "          Conv2d-163           [-1, 48, 16, 16]          10,944\n",
      "     BatchNorm2d-164           [-1, 48, 16, 16]              96\n",
      "            ReLU-165           [-1, 48, 16, 16]               0\n",
      "          Conv2d-166           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-167          [-1, 240, 16, 16]               0\n",
      "     BatchNorm2d-168          [-1, 240, 16, 16]             480\n",
      "            ReLU-169          [-1, 240, 16, 16]               0\n",
      "          Conv2d-170           [-1, 48, 16, 16]          11,520\n",
      "     BatchNorm2d-171           [-1, 48, 16, 16]              96\n",
      "            ReLU-172           [-1, 48, 16, 16]               0\n",
      "          Conv2d-173           [-1, 12, 16, 16]           5,184\n",
      "      Bottleneck-174          [-1, 252, 16, 16]               0\n",
      "     BatchNorm2d-175          [-1, 252, 16, 16]             504\n",
      "            ReLU-176          [-1, 252, 16, 16]               0\n",
      "          Conv2d-177          [-1, 126, 16, 16]          31,752\n",
      "       AvgPool2d-178            [-1, 126, 8, 8]               0\n",
      "      Transition-179            [-1, 126, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 126, 8, 8]             252\n",
      "            ReLU-181            [-1, 126, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]           6,048\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 138, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 138, 8, 8]             276\n",
      "            ReLU-188            [-1, 138, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]           6,624\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 150, 8, 8]             300\n",
      "            ReLU-195            [-1, 150, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]           7,200\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 162, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 162, 8, 8]             324\n",
      "            ReLU-202            [-1, 162, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]           7,776\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 174, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 174, 8, 8]             348\n",
      "            ReLU-209            [-1, 174, 8, 8]               0\n",
      "          Conv2d-210             [-1, 48, 8, 8]           8,352\n",
      "     BatchNorm2d-211             [-1, 48, 8, 8]              96\n",
      "            ReLU-212             [-1, 48, 8, 8]               0\n",
      "          Conv2d-213             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-214            [-1, 186, 8, 8]               0\n",
      "     BatchNorm2d-215            [-1, 186, 8, 8]             372\n",
      "            ReLU-216            [-1, 186, 8, 8]               0\n",
      "          Conv2d-217             [-1, 48, 8, 8]           8,928\n",
      "     BatchNorm2d-218             [-1, 48, 8, 8]              96\n",
      "            ReLU-219             [-1, 48, 8, 8]               0\n",
      "          Conv2d-220             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-221            [-1, 198, 8, 8]               0\n",
      "     BatchNorm2d-222            [-1, 198, 8, 8]             396\n",
      "            ReLU-223            [-1, 198, 8, 8]               0\n",
      "          Conv2d-224             [-1, 48, 8, 8]           9,504\n",
      "     BatchNorm2d-225             [-1, 48, 8, 8]              96\n",
      "            ReLU-226             [-1, 48, 8, 8]               0\n",
      "          Conv2d-227             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-228            [-1, 210, 8, 8]               0\n",
      "     BatchNorm2d-229            [-1, 210, 8, 8]             420\n",
      "            ReLU-230            [-1, 210, 8, 8]               0\n",
      "          Conv2d-231             [-1, 48, 8, 8]          10,080\n",
      "     BatchNorm2d-232             [-1, 48, 8, 8]              96\n",
      "            ReLU-233             [-1, 48, 8, 8]               0\n",
      "          Conv2d-234             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-235            [-1, 222, 8, 8]               0\n",
      "     BatchNorm2d-236            [-1, 222, 8, 8]             444\n",
      "            ReLU-237            [-1, 222, 8, 8]               0\n",
      "          Conv2d-238             [-1, 48, 8, 8]          10,656\n",
      "     BatchNorm2d-239             [-1, 48, 8, 8]              96\n",
      "            ReLU-240             [-1, 48, 8, 8]               0\n",
      "          Conv2d-241             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-242            [-1, 234, 8, 8]               0\n",
      "     BatchNorm2d-243            [-1, 234, 8, 8]             468\n",
      "            ReLU-244            [-1, 234, 8, 8]               0\n",
      "          Conv2d-245             [-1, 48, 8, 8]          11,232\n",
      "     BatchNorm2d-246             [-1, 48, 8, 8]              96\n",
      "            ReLU-247             [-1, 48, 8, 8]               0\n",
      "          Conv2d-248             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-249            [-1, 246, 8, 8]               0\n",
      "     BatchNorm2d-250            [-1, 246, 8, 8]             492\n",
      "            ReLU-251            [-1, 246, 8, 8]               0\n",
      "          Conv2d-252             [-1, 48, 8, 8]          11,808\n",
      "     BatchNorm2d-253             [-1, 48, 8, 8]              96\n",
      "            ReLU-254             [-1, 48, 8, 8]               0\n",
      "          Conv2d-255             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-256            [-1, 258, 8, 8]               0\n",
      "     BatchNorm2d-257            [-1, 258, 8, 8]             516\n",
      "            ReLU-258            [-1, 258, 8, 8]               0\n",
      "          Conv2d-259             [-1, 48, 8, 8]          12,384\n",
      "     BatchNorm2d-260             [-1, 48, 8, 8]              96\n",
      "            ReLU-261             [-1, 48, 8, 8]               0\n",
      "          Conv2d-262             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-263            [-1, 270, 8, 8]               0\n",
      "     BatchNorm2d-264            [-1, 270, 8, 8]             540\n",
      "            ReLU-265            [-1, 270, 8, 8]               0\n",
      "          Conv2d-266             [-1, 48, 8, 8]          12,960\n",
      "     BatchNorm2d-267             [-1, 48, 8, 8]              96\n",
      "            ReLU-268             [-1, 48, 8, 8]               0\n",
      "          Conv2d-269             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-270            [-1, 282, 8, 8]               0\n",
      "     BatchNorm2d-271            [-1, 282, 8, 8]             564\n",
      "            ReLU-272            [-1, 282, 8, 8]               0\n",
      "          Conv2d-273             [-1, 48, 8, 8]          13,536\n",
      "     BatchNorm2d-274             [-1, 48, 8, 8]              96\n",
      "            ReLU-275             [-1, 48, 8, 8]               0\n",
      "          Conv2d-276             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-277            [-1, 294, 8, 8]               0\n",
      "     BatchNorm2d-278            [-1, 294, 8, 8]             588\n",
      "            ReLU-279            [-1, 294, 8, 8]               0\n",
      "          Conv2d-280             [-1, 48, 8, 8]          14,112\n",
      "     BatchNorm2d-281             [-1, 48, 8, 8]              96\n",
      "            ReLU-282             [-1, 48, 8, 8]               0\n",
      "          Conv2d-283             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-284            [-1, 306, 8, 8]               0\n",
      "     BatchNorm2d-285            [-1, 306, 8, 8]             612\n",
      "            ReLU-286            [-1, 306, 8, 8]               0\n",
      "          Conv2d-287             [-1, 48, 8, 8]          14,688\n",
      "     BatchNorm2d-288             [-1, 48, 8, 8]              96\n",
      "            ReLU-289             [-1, 48, 8, 8]               0\n",
      "          Conv2d-290             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-291            [-1, 318, 8, 8]               0\n",
      "     BatchNorm2d-292            [-1, 318, 8, 8]             636\n",
      "            ReLU-293            [-1, 318, 8, 8]               0\n",
      "          Conv2d-294             [-1, 48, 8, 8]          15,264\n",
      "     BatchNorm2d-295             [-1, 48, 8, 8]              96\n",
      "            ReLU-296             [-1, 48, 8, 8]               0\n",
      "          Conv2d-297             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-298            [-1, 330, 8, 8]               0\n",
      "     BatchNorm2d-299            [-1, 330, 8, 8]             660\n",
      "            ReLU-300            [-1, 330, 8, 8]               0\n",
      "          Conv2d-301             [-1, 48, 8, 8]          15,840\n",
      "     BatchNorm2d-302             [-1, 48, 8, 8]              96\n",
      "            ReLU-303             [-1, 48, 8, 8]               0\n",
      "          Conv2d-304             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-305            [-1, 342, 8, 8]               0\n",
      "     BatchNorm2d-306            [-1, 342, 8, 8]             684\n",
      "            ReLU-307            [-1, 342, 8, 8]               0\n",
      "          Conv2d-308             [-1, 48, 8, 8]          16,416\n",
      "     BatchNorm2d-309             [-1, 48, 8, 8]              96\n",
      "            ReLU-310             [-1, 48, 8, 8]               0\n",
      "          Conv2d-311             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-312            [-1, 354, 8, 8]               0\n",
      "     BatchNorm2d-313            [-1, 354, 8, 8]             708\n",
      "            ReLU-314            [-1, 354, 8, 8]               0\n",
      "          Conv2d-315             [-1, 48, 8, 8]          16,992\n",
      "     BatchNorm2d-316             [-1, 48, 8, 8]              96\n",
      "            ReLU-317             [-1, 48, 8, 8]               0\n",
      "          Conv2d-318             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-319            [-1, 366, 8, 8]               0\n",
      "     BatchNorm2d-320            [-1, 366, 8, 8]             732\n",
      "            ReLU-321            [-1, 366, 8, 8]               0\n",
      "          Conv2d-322             [-1, 48, 8, 8]          17,568\n",
      "     BatchNorm2d-323             [-1, 48, 8, 8]              96\n",
      "            ReLU-324             [-1, 48, 8, 8]               0\n",
      "          Conv2d-325             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-326            [-1, 378, 8, 8]               0\n",
      "     BatchNorm2d-327            [-1, 378, 8, 8]             756\n",
      "            ReLU-328            [-1, 378, 8, 8]               0\n",
      "          Conv2d-329             [-1, 48, 8, 8]          18,144\n",
      "     BatchNorm2d-330             [-1, 48, 8, 8]              96\n",
      "            ReLU-331             [-1, 48, 8, 8]               0\n",
      "          Conv2d-332             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-333            [-1, 390, 8, 8]               0\n",
      "     BatchNorm2d-334            [-1, 390, 8, 8]             780\n",
      "            ReLU-335            [-1, 390, 8, 8]               0\n",
      "          Conv2d-336             [-1, 48, 8, 8]          18,720\n",
      "     BatchNorm2d-337             [-1, 48, 8, 8]              96\n",
      "            ReLU-338             [-1, 48, 8, 8]               0\n",
      "          Conv2d-339             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-340            [-1, 402, 8, 8]               0\n",
      "     BatchNorm2d-341            [-1, 402, 8, 8]             804\n",
      "            ReLU-342            [-1, 402, 8, 8]               0\n",
      "          Conv2d-343             [-1, 48, 8, 8]          19,296\n",
      "     BatchNorm2d-344             [-1, 48, 8, 8]              96\n",
      "            ReLU-345             [-1, 48, 8, 8]               0\n",
      "          Conv2d-346             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-347            [-1, 414, 8, 8]               0\n",
      "     BatchNorm2d-348            [-1, 414, 8, 8]             828\n",
      "            ReLU-349            [-1, 414, 8, 8]               0\n",
      "          Conv2d-350             [-1, 48, 8, 8]          19,872\n",
      "     BatchNorm2d-351             [-1, 48, 8, 8]              96\n",
      "            ReLU-352             [-1, 48, 8, 8]               0\n",
      "          Conv2d-353             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-354            [-1, 426, 8, 8]               0\n",
      "     BatchNorm2d-355            [-1, 426, 8, 8]             852\n",
      "            ReLU-356            [-1, 426, 8, 8]               0\n",
      "          Conv2d-357             [-1, 48, 8, 8]          20,448\n",
      "     BatchNorm2d-358             [-1, 48, 8, 8]              96\n",
      "            ReLU-359             [-1, 48, 8, 8]               0\n",
      "          Conv2d-360             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-361            [-1, 438, 8, 8]               0\n",
      "     BatchNorm2d-362            [-1, 438, 8, 8]             876\n",
      "            ReLU-363            [-1, 438, 8, 8]               0\n",
      "          Conv2d-364             [-1, 48, 8, 8]          21,024\n",
      "     BatchNorm2d-365             [-1, 48, 8, 8]              96\n",
      "            ReLU-366             [-1, 48, 8, 8]               0\n",
      "          Conv2d-367             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-368            [-1, 450, 8, 8]               0\n",
      "     BatchNorm2d-369            [-1, 450, 8, 8]             900\n",
      "            ReLU-370            [-1, 450, 8, 8]               0\n",
      "          Conv2d-371             [-1, 48, 8, 8]          21,600\n",
      "     BatchNorm2d-372             [-1, 48, 8, 8]              96\n",
      "            ReLU-373             [-1, 48, 8, 8]               0\n",
      "          Conv2d-374             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-375            [-1, 462, 8, 8]               0\n",
      "     BatchNorm2d-376            [-1, 462, 8, 8]             924\n",
      "            ReLU-377            [-1, 462, 8, 8]               0\n",
      "          Conv2d-378             [-1, 48, 8, 8]          22,176\n",
      "     BatchNorm2d-379             [-1, 48, 8, 8]              96\n",
      "            ReLU-380             [-1, 48, 8, 8]               0\n",
      "          Conv2d-381             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-382            [-1, 474, 8, 8]               0\n",
      "     BatchNorm2d-383            [-1, 474, 8, 8]             948\n",
      "            ReLU-384            [-1, 474, 8, 8]               0\n",
      "          Conv2d-385             [-1, 48, 8, 8]          22,752\n",
      "     BatchNorm2d-386             [-1, 48, 8, 8]              96\n",
      "            ReLU-387             [-1, 48, 8, 8]               0\n",
      "          Conv2d-388             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-389            [-1, 486, 8, 8]               0\n",
      "     BatchNorm2d-390            [-1, 486, 8, 8]             972\n",
      "            ReLU-391            [-1, 486, 8, 8]               0\n",
      "          Conv2d-392             [-1, 48, 8, 8]          23,328\n",
      "     BatchNorm2d-393             [-1, 48, 8, 8]              96\n",
      "            ReLU-394             [-1, 48, 8, 8]               0\n",
      "          Conv2d-395             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-396            [-1, 498, 8, 8]               0\n",
      "     BatchNorm2d-397            [-1, 498, 8, 8]             996\n",
      "            ReLU-398            [-1, 498, 8, 8]               0\n",
      "          Conv2d-399             [-1, 48, 8, 8]          23,904\n",
      "     BatchNorm2d-400             [-1, 48, 8, 8]              96\n",
      "            ReLU-401             [-1, 48, 8, 8]               0\n",
      "          Conv2d-402             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-403            [-1, 510, 8, 8]               0\n",
      "     BatchNorm2d-404            [-1, 510, 8, 8]           1,020\n",
      "            ReLU-405            [-1, 510, 8, 8]               0\n",
      "          Conv2d-406            [-1, 255, 8, 8]         130,050\n",
      "       AvgPool2d-407            [-1, 255, 4, 4]               0\n",
      "      Transition-408            [-1, 255, 4, 4]               0\n",
      "     BatchNorm2d-409            [-1, 255, 4, 4]             510\n",
      "            ReLU-410            [-1, 255, 4, 4]               0\n",
      "          Conv2d-411             [-1, 48, 4, 4]          12,240\n",
      "     BatchNorm2d-412             [-1, 48, 4, 4]              96\n",
      "            ReLU-413             [-1, 48, 4, 4]               0\n",
      "          Conv2d-414             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-415            [-1, 267, 4, 4]               0\n",
      "     BatchNorm2d-416            [-1, 267, 4, 4]             534\n",
      "            ReLU-417            [-1, 267, 4, 4]               0\n",
      "          Conv2d-418             [-1, 48, 4, 4]          12,816\n",
      "     BatchNorm2d-419             [-1, 48, 4, 4]              96\n",
      "            ReLU-420             [-1, 48, 4, 4]               0\n",
      "          Conv2d-421             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-422            [-1, 279, 4, 4]               0\n",
      "     BatchNorm2d-423            [-1, 279, 4, 4]             558\n",
      "            ReLU-424            [-1, 279, 4, 4]               0\n",
      "          Conv2d-425             [-1, 48, 4, 4]          13,392\n",
      "     BatchNorm2d-426             [-1, 48, 4, 4]              96\n",
      "            ReLU-427             [-1, 48, 4, 4]               0\n",
      "          Conv2d-428             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-429            [-1, 291, 4, 4]               0\n",
      "     BatchNorm2d-430            [-1, 291, 4, 4]             582\n",
      "            ReLU-431            [-1, 291, 4, 4]               0\n",
      "          Conv2d-432             [-1, 48, 4, 4]          13,968\n",
      "     BatchNorm2d-433             [-1, 48, 4, 4]              96\n",
      "            ReLU-434             [-1, 48, 4, 4]               0\n",
      "          Conv2d-435             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-436            [-1, 303, 4, 4]               0\n",
      "     BatchNorm2d-437            [-1, 303, 4, 4]             606\n",
      "            ReLU-438            [-1, 303, 4, 4]               0\n",
      "          Conv2d-439             [-1, 48, 4, 4]          14,544\n",
      "     BatchNorm2d-440             [-1, 48, 4, 4]              96\n",
      "            ReLU-441             [-1, 48, 4, 4]               0\n",
      "          Conv2d-442             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-443            [-1, 315, 4, 4]               0\n",
      "     BatchNorm2d-444            [-1, 315, 4, 4]             630\n",
      "            ReLU-445            [-1, 315, 4, 4]               0\n",
      "          Conv2d-446             [-1, 48, 4, 4]          15,120\n",
      "     BatchNorm2d-447             [-1, 48, 4, 4]              96\n",
      "            ReLU-448             [-1, 48, 4, 4]               0\n",
      "          Conv2d-449             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-450            [-1, 327, 4, 4]               0\n",
      "     BatchNorm2d-451            [-1, 327, 4, 4]             654\n",
      "            ReLU-452            [-1, 327, 4, 4]               0\n",
      "          Conv2d-453             [-1, 48, 4, 4]          15,696\n",
      "     BatchNorm2d-454             [-1, 48, 4, 4]              96\n",
      "            ReLU-455             [-1, 48, 4, 4]               0\n",
      "          Conv2d-456             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-457            [-1, 339, 4, 4]               0\n",
      "     BatchNorm2d-458            [-1, 339, 4, 4]             678\n",
      "            ReLU-459            [-1, 339, 4, 4]               0\n",
      "          Conv2d-460             [-1, 48, 4, 4]          16,272\n",
      "     BatchNorm2d-461             [-1, 48, 4, 4]              96\n",
      "            ReLU-462             [-1, 48, 4, 4]               0\n",
      "          Conv2d-463             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-464            [-1, 351, 4, 4]               0\n",
      "     BatchNorm2d-465            [-1, 351, 4, 4]             702\n",
      "            ReLU-466            [-1, 351, 4, 4]               0\n",
      "          Conv2d-467             [-1, 48, 4, 4]          16,848\n",
      "     BatchNorm2d-468             [-1, 48, 4, 4]              96\n",
      "            ReLU-469             [-1, 48, 4, 4]               0\n",
      "          Conv2d-470             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-471            [-1, 363, 4, 4]               0\n",
      "     BatchNorm2d-472            [-1, 363, 4, 4]             726\n",
      "            ReLU-473            [-1, 363, 4, 4]               0\n",
      "          Conv2d-474             [-1, 48, 4, 4]          17,424\n",
      "     BatchNorm2d-475             [-1, 48, 4, 4]              96\n",
      "            ReLU-476             [-1, 48, 4, 4]               0\n",
      "          Conv2d-477             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-478            [-1, 375, 4, 4]               0\n",
      "     BatchNorm2d-479            [-1, 375, 4, 4]             750\n",
      "            ReLU-480            [-1, 375, 4, 4]               0\n",
      "          Conv2d-481             [-1, 48, 4, 4]          18,000\n",
      "     BatchNorm2d-482             [-1, 48, 4, 4]              96\n",
      "            ReLU-483             [-1, 48, 4, 4]               0\n",
      "          Conv2d-484             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-485            [-1, 387, 4, 4]               0\n",
      "     BatchNorm2d-486            [-1, 387, 4, 4]             774\n",
      "            ReLU-487            [-1, 387, 4, 4]               0\n",
      "          Conv2d-488             [-1, 48, 4, 4]          18,576\n",
      "     BatchNorm2d-489             [-1, 48, 4, 4]              96\n",
      "            ReLU-490             [-1, 48, 4, 4]               0\n",
      "          Conv2d-491             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-492            [-1, 399, 4, 4]               0\n",
      "     BatchNorm2d-493            [-1, 399, 4, 4]             798\n",
      "            ReLU-494            [-1, 399, 4, 4]               0\n",
      "          Conv2d-495             [-1, 48, 4, 4]          19,152\n",
      "     BatchNorm2d-496             [-1, 48, 4, 4]              96\n",
      "            ReLU-497             [-1, 48, 4, 4]               0\n",
      "          Conv2d-498             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-499            [-1, 411, 4, 4]               0\n",
      "     BatchNorm2d-500            [-1, 411, 4, 4]             822\n",
      "            ReLU-501            [-1, 411, 4, 4]               0\n",
      "          Conv2d-502             [-1, 48, 4, 4]          19,728\n",
      "     BatchNorm2d-503             [-1, 48, 4, 4]              96\n",
      "            ReLU-504             [-1, 48, 4, 4]               0\n",
      "          Conv2d-505             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-506            [-1, 423, 4, 4]               0\n",
      "     BatchNorm2d-507            [-1, 423, 4, 4]             846\n",
      "            ReLU-508            [-1, 423, 4, 4]               0\n",
      "          Conv2d-509             [-1, 48, 4, 4]          20,304\n",
      "     BatchNorm2d-510             [-1, 48, 4, 4]              96\n",
      "            ReLU-511             [-1, 48, 4, 4]               0\n",
      "          Conv2d-512             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-513            [-1, 435, 4, 4]               0\n",
      "     BatchNorm2d-514            [-1, 435, 4, 4]             870\n",
      "            ReLU-515            [-1, 435, 4, 4]               0\n",
      "          Conv2d-516             [-1, 48, 4, 4]          20,880\n",
      "     BatchNorm2d-517             [-1, 48, 4, 4]              96\n",
      "            ReLU-518             [-1, 48, 4, 4]               0\n",
      "          Conv2d-519             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-520            [-1, 447, 4, 4]               0\n",
      "     BatchNorm2d-521            [-1, 447, 4, 4]             894\n",
      "            ReLU-522            [-1, 447, 4, 4]               0\n",
      "       AvgPool2d-523            [-1, 447, 1, 1]               0\n",
      "          Linear-524                    [-1, 2]             896\n",
      "================================================================\n",
      "Total params: 1,474,964\n",
      "Trainable params: 1,474,964\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.70\n",
      "Params size (MB): 5.63\n",
      "Estimated Total Size (MB): 72.34\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 201755373.0\n",
      "MACs: 100877686.5\n",
      "Parameters: 1474964.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.8742 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 41.00\n",
      "FP: 3.00\n",
      "Acc: 94.39%\n",
      "Se: 95.24%\n",
      "Sp: 93.18%\n",
      "MAcc: 94.21%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_large_compression.pth' \\\n",
    "--num_blocks 8 16 32 16 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 72, 32, 32]           5,184\n",
      "        AvgPool2d-33           [-1, 72, 16, 16]               0\n",
      "       Transition-34           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 72, 16, 16]             144\n",
      "             ReLU-36           [-1, 72, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 84, 16, 16]             168\n",
      "             ReLU-43           [-1, 84, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 96, 16, 16]             192\n",
      "             ReLU-50           [-1, 96, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-56          [-1, 108, 16, 16]             216\n",
      "             ReLU-57          [-1, 108, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-63          [-1, 120, 16, 16]             240\n",
      "             ReLU-64          [-1, 120, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-70          [-1, 132, 16, 16]             264\n",
      "             ReLU-71          [-1, 132, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           6,336\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76          [-1, 144, 16, 16]               0\n",
      "      BatchNorm2d-77          [-1, 144, 16, 16]             288\n",
      "             ReLU-78          [-1, 144, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           6,912\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 156, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 156, 16, 16]             312\n",
      "             ReLU-85          [-1, 156, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           7,488\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 168, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 168, 16, 16]             336\n",
      "             ReLU-92          [-1, 168, 16, 16]               0\n",
      "           Conv2d-93          [-1, 168, 16, 16]          28,224\n",
      "        AvgPool2d-94            [-1, 168, 8, 8]               0\n",
      "       Transition-95            [-1, 168, 8, 8]               0\n",
      "      BatchNorm2d-96            [-1, 168, 8, 8]             336\n",
      "             ReLU-97            [-1, 168, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           8,064\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-103            [-1, 180, 8, 8]             360\n",
      "            ReLU-104            [-1, 180, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           8,640\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-110            [-1, 192, 8, 8]             384\n",
      "            ReLU-111            [-1, 192, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           9,216\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-117            [-1, 204, 8, 8]             408\n",
      "            ReLU-118            [-1, 204, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           9,792\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 216, 8, 8]             432\n",
      "            ReLU-125            [-1, 216, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]          10,368\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-131            [-1, 228, 8, 8]             456\n",
      "            ReLU-132            [-1, 228, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]          10,944\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 240, 8, 8]             480\n",
      "            ReLU-139            [-1, 240, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]          11,520\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 252, 8, 8]             504\n",
      "            ReLU-146            [-1, 252, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]          12,096\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 264, 8, 8]             528\n",
      "            ReLU-153            [-1, 264, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]          12,672\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 276, 8, 8]             552\n",
      "            ReLU-160            [-1, 276, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]          13,248\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 288, 8, 8]             576\n",
      "            ReLU-167            [-1, 288, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]          13,824\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 300, 8, 8]             600\n",
      "            ReLU-174            [-1, 300, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]          14,400\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 312, 8, 8]             624\n",
      "            ReLU-181            [-1, 312, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]          14,976\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 324, 8, 8]             648\n",
      "            ReLU-188            [-1, 324, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]          15,552\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 336, 8, 8]             672\n",
      "            ReLU-195            [-1, 336, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]          16,128\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 348, 8, 8]             696\n",
      "            ReLU-202            [-1, 348, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          16,704\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 360, 8, 8]             720\n",
      "            ReLU-209            [-1, 360, 8, 8]               0\n",
      "          Conv2d-210            [-1, 360, 8, 8]         129,600\n",
      "       AvgPool2d-211            [-1, 360, 4, 4]               0\n",
      "      Transition-212            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 360, 4, 4]             720\n",
      "            ReLU-214            [-1, 360, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]          17,280\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-220            [-1, 372, 4, 4]             744\n",
      "            ReLU-221            [-1, 372, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]          17,856\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-227            [-1, 384, 4, 4]             768\n",
      "            ReLU-228            [-1, 384, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]          18,432\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 396, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 396, 4, 4]             792\n",
      "            ReLU-235            [-1, 396, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]          19,008\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 408, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 408, 4, 4]             816\n",
      "            ReLU-242            [-1, 408, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]          19,584\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 420, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 420, 4, 4]             840\n",
      "            ReLU-249            [-1, 420, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]          20,160\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 432, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 432, 4, 4]             864\n",
      "            ReLU-256            [-1, 432, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]          20,736\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 444, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 444, 4, 4]             888\n",
      "            ReLU-263            [-1, 444, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]          21,312\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 456, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 456, 4, 4]             912\n",
      "            ReLU-270            [-1, 456, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 456, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             914\n",
      "================================================================\n",
      "Total params: 777,962\n",
      "Trainable params: 777,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 29.89\n",
      "Params size (MB): 2.97\n",
      "Estimated Total Size (MB): 32.87\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 98839512.0\n",
      "MACs: 49419756.0\n",
      "Parameters: 777962.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.4590 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 43.00\n",
      "FP: 1.00\n",
      "Acc: 96.26%\n",
      "Se: 95.24%\n",
      "Sp: 97.73%\n",
      "MAcc: 96.48%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 50, 32, 32]           3,600\n",
      "        AvgPool2d-33           [-1, 50, 16, 16]               0\n",
      "       Transition-34           [-1, 50, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 50, 16, 16]             100\n",
      "             ReLU-36           [-1, 50, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           2,400\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 62, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 62, 16, 16]             124\n",
      "             ReLU-43           [-1, 62, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           2,976\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 74, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 74, 16, 16]             148\n",
      "             ReLU-50           [-1, 74, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           3,552\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55           [-1, 86, 16, 16]               0\n",
      "      BatchNorm2d-56           [-1, 86, 16, 16]             172\n",
      "             ReLU-57           [-1, 86, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           4,128\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62           [-1, 98, 16, 16]               0\n",
      "      BatchNorm2d-63           [-1, 98, 16, 16]             196\n",
      "             ReLU-64           [-1, 98, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           4,704\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69          [-1, 110, 16, 16]               0\n",
      "      BatchNorm2d-70          [-1, 110, 16, 16]             220\n",
      "             ReLU-71          [-1, 110, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           5,280\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76          [-1, 122, 16, 16]               0\n",
      "      BatchNorm2d-77          [-1, 122, 16, 16]             244\n",
      "             ReLU-78          [-1, 122, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           5,856\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 134, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 134, 16, 16]             268\n",
      "             ReLU-85          [-1, 134, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           6,432\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 146, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 146, 16, 16]             292\n",
      "             ReLU-92          [-1, 146, 16, 16]               0\n",
      "           Conv2d-93          [-1, 102, 16, 16]          14,892\n",
      "        AvgPool2d-94            [-1, 102, 8, 8]               0\n",
      "       Transition-95            [-1, 102, 8, 8]               0\n",
      "      BatchNorm2d-96            [-1, 102, 8, 8]             204\n",
      "             ReLU-97            [-1, 102, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           4,896\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102            [-1, 114, 8, 8]               0\n",
      "     BatchNorm2d-103            [-1, 114, 8, 8]             228\n",
      "            ReLU-104            [-1, 114, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           5,472\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109            [-1, 126, 8, 8]               0\n",
      "     BatchNorm2d-110            [-1, 126, 8, 8]             252\n",
      "            ReLU-111            [-1, 126, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           6,048\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116            [-1, 138, 8, 8]               0\n",
      "     BatchNorm2d-117            [-1, 138, 8, 8]             276\n",
      "            ReLU-118            [-1, 138, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           6,624\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123            [-1, 150, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 150, 8, 8]             300\n",
      "            ReLU-125            [-1, 150, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]           7,200\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130            [-1, 162, 8, 8]               0\n",
      "     BatchNorm2d-131            [-1, 162, 8, 8]             324\n",
      "            ReLU-132            [-1, 162, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]           7,776\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 174, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 174, 8, 8]             348\n",
      "            ReLU-139            [-1, 174, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]           8,352\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 186, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 186, 8, 8]             372\n",
      "            ReLU-146            [-1, 186, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]           8,928\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 198, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 198, 8, 8]             396\n",
      "            ReLU-153            [-1, 198, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]           9,504\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 210, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 210, 8, 8]             420\n",
      "            ReLU-160            [-1, 210, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]          10,080\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 222, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 222, 8, 8]             444\n",
      "            ReLU-167            [-1, 222, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]          10,656\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 234, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 234, 8, 8]             468\n",
      "            ReLU-174            [-1, 234, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]          11,232\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 246, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 246, 8, 8]             492\n",
      "            ReLU-181            [-1, 246, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]          11,808\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 258, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 258, 8, 8]             516\n",
      "            ReLU-188            [-1, 258, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]          12,384\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 270, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 270, 8, 8]             540\n",
      "            ReLU-195            [-1, 270, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]          12,960\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 282, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 282, 8, 8]             564\n",
      "            ReLU-202            [-1, 282, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          13,536\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 294, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 294, 8, 8]             588\n",
      "            ReLU-209            [-1, 294, 8, 8]               0\n",
      "          Conv2d-210            [-1, 205, 8, 8]          60,270\n",
      "       AvgPool2d-211            [-1, 205, 4, 4]               0\n",
      "      Transition-212            [-1, 205, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 205, 4, 4]             410\n",
      "            ReLU-214            [-1, 205, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]           9,840\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219            [-1, 217, 4, 4]               0\n",
      "     BatchNorm2d-220            [-1, 217, 4, 4]             434\n",
      "            ReLU-221            [-1, 217, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]          10,416\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226            [-1, 229, 4, 4]               0\n",
      "     BatchNorm2d-227            [-1, 229, 4, 4]             458\n",
      "            ReLU-228            [-1, 229, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]          10,992\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 241, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 241, 4, 4]             482\n",
      "            ReLU-235            [-1, 241, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]          11,568\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 253, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 253, 4, 4]             506\n",
      "            ReLU-242            [-1, 253, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]          12,144\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 265, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 265, 4, 4]             530\n",
      "            ReLU-249            [-1, 265, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]          12,720\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 277, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 277, 4, 4]             554\n",
      "            ReLU-256            [-1, 277, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]          13,296\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 289, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 289, 4, 4]             578\n",
      "            ReLU-263            [-1, 289, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]          13,872\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 301, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 301, 4, 4]             602\n",
      "            ReLU-270            [-1, 301, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 301, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             604\n",
      "================================================================\n",
      "Total params: 569,320\n",
      "Trainable params: 569,320\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 26.11\n",
      "Params size (MB): 2.17\n",
      "Estimated Total Size (MB): 28.29\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 82416279.0\n",
      "MACs: 41208139.5\n",
      "Parameters: 569320.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.3786 seconds\n",
      "TP: 60.00\n",
      "FN: 3.00\n",
      "TN: 41.00\n",
      "FP: 3.00\n",
      "Acc: 94.39%\n",
      "Se: 95.24%\n",
      "Sp: 93.18%\n",
      "MAcc: 94.21%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 32, 32]             648\n",
      "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
      "              ReLU-3           [-1, 24, 32, 32]               0\n",
      "            Conv2d-4           [-1, 48, 32, 32]           1,152\n",
      "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
      "              ReLU-6           [-1, 48, 32, 32]               0\n",
      "            Conv2d-7           [-1, 12, 32, 32]           5,184\n",
      "        Bottleneck-8           [-1, 36, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 36, 32, 32]              72\n",
      "             ReLU-10           [-1, 36, 32, 32]               0\n",
      "           Conv2d-11           [-1, 48, 32, 32]           1,728\n",
      "      BatchNorm2d-12           [-1, 48, 32, 32]              96\n",
      "             ReLU-13           [-1, 48, 32, 32]               0\n",
      "           Conv2d-14           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-15           [-1, 48, 32, 32]               0\n",
      "      BatchNorm2d-16           [-1, 48, 32, 32]              96\n",
      "             ReLU-17           [-1, 48, 32, 32]               0\n",
      "           Conv2d-18           [-1, 48, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 48, 32, 32]              96\n",
      "             ReLU-20           [-1, 48, 32, 32]               0\n",
      "           Conv2d-21           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-22           [-1, 60, 32, 32]               0\n",
      "      BatchNorm2d-23           [-1, 60, 32, 32]             120\n",
      "             ReLU-24           [-1, 60, 32, 32]               0\n",
      "           Conv2d-25           [-1, 48, 32, 32]           2,880\n",
      "      BatchNorm2d-26           [-1, 48, 32, 32]              96\n",
      "             ReLU-27           [-1, 48, 32, 32]               0\n",
      "           Conv2d-28           [-1, 12, 32, 32]           5,184\n",
      "       Bottleneck-29           [-1, 72, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 72, 32, 32]             144\n",
      "             ReLU-31           [-1, 72, 32, 32]               0\n",
      "           Conv2d-32           [-1, 72, 32, 32]           5,184\n",
      "        AvgPool2d-33           [-1, 72, 16, 16]               0\n",
      "       Transition-34           [-1, 72, 16, 16]               0\n",
      "      BatchNorm2d-35           [-1, 72, 16, 16]             144\n",
      "             ReLU-36           [-1, 72, 16, 16]               0\n",
      "           Conv2d-37           [-1, 48, 16, 16]           3,456\n",
      "      BatchNorm2d-38           [-1, 48, 16, 16]              96\n",
      "             ReLU-39           [-1, 48, 16, 16]               0\n",
      "           Conv2d-40           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-41           [-1, 84, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 84, 16, 16]             168\n",
      "             ReLU-43           [-1, 84, 16, 16]               0\n",
      "           Conv2d-44           [-1, 48, 16, 16]           4,032\n",
      "      BatchNorm2d-45           [-1, 48, 16, 16]              96\n",
      "             ReLU-46           [-1, 48, 16, 16]               0\n",
      "           Conv2d-47           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-48           [-1, 96, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 96, 16, 16]             192\n",
      "             ReLU-50           [-1, 96, 16, 16]               0\n",
      "           Conv2d-51           [-1, 48, 16, 16]           4,608\n",
      "      BatchNorm2d-52           [-1, 48, 16, 16]              96\n",
      "             ReLU-53           [-1, 48, 16, 16]               0\n",
      "           Conv2d-54           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-55          [-1, 108, 16, 16]               0\n",
      "      BatchNorm2d-56          [-1, 108, 16, 16]             216\n",
      "             ReLU-57          [-1, 108, 16, 16]               0\n",
      "           Conv2d-58           [-1, 48, 16, 16]           5,184\n",
      "      BatchNorm2d-59           [-1, 48, 16, 16]              96\n",
      "             ReLU-60           [-1, 48, 16, 16]               0\n",
      "           Conv2d-61           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-62          [-1, 120, 16, 16]               0\n",
      "      BatchNorm2d-63          [-1, 120, 16, 16]             240\n",
      "             ReLU-64          [-1, 120, 16, 16]               0\n",
      "           Conv2d-65           [-1, 48, 16, 16]           5,760\n",
      "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
      "             ReLU-67           [-1, 48, 16, 16]               0\n",
      "           Conv2d-68           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-69          [-1, 132, 16, 16]               0\n",
      "      BatchNorm2d-70          [-1, 132, 16, 16]             264\n",
      "             ReLU-71          [-1, 132, 16, 16]               0\n",
      "           Conv2d-72           [-1, 48, 16, 16]           6,336\n",
      "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
      "             ReLU-74           [-1, 48, 16, 16]               0\n",
      "           Conv2d-75           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-76          [-1, 144, 16, 16]               0\n",
      "      BatchNorm2d-77          [-1, 144, 16, 16]             288\n",
      "             ReLU-78          [-1, 144, 16, 16]               0\n",
      "           Conv2d-79           [-1, 48, 16, 16]           6,912\n",
      "      BatchNorm2d-80           [-1, 48, 16, 16]              96\n",
      "             ReLU-81           [-1, 48, 16, 16]               0\n",
      "           Conv2d-82           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-83          [-1, 156, 16, 16]               0\n",
      "      BatchNorm2d-84          [-1, 156, 16, 16]             312\n",
      "             ReLU-85          [-1, 156, 16, 16]               0\n",
      "           Conv2d-86           [-1, 48, 16, 16]           7,488\n",
      "      BatchNorm2d-87           [-1, 48, 16, 16]              96\n",
      "             ReLU-88           [-1, 48, 16, 16]               0\n",
      "           Conv2d-89           [-1, 12, 16, 16]           5,184\n",
      "       Bottleneck-90          [-1, 168, 16, 16]               0\n",
      "      BatchNorm2d-91          [-1, 168, 16, 16]             336\n",
      "             ReLU-92          [-1, 168, 16, 16]               0\n",
      "           Conv2d-93          [-1, 168, 16, 16]          28,224\n",
      "        AvgPool2d-94            [-1, 168, 8, 8]               0\n",
      "       Transition-95            [-1, 168, 8, 8]               0\n",
      "      BatchNorm2d-96            [-1, 168, 8, 8]             336\n",
      "             ReLU-97            [-1, 168, 8, 8]               0\n",
      "           Conv2d-98             [-1, 48, 8, 8]           8,064\n",
      "      BatchNorm2d-99             [-1, 48, 8, 8]              96\n",
      "            ReLU-100             [-1, 48, 8, 8]               0\n",
      "          Conv2d-101             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-102            [-1, 180, 8, 8]               0\n",
      "     BatchNorm2d-103            [-1, 180, 8, 8]             360\n",
      "            ReLU-104            [-1, 180, 8, 8]               0\n",
      "          Conv2d-105             [-1, 48, 8, 8]           8,640\n",
      "     BatchNorm2d-106             [-1, 48, 8, 8]              96\n",
      "            ReLU-107             [-1, 48, 8, 8]               0\n",
      "          Conv2d-108             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-109            [-1, 192, 8, 8]               0\n",
      "     BatchNorm2d-110            [-1, 192, 8, 8]             384\n",
      "            ReLU-111            [-1, 192, 8, 8]               0\n",
      "          Conv2d-112             [-1, 48, 8, 8]           9,216\n",
      "     BatchNorm2d-113             [-1, 48, 8, 8]              96\n",
      "            ReLU-114             [-1, 48, 8, 8]               0\n",
      "          Conv2d-115             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-116            [-1, 204, 8, 8]               0\n",
      "     BatchNorm2d-117            [-1, 204, 8, 8]             408\n",
      "            ReLU-118            [-1, 204, 8, 8]               0\n",
      "          Conv2d-119             [-1, 48, 8, 8]           9,792\n",
      "     BatchNorm2d-120             [-1, 48, 8, 8]              96\n",
      "            ReLU-121             [-1, 48, 8, 8]               0\n",
      "          Conv2d-122             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-123            [-1, 216, 8, 8]               0\n",
      "     BatchNorm2d-124            [-1, 216, 8, 8]             432\n",
      "            ReLU-125            [-1, 216, 8, 8]               0\n",
      "          Conv2d-126             [-1, 48, 8, 8]          10,368\n",
      "     BatchNorm2d-127             [-1, 48, 8, 8]              96\n",
      "            ReLU-128             [-1, 48, 8, 8]               0\n",
      "          Conv2d-129             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-130            [-1, 228, 8, 8]               0\n",
      "     BatchNorm2d-131            [-1, 228, 8, 8]             456\n",
      "            ReLU-132            [-1, 228, 8, 8]               0\n",
      "          Conv2d-133             [-1, 48, 8, 8]          10,944\n",
      "     BatchNorm2d-134             [-1, 48, 8, 8]              96\n",
      "            ReLU-135             [-1, 48, 8, 8]               0\n",
      "          Conv2d-136             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-137            [-1, 240, 8, 8]               0\n",
      "     BatchNorm2d-138            [-1, 240, 8, 8]             480\n",
      "            ReLU-139            [-1, 240, 8, 8]               0\n",
      "          Conv2d-140             [-1, 48, 8, 8]          11,520\n",
      "     BatchNorm2d-141             [-1, 48, 8, 8]              96\n",
      "            ReLU-142             [-1, 48, 8, 8]               0\n",
      "          Conv2d-143             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-144            [-1, 252, 8, 8]               0\n",
      "     BatchNorm2d-145            [-1, 252, 8, 8]             504\n",
      "            ReLU-146            [-1, 252, 8, 8]               0\n",
      "          Conv2d-147             [-1, 48, 8, 8]          12,096\n",
      "     BatchNorm2d-148             [-1, 48, 8, 8]              96\n",
      "            ReLU-149             [-1, 48, 8, 8]               0\n",
      "          Conv2d-150             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-151            [-1, 264, 8, 8]               0\n",
      "     BatchNorm2d-152            [-1, 264, 8, 8]             528\n",
      "            ReLU-153            [-1, 264, 8, 8]               0\n",
      "          Conv2d-154             [-1, 48, 8, 8]          12,672\n",
      "     BatchNorm2d-155             [-1, 48, 8, 8]              96\n",
      "            ReLU-156             [-1, 48, 8, 8]               0\n",
      "          Conv2d-157             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-158            [-1, 276, 8, 8]               0\n",
      "     BatchNorm2d-159            [-1, 276, 8, 8]             552\n",
      "            ReLU-160            [-1, 276, 8, 8]               0\n",
      "          Conv2d-161             [-1, 48, 8, 8]          13,248\n",
      "     BatchNorm2d-162             [-1, 48, 8, 8]              96\n",
      "            ReLU-163             [-1, 48, 8, 8]               0\n",
      "          Conv2d-164             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-165            [-1, 288, 8, 8]               0\n",
      "     BatchNorm2d-166            [-1, 288, 8, 8]             576\n",
      "            ReLU-167            [-1, 288, 8, 8]               0\n",
      "          Conv2d-168             [-1, 48, 8, 8]          13,824\n",
      "     BatchNorm2d-169             [-1, 48, 8, 8]              96\n",
      "            ReLU-170             [-1, 48, 8, 8]               0\n",
      "          Conv2d-171             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-172            [-1, 300, 8, 8]               0\n",
      "     BatchNorm2d-173            [-1, 300, 8, 8]             600\n",
      "            ReLU-174            [-1, 300, 8, 8]               0\n",
      "          Conv2d-175             [-1, 48, 8, 8]          14,400\n",
      "     BatchNorm2d-176             [-1, 48, 8, 8]              96\n",
      "            ReLU-177             [-1, 48, 8, 8]               0\n",
      "          Conv2d-178             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-179            [-1, 312, 8, 8]               0\n",
      "     BatchNorm2d-180            [-1, 312, 8, 8]             624\n",
      "            ReLU-181            [-1, 312, 8, 8]               0\n",
      "          Conv2d-182             [-1, 48, 8, 8]          14,976\n",
      "     BatchNorm2d-183             [-1, 48, 8, 8]              96\n",
      "            ReLU-184             [-1, 48, 8, 8]               0\n",
      "          Conv2d-185             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-186            [-1, 324, 8, 8]               0\n",
      "     BatchNorm2d-187            [-1, 324, 8, 8]             648\n",
      "            ReLU-188            [-1, 324, 8, 8]               0\n",
      "          Conv2d-189             [-1, 48, 8, 8]          15,552\n",
      "     BatchNorm2d-190             [-1, 48, 8, 8]              96\n",
      "            ReLU-191             [-1, 48, 8, 8]               0\n",
      "          Conv2d-192             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-193            [-1, 336, 8, 8]               0\n",
      "     BatchNorm2d-194            [-1, 336, 8, 8]             672\n",
      "            ReLU-195            [-1, 336, 8, 8]               0\n",
      "          Conv2d-196             [-1, 48, 8, 8]          16,128\n",
      "     BatchNorm2d-197             [-1, 48, 8, 8]              96\n",
      "            ReLU-198             [-1, 48, 8, 8]               0\n",
      "          Conv2d-199             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-200            [-1, 348, 8, 8]               0\n",
      "     BatchNorm2d-201            [-1, 348, 8, 8]             696\n",
      "            ReLU-202            [-1, 348, 8, 8]               0\n",
      "          Conv2d-203             [-1, 48, 8, 8]          16,704\n",
      "     BatchNorm2d-204             [-1, 48, 8, 8]              96\n",
      "            ReLU-205             [-1, 48, 8, 8]               0\n",
      "          Conv2d-206             [-1, 12, 8, 8]           5,184\n",
      "      Bottleneck-207            [-1, 360, 8, 8]               0\n",
      "     BatchNorm2d-208            [-1, 360, 8, 8]             720\n",
      "            ReLU-209            [-1, 360, 8, 8]               0\n",
      "          Conv2d-210            [-1, 360, 8, 8]         129,600\n",
      "       AvgPool2d-211            [-1, 360, 4, 4]               0\n",
      "      Transition-212            [-1, 360, 4, 4]               0\n",
      "     BatchNorm2d-213            [-1, 360, 4, 4]             720\n",
      "            ReLU-214            [-1, 360, 4, 4]               0\n",
      "          Conv2d-215             [-1, 48, 4, 4]          17,280\n",
      "     BatchNorm2d-216             [-1, 48, 4, 4]              96\n",
      "            ReLU-217             [-1, 48, 4, 4]               0\n",
      "          Conv2d-218             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-219            [-1, 372, 4, 4]               0\n",
      "     BatchNorm2d-220            [-1, 372, 4, 4]             744\n",
      "            ReLU-221            [-1, 372, 4, 4]               0\n",
      "          Conv2d-222             [-1, 48, 4, 4]          17,856\n",
      "     BatchNorm2d-223             [-1, 48, 4, 4]              96\n",
      "            ReLU-224             [-1, 48, 4, 4]               0\n",
      "          Conv2d-225             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-226            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-227            [-1, 384, 4, 4]             768\n",
      "            ReLU-228            [-1, 384, 4, 4]               0\n",
      "          Conv2d-229             [-1, 48, 4, 4]          18,432\n",
      "     BatchNorm2d-230             [-1, 48, 4, 4]              96\n",
      "            ReLU-231             [-1, 48, 4, 4]               0\n",
      "          Conv2d-232             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-233            [-1, 396, 4, 4]               0\n",
      "     BatchNorm2d-234            [-1, 396, 4, 4]             792\n",
      "            ReLU-235            [-1, 396, 4, 4]               0\n",
      "          Conv2d-236             [-1, 48, 4, 4]          19,008\n",
      "     BatchNorm2d-237             [-1, 48, 4, 4]              96\n",
      "            ReLU-238             [-1, 48, 4, 4]               0\n",
      "          Conv2d-239             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-240            [-1, 408, 4, 4]               0\n",
      "     BatchNorm2d-241            [-1, 408, 4, 4]             816\n",
      "            ReLU-242            [-1, 408, 4, 4]               0\n",
      "          Conv2d-243             [-1, 48, 4, 4]          19,584\n",
      "     BatchNorm2d-244             [-1, 48, 4, 4]              96\n",
      "            ReLU-245             [-1, 48, 4, 4]               0\n",
      "          Conv2d-246             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-247            [-1, 420, 4, 4]               0\n",
      "     BatchNorm2d-248            [-1, 420, 4, 4]             840\n",
      "            ReLU-249            [-1, 420, 4, 4]               0\n",
      "          Conv2d-250             [-1, 48, 4, 4]          20,160\n",
      "     BatchNorm2d-251             [-1, 48, 4, 4]              96\n",
      "            ReLU-252             [-1, 48, 4, 4]               0\n",
      "          Conv2d-253             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-254            [-1, 432, 4, 4]               0\n",
      "     BatchNorm2d-255            [-1, 432, 4, 4]             864\n",
      "            ReLU-256            [-1, 432, 4, 4]               0\n",
      "          Conv2d-257             [-1, 48, 4, 4]          20,736\n",
      "     BatchNorm2d-258             [-1, 48, 4, 4]              96\n",
      "            ReLU-259             [-1, 48, 4, 4]               0\n",
      "          Conv2d-260             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-261            [-1, 444, 4, 4]               0\n",
      "     BatchNorm2d-262            [-1, 444, 4, 4]             888\n",
      "            ReLU-263            [-1, 444, 4, 4]               0\n",
      "          Conv2d-264             [-1, 48, 4, 4]          21,312\n",
      "     BatchNorm2d-265             [-1, 48, 4, 4]              96\n",
      "            ReLU-266             [-1, 48, 4, 4]               0\n",
      "          Conv2d-267             [-1, 12, 4, 4]           5,184\n",
      "      Bottleneck-268            [-1, 456, 4, 4]               0\n",
      "     BatchNorm2d-269            [-1, 456, 4, 4]             912\n",
      "            ReLU-270            [-1, 456, 4, 4]               0\n",
      "       AvgPool2d-271            [-1, 456, 1, 1]               0\n",
      "          Linear-272                    [-1, 2]             914\n",
      "================================================================\n",
      "Total params: 777,962\n",
      "Trainable params: 777,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 29.89\n",
      "Params size (MB): 2.97\n",
      "Estimated Total Size (MB): 32.87\n",
      "----------------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs: 98839512.0\n",
      "MACs: 49419756.0\n",
      "Parameters: 777962.0\n",
      "Finished Training\n",
      "Average inference time per batch: 0.4823 seconds\n",
      "TP: 58.00\n",
      "FN: 5.00\n",
      "TN: 42.00\n",
      "FP: 2.00\n",
      "Acc: 93.46%\n",
      "Se: 92.06%\n",
      "Sp: 95.45%\n",
      "MAcc: 93.76%\n"
     ]
    }
   ],
   "source": [
    "!python /media/zhaoyu/HDD/Coding_workspace/AHF-Rapid-Diagnosis/ablation.py \\\n",
    "--train_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/train' \\\n",
    "--test_dir '/media/zhaoyu/HDD/Datasets/QiuZhaoyu/PCG/main-1channel/dataset_mfcc/train_1/test' \\\n",
    "--model_path '/media/zhaoyu/HDD/Models/Dense1_deep_blocks.pth' \\\n",
    "--num_blocks 4 8 16 8\\\n",
    "--compression_rate 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
